"""
è®¡åˆ’è¯¦æƒ…é¡µUI
åŒ…å«ï¼šä¸Šéƒ¨æ¦‚è§ˆã€å·¦ä¾§è®­ç»ƒåˆ—è¡¨ã€ä¸­é—´Kçº¿å›¾ã€å³ä¾§Agentè®°å½•ã€ä¸‹æ–¹è´¦æˆ·è®¢å•
"""
import gradio as gr
import plotly.graph_objects as go
import pandas as pd
import asyncio
import json
from datetime import datetime, timedelta, timezone
from typing import Optional, List, Dict
from services.plan_service import PlanService
from services.training_service import TrainingService
from services.inference_service import InferenceService
from database.db import get_db
from database.models import TradingPlan, TrainingRecord, PredictionData, AgentDecision, KlineData
from sqlalchemy import and_, desc, func
from utils.logger import setup_logger
from utils.timezone_helper import (format_datetime_full_beijing, format_datetime_short_beijing,
                                   format_datetime_beijing, format_time_range_utc8)
from services.agent_confirmation_service import confirmation_service

logger = setup_logger(__name__, "plan_detail_ui.log")


class PlanDetailUI:
    """è®¡åˆ’è¯¦æƒ…é¡µUI"""

    def __init__(self):
        self.current_plan_id = None

    def _safe_db_update(self, update_func, plan_id: int, max_retries: int = 3):
        """
        å®‰å…¨çš„æ•°æ®åº“æ›´æ–°æ“ä½œï¼Œå¸¦é‡è¯•æœºåˆ¶

        Args:
            update_func: æ›´æ–°å‡½æ•°ï¼Œæ¥æ”¶dbä¼šè¯ä½œä¸ºå‚æ•°
            plan_id: è®¡åˆ’ID
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        for attempt in range(max_retries):
            try:
                from database.db import SessionLocal
                db = SessionLocal()
                try:
                    update_func(db)
                    db.commit()
                    return True
                finally:
                    db.close()
            except Exception as e:
                if attempt == max_retries - 1:
                    logger.error(f"æ•°æ®åº“æ›´æ–°å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: plan_id={plan_id}, error={e}")
                    return False
                else:
                    logger.warning(f"æ•°æ®åº“æ›´æ–°å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•({attempt + 1}/{max_retries}): plan_id={plan_id}, error={e}")
                    import time
                    time.sleep(0.1 * (attempt + 1))
        return False

    def load_plan_data(self, plan_id: int) -> Dict:
        """åŠ è½½è®¡åˆ’æ•°æ®"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return {'error': 'è®¡åˆ’ä¸å­˜åœ¨'}

                # è·å–æœ€æ–°è®­ç»ƒè®°å½•
                latest_training = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status == 'completed',
                        TrainingRecord.is_active == True
                    )
                ).order_by(desc(TrainingRecord.created_at)).first()

                # è·å–æœ€æ–°Agentå†³ç­–
                latest_agent = db.query(AgentDecision).filter(
                    AgentDecision.plan_id == plan_id
                ).order_by(desc(AgentDecision.decision_time)).first()

                return {
                    'plan': plan,
                    'latest_training': latest_training,
                    'latest_agent': latest_agent
                }
        except Exception as e:
            logger.error(f"åŠ è½½è®¡åˆ’æ•°æ®å¤±è´¥: {e}")
            return {'error': str(e)}

    def render_plan_overview(self, plan_id: int) -> tuple:
        """
        æ¸²æŸ“è®¡åˆ’æ¦‚è§ˆï¼ˆä¸Šéƒ¨ï¼‰

        Returns:
            tuple: (overview_text, ws_status_text, ws_start_visible, ws_stop_visible, plan_status_text, plan_start_visible, plan_stop_visible)
        """
        data = self.load_plan_data(plan_id)
        if 'error' in data:
            return (
                f"âŒ é”™è¯¯: {data['error']}",  # overview_text
                "**WebSocketçŠ¶æ€**: âšª æœªè¿æ¥",  # ws_status_text
                True,  # ws_start_visible
                False, # ws_stop_visible
                "**è®¡åˆ’çŠ¶æ€**: âšª å·²åˆ›å»º",  # plan_status_text
                True,  # plan_start_visible
                False  # plan_stop_visible
            )

        plan = data['plan']
        latest_training = data['latest_training']
        latest_agent = data['latest_agent']

        training_version = latest_training.version if latest_training else "æœªè®­ç»ƒ"
        agent_time = format_datetime_full_beijing(latest_agent.decision_time) if latest_agent else "æ— è®°å½•"

        # è‡ªåŠ¨å¾®è°ƒæ—¶é—´è¡¨
        schedule = plan.auto_finetune_schedule or []
        schedule_str = ', '.join(schedule) if schedule else 'æœªé…ç½®'

        # è®¡åˆ’çŠ¶æ€
        plan_status_emoji = {
            'created': 'âšª å·²åˆ›å»º',
            'running': 'ğŸŸ¢ è¿è¡Œä¸­',
            'paused': 'ğŸŸ¡ å·²æš‚åœ',
            'stopped': 'ğŸ”´ å·²åœæ­¢'
        }.get(plan.status, 'â“ æœªçŸ¥')

        overview = f"""
# ğŸ“Š {plan.plan_name}

---

**äº¤æ˜“å¯¹**: `{plan.inst_id}` | **æ—¶é—´é¢—ç²’åº¦**: `{plan.interval}` | **ç¯å¢ƒ**: {'ğŸ§ª æ¨¡æ‹Ÿç›˜' if plan.is_demo else 'ğŸ’° å®ç›˜'}

**è®¡åˆ’çŠ¶æ€**: {plan_status_emoji}

**æœ€æ–°æ¨¡å‹ç‰ˆæœ¬**: `{training_version}` | **AI Agentæœ€åè¿è¡Œ**: {agent_time}

**è‡ªåŠ¨å¾®è°ƒæ—¶é—´**: {schedule_str}

**åˆ›å»ºæ—¶é—´**: {format_datetime_full_beijing(plan.created_at)}

---
"""

        # è·å–æ§åˆ¶é¢æ¿çŠ¶æ€
        control_status = self.get_control_panel_status(plan_id)

        return (
            overview,  # overview_text
            control_status[0],  # ws_status_text
            control_status[1],  # ws_start_visible
            control_status[2],  # ws_stop_visible
            control_status[3],  # plan_status_text
            control_status[4],  # plan_start_visible
            control_status[5]   # plan_stop_visible
        )

    def get_control_panel_status(self, plan_id: int) -> tuple:
        """
        è·å–æ§åˆ¶é¢æ¿çŠ¶æ€

        Returns:
            tuple: (ws_status_text, ws_start_visible, ws_stop_visible, plan_status_text, plan_start_visible, plan_stop_visible)
        """
        data = self.load_plan_data(plan_id)
        if 'error' in data:
            return (
                "**WebSocketçŠ¶æ€**: âšª æœªè¿æ¥",  # ws_status_text
                True,  # ws_start_visible
                False, # ws_stop_visible
                "**è®¡åˆ’çŠ¶æ€**: âšª å·²åˆ›å»º",  # plan_status_text
                True,  # plan_start_visible
                False  # plan_stop_visible
            )

        plan = data['plan']

        # å¤šé‡æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€
        try:
            # 1. é¦–å…ˆæ£€æŸ¥WebSocketè®¢é˜…è¡¨çš„çŠ¶æ€ï¼ˆæœ€å¯é çš„æ•°æ®æºï¼‰
            from database.db import get_db
            from database.models import WebSocketSubscription

            ws_connected = False

            with get_db() as db:
                subscription = db.query(WebSocketSubscription).filter(
                    WebSocketSubscription.inst_id == plan.inst_id,
                    WebSocketSubscription.interval == plan.interval,
                    WebSocketSubscription.is_demo == plan.is_demo
                ).first()

                if subscription:
                    # å¦‚æœè®¢é˜…è¡¨ä¸­æœ‰è®°å½•ï¼Œæ£€æŸ¥æ˜¯å¦çœŸçš„åœ¨è¿è¡Œ
                    # ä¸»è¦æŒ‡æ ‡ï¼šçŠ¶æ€ä¸ºrunningä¸”æœ‰æ•°æ®æ¥æ”¶
                    if (subscription.status == 'running' and
                        subscription.total_received > 0 and
                        subscription.last_data_time):
                        ws_connected = True
                        logger.debug(f"WebSocketè¿è¡Œä¸­ (æ¥è‡ªè®¢é˜…è¡¨): plan_id={plan_id}, received={subscription.total_received}")

            # 2. å¦‚æœè®¢é˜…è¡¨æ˜¾ç¤ºæœªè¿æ¥ï¼Œå°è¯•è¿æ¥ç®¡ç†å™¨
            if not ws_connected:
                try:
                    from services.ws_connection_manager import ws_connection_manager
                    ws_status = ws_connection_manager.get_connection_status(
                        inst_id=plan.inst_id,
                        interval=plan.interval,
                        is_demo=plan.is_demo
                    )

                    if ws_status['exists'] and ws_status['thread_alive']:
                        ws_connected = ws_status['connected'] and ws_status['running']
                        logger.debug(f"WebSocketçŠ¶æ€ (æ¥è‡ªè¿æ¥ç®¡ç†å™¨): plan_id={plan_id}, connected={ws_connected}")

                except Exception as conn_error:
                    logger.debug(f"è¿æ¥ç®¡ç†å™¨çŠ¶æ€è·å–å¤±è´¥: {conn_error}")

            # 3. æœ€åå›é€€åˆ°æ•°æ®åº“ä¸­çš„çŠ¶æ€
            if not ws_connected and plan.ws_connected:
                ws_connected = plan.ws_connected
                logger.debug(f"WebSocketçŠ¶æ€ (æ¥è‡ªæ•°æ®åº“): plan_id={plan_id}, connected={ws_connected}")

            # 4. å¼‚æ­¥æ›´æ–°æ•°æ®åº“çŠ¶æ€ï¼ˆå¦‚æœå‘ç°ä¸ä¸€è‡´ï¼‰
            if ws_connected != plan.ws_connected:
                def update_plan_ws_status(db):
                    current_plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                    if current_plan and current_plan.ws_connected != ws_connected:
                        db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                            'ws_connected': ws_connected,
                            'last_sync_time': datetime.utcnow()
                        })
                        logger.info(f"è®¡åˆ’WebSocketçŠ¶æ€å·²æ›´æ–°: plan_id={plan_id}, ws_connected={ws_connected}")

                self._safe_db_update(update_plan_ws_status, plan_id)

        except Exception as e:
            logger.error(f"è·å–WebSocketçŠ¶æ€å¤±è´¥: {e}")
            ws_connected = plan.ws_connected

        ws_status_text = "ğŸŸ¢ å·²è¿æ¥" if ws_connected else "âšª æœªè¿æ¥"
        ws_status_display = f"**WebSocketçŠ¶æ€**: {ws_status_text}"

        # è®¡åˆ’çŠ¶æ€
        plan_status_emoji = {
            'created': 'âšª å·²åˆ›å»º',
            'running': 'ğŸŸ¢ è¿è¡Œä¸­',
            'paused': 'ğŸŸ¡ å·²æš‚åœ',
            'stopped': 'ğŸ”´ å·²åœæ­¢'
        }.get(plan.status, 'â“ æœªçŸ¥')
        plan_status_display = f"**è®¡åˆ’çŠ¶æ€**: {plan_status_emoji}"

        # WebSocketçŠ¶æ€æ§åˆ¶
        ws_start_visible = not ws_connected
        ws_stop_visible = ws_connected

        # è®¡åˆ’çŠ¶æ€æ§åˆ¶
        plan_start_visible = plan.status != 'running'
        plan_stop_visible = plan.status == 'running'

        return (
            ws_status_display,  # ws_status_text
            ws_start_visible,   # ws_start_visible
            ws_stop_visible,    # ws_stop_visible
            plan_status_display,  # plan_status_text
            plan_start_visible,  # plan_start_visible
            plan_stop_visible   # plan_stop_visible
        )

    def load_training_records(self, plan_id: int) -> pd.DataFrame:
        """åŠ è½½è®­ç»ƒè®°å½•åˆ—è¡¨ï¼ˆå·¦ä¾§ï¼‰"""
        try:
            records = TrainingService.list_training_records(plan_id)
            if not records:
                return pd.DataFrame()

            df_data = []
            for record in records:
                status_emoji = {
                    'waiting': 'â³',
                    'training': 'ğŸ”„',
                    'completed': 'âœ…',
                    'failed': 'âŒ'
                }.get(record['status'], 'â“')

                df_data.append({
                    'ID': record['id'],
                    'ç‰ˆæœ¬': record['version'],
                    'çŠ¶æ€': f"{status_emoji} {record['status']}",
                    'å¯ç”¨': 'âœ“' if record['is_active'] else 'âœ—',
                    'æ•°æ®é‡': record['data_count'] or 0,
                    'è®­ç»ƒæ—¶é•¿(ç§’)': record['train_duration'] or 0,  # æ”¹ä¸ºçº¯æ•°å­—
                    'åˆ›å»ºæ—¶é—´': format_datetime_short_beijing(record['created_at'])
                })

            return pd.DataFrame(df_data)

        except Exception as e:
            logger.error(f"åŠ è½½è®­ç»ƒè®°å½•å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_current_training_status(self, plan_id: int) -> str:
        """
        è·å–å½“å‰è®¡åˆ’çš„è®­ç»ƒçŠ¶æ€å’Œè¿›åº¦

        Args:
            plan_id: è®¡åˆ’ID

        Returns:
            æ ¼å¼åŒ–çš„è®­ç»ƒçŠ¶æ€å­—ç¬¦ä¸²
        """
        try:
            from services.training_service import TrainingService

            with get_db() as db:
                # æŸ¥æ‰¾å½“å‰è®¡åˆ’æ­£åœ¨è®­ç»ƒçš„è®°å½•
                training_record = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status.in_(['waiting', 'training'])
                    )
                ).order_by(TrainingRecord.created_at.desc()).first()

                if not training_record:
                    return None

                # è·å–è®­ç»ƒè¿›åº¦
                progress_info = TrainingService.get_training_progress(training_record.id)

                status_emoji = {
                    'waiting': 'â³',
                    'training': 'ğŸ”„'
                }.get(training_record.status, 'â“')

                if progress_info:
                    progress_percent = int(progress_info['progress'] * 100)
                    stage = progress_info['stage']
                    message = progress_info['message']
                    progress_bar = 'â–ˆ' * (progress_percent // 5) + 'â–‘' * (20 - progress_percent // 5)

                    return f"""
**{status_emoji} å½“å‰è®­ç»ƒçŠ¶æ€**

- **è®°å½•ID**: {training_record.id}
- **ç‰ˆæœ¬**: {training_record.version}
- **è¿›åº¦**: {progress_percent}%
- **é˜¶æ®µ**: {stage}
- **çŠ¶æ€**: {message}

`{progress_bar}` ({progress_percent}%)
                    """
                else:
                    return f"""
**{status_emoji} å½“å‰è®­ç»ƒçŠ¶æ€**

- **è®°å½•ID**: {training_record.id}
- **ç‰ˆæœ¬**: {training_record.version}
- **çŠ¶æ€**: {training_record.status}
- **ç­‰å¾…è¿›åº¦æ›´æ–°...**
                    """

        except Exception as e:
            logger.error(f"è·å–è®­ç»ƒçŠ¶æ€å¤±è´¥: {e}")
            return f"âŒ è·å–è®­ç»ƒçŠ¶æ€å¤±è´¥: {str(e)}"

    def get_training_options(self, plan_id: int) -> List[tuple]:
        """
        è·å–è®­ç»ƒ ID é€‰é¡¹åˆ—è¡¨ï¼ˆç”¨äºä¸‹æ‹‰é€‰æ‹©å™¨ï¼‰

        Returns:
            List[tuple]: [(æ˜¾ç¤ºæ–‡æœ¬, training_id), ...]
        """
        try:
            with get_db() as db:
                # è·å–æ‰€æœ‰å·²å®Œæˆä¸”æœ‰é¢„æµ‹æ•°æ®çš„è®­ç»ƒè®°å½•
                training_records = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status == 'completed'
                    )
                ).order_by(desc(TrainingRecord.created_at)).all()

                options = [("å…¨éƒ¨", None)]  # ç¬¬ä¸€é¡¹æ˜¯"å…¨éƒ¨"

                for record in training_records:
                    # æ£€æŸ¥æ˜¯å¦æœ‰é¢„æµ‹æ•°æ®
                    pred_count = db.query(func.count(PredictionData.id)).filter(
                        PredictionData.training_record_id == record.id
                    ).scalar()

                    if pred_count > 0:
                        # è·å–æ¨ç†æ—¶é—´ï¼ˆæœ€æ—©çš„é¢„æµ‹æ•°æ®åˆ›å»ºæ—¶é—´ï¼‰
                        first_pred = db.query(PredictionData).filter(
                            PredictionData.training_record_id == record.id
                        ).order_by(PredictionData.created_at.asc()).first()

                        inference_time_str = format_datetime_short_beijing(first_pred.created_at) if first_pred else ''

                        # æ ¼å¼ï¼šv1 (æ¨ç†: 12-20 10:30)
                        display_text = f"{record.version} (æ¨ç†: {inference_time_str})"
                        options.append((display_text, record.id))

                return options

        except Exception as e:
            logger.error(f"è·å–è®­ç»ƒé€‰é¡¹å¤±è´¥: {e}")
            return [("å…¨éƒ¨", None)]

    def generate_kline_chart(
        self,
        plan_id: int,
        show_predictions: bool = True,
        training_id: Optional[int] = None,
        last_days: int = 30
    ) -> go.Figure:
        """
        ç”ŸæˆKçº¿å›¾ï¼ˆä¸­é—´ï¼Œå«é¢„æµ‹æ•°æ®ï¼‰

        Args:
            plan_id: è®¡åˆ’ID
            show_predictions: æ˜¯å¦æ˜¾ç¤ºé¢„æµ‹
            training_id: è®­ç»ƒè®°å½•IDï¼ŒNoneè¡¨ç¤ºæ˜¾ç¤ºå…¨éƒ¨
            last_days: æ˜¾ç¤ºæœ€è¿‘å¤šå°‘å¤©
        """
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return self._empty_chart("è®¡åˆ’ä¸å­˜åœ¨")

                # æŸ¥è¯¢å†å²Kçº¿æ•°æ®
                end_time = datetime.now()
                start_time = end_time - pd.Timedelta(days=last_days)

                klines = db.query(KlineData).filter(
                    and_(
                        KlineData.inst_id == plan.inst_id,
                        KlineData.interval == plan.interval,
                        KlineData.timestamp >= start_time,
                        KlineData.timestamp <= end_time
                    )
                ).order_by(KlineData.timestamp).all()

                if not klines:
                    return self._empty_chart("æ— å†å²æ•°æ®")

                # åˆ›å»ºKçº¿å›¾
                fig = go.Figure()

                # å°†UTCæ—¶é—´è½¬æ¢ä¸ºUTC+8ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰æ˜¾ç¤º
                timestamps_utc8 = []
                for k in klines:
                    ts = k.timestamp
                    # å¦‚æœæ˜¯naive datetimeï¼Œå‡è®¾å®ƒæ˜¯UTC
                    if ts.tzinfo is None:
                        ts = ts.replace(tzinfo=timezone.utc)
                    # è½¬æ¢ä¸ºUTC+8
                    ts_utc8 = ts + timedelta(hours=8)
                    timestamps_utc8.append(ts_utc8)

                # æ·»åŠ çœŸå®Kçº¿
                fig.add_trace(go.Candlestick(
                    x=timestamps_utc8,
                    open=[k.open for k in klines],
                    high=[k.high for k in klines],
                    low=[k.low for k in klines],
                    close=[k.close for k in klines],
                    name='å®é™…Kçº¿',
                    increasing_line_color='#26a69a',
                    decreasing_line_color='#ef5350'
                ))

                # æ·»åŠ é¢„æµ‹æ•°æ®
                if show_predictions:
                    # å¦‚æœ training_id ä¸º Noneï¼Œæ˜¾ç¤ºæ‰€æœ‰å†å²é¢„æµ‹
                    if training_id is None:
                        # è·å–æ‰€æœ‰å·²å®Œæˆçš„è®­ç»ƒè®°å½•
                        all_training_records = db.query(TrainingRecord).filter(
                            and_(
                                TrainingRecord.plan_id == plan_id,
                                TrainingRecord.status == 'completed'
                            )
                        ).order_by(TrainingRecord.created_at.asc()).all()  # ä»æ—§åˆ°æ–°

                        # ä¸ºæ¯ä¸ªè®­ç»ƒè®°å½•åˆ†é…é¢œè‰²ï¼ˆç›¸åŒè®­ç»ƒç‰ˆæœ¬çš„æ‰€æœ‰æ‰¹æ¬¡ä½¿ç”¨ç›¸åŒé¢œè‰²ï¼‰
                        colors = ['#ff9800', '#2196f3', '#4caf50', '#9c27b0', '#f44336', '#00bcd4']

                        for record_idx, record in enumerate(all_training_records):
                            # ä¸ºå½“å‰è®­ç»ƒç‰ˆæœ¬åˆ†é…é¢œè‰²
                            record_color = colors[record_idx % len(colors)]

                            # è·å–è¯¥è®­ç»ƒè®°å½•çš„æ‰€æœ‰æ¨ç†æ‰¹æ¬¡
                            batches = db.query(
                                PredictionData.inference_batch_id,
                                func.min(PredictionData.created_at).label('inference_time')
                            ).filter(
                                PredictionData.training_record_id == record.id
                            ).group_by(
                                PredictionData.inference_batch_id
                            ).order_by(
                                func.min(PredictionData.created_at).asc()
                            ).all()

                            for batch_idx, batch in enumerate(batches):
                                predictions = db.query(PredictionData).filter(
                                    and_(
                                        PredictionData.training_record_id == record.id,
                                        PredictionData.inference_batch_id == batch.inference_batch_id
                                    )
                                ).order_by(PredictionData.timestamp).all()

                                if predictions:
                                    # åªåœ¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ—¶æ˜¾ç¤ºå›¾ä¾‹
                                    show_in_legend = (batch_idx == 0)
                                    self._add_prediction_trace(
                                        fig,
                                        predictions,
                                        record.id,
                                        f"{record.version} (æ¨ç†: {format_datetime_short_beijing(batch.inference_time)})",
                                        batch.inference_time,
                                        record_color,  # ç›¸åŒè®­ç»ƒç‰ˆæœ¬ä½¿ç”¨ç›¸åŒé¢œè‰²
                                        show_in_legend=show_in_legend
                                    )
                    else:
                        # æ˜¾ç¤ºæŒ‡å®šè®­ç»ƒè®°å½•çš„æ‰€æœ‰æ‰¹æ¬¡é¢„æµ‹
                        record = db.query(TrainingRecord).filter(
                            TrainingRecord.id == training_id
                        ).first()

                        if record:
                            # ä¸ºè¯¥è®­ç»ƒç‰ˆæœ¬åˆ†é…ä¸€ä¸ªå›ºå®šé¢œè‰²ï¼ˆæ‰€æœ‰æ‰¹æ¬¡ä½¿ç”¨ç›¸åŒé¢œè‰²ï¼‰
                            colors = ['#ff9800', '#2196f3', '#4caf50', '#9c27b0', '#f44336', '#00bcd4']
                            record_color = colors[record.id % len(colors)]

                            # è·å–è¯¥è®­ç»ƒè®°å½•çš„æ‰€æœ‰æ¨ç†æ‰¹æ¬¡
                            batches = db.query(
                                PredictionData.inference_batch_id,
                                func.min(PredictionData.created_at).label('inference_time')
                            ).filter(
                                PredictionData.training_record_id == training_id
                            ).group_by(
                                PredictionData.inference_batch_id
                            ).order_by(
                                func.min(PredictionData.created_at).asc()
                            ).all()

                            for batch_idx, batch in enumerate(batches):
                                predictions = db.query(PredictionData).filter(
                                    and_(
                                        PredictionData.training_record_id == training_id,
                                        PredictionData.inference_batch_id == batch.inference_batch_id
                                    )
                                ).order_by(PredictionData.timestamp).all()

                                if predictions:
                                    # åªåœ¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ—¶æ˜¾ç¤ºå›¾ä¾‹
                                    show_in_legend = (batch_idx == 0)
                                    self._add_prediction_trace(
                                        fig,
                                        predictions,
                                        record.id,
                                        f"{record.version} (æ¨ç†: {format_datetime_short_beijing(batch.inference_time)})",
                                        batch.inference_time,
                                        record_color,  # ç›¸åŒè®­ç»ƒç‰ˆæœ¬ä½¿ç”¨ç›¸åŒé¢œè‰²
                                        show_in_legend=show_in_legend
                                    )

                fig.update_layout(
                    title=f"{plan.inst_id} {plan.interval} Kçº¿å›¾ (æœ€è¿‘{last_days}å¤©)",
                    xaxis_title="æ—¶é—´ (UTC+8)",
                    yaxis_title="ä»·æ ¼",
                    height=600,
                    template="plotly_white",
                    hovermode='x unified',
                    xaxis_rangeslider_visible=False
                )

                return fig

        except Exception as e:
            logger.error(f"ç”ŸæˆKçº¿å›¾å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._empty_chart(f"ç”Ÿæˆå¤±è´¥: {str(e)}")

    def _add_prediction_trace(
        self,
        fig: go.Figure,
        predictions: List[PredictionData],
        training_id: int,
        version: str,
        inference_time: datetime,
        color: str,
        show_in_legend: bool = True
    ):
        """
        æ·»åŠ é¢„æµ‹è½¨è¿¹åˆ°å›¾è¡¨

        Args:
            fig: Plotly Figureå¯¹è±¡
            predictions: é¢„æµ‹æ•°æ®åˆ—è¡¨
            training_id: è®­ç»ƒè®°å½•ID
            version: ç‰ˆæœ¬å·ï¼ˆå·²åŒ…å«æ¨ç†æ—¶é—´ï¼‰
            inference_time: æ¨ç†æ—¶é—´
            color: çº¿æ¡é¢œè‰²
            show_in_legend: æ˜¯å¦åœ¨å›¾ä¾‹ä¸­æ˜¾ç¤ºï¼ˆç”¨äºæ§åˆ¶åŒä¸€è®­ç»ƒç‰ˆæœ¬åªæ˜¾ç¤ºä¸€æ¬¡ï¼‰
        """
        # é¢„æµ‹æ•°æ®è½¬æ¢ä¸ºUTC+8
        pred_timestamps_utc8 = []
        for p in predictions:
            ts = p.timestamp
            if ts.tzinfo is None:
                ts = ts.replace(tzinfo=timezone.utc)
            ts_utc8 = ts + timedelta(hours=8)
            pred_timestamps_utc8.append(ts_utc8)

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸ç¡®å®šæ€§æ•°æ®
        has_uncertainty = any(p.close_min is not None and p.close_max is not None for p in predictions)

        if has_uncertainty:
            # ç»˜åˆ¶ä¸ç¡®å®šæ€§é˜´å½±åŒºåŸŸ
            # 1. ä¸Šè¾¹ç•Œ
            fig.add_trace(go.Scatter(
                x=pred_timestamps_utc8,
                y=[p.close_max if p.close_max is not None else p.close for p in predictions],
                mode='lines',
                line=dict(width=0),
                showlegend=False,
                hoverinfo='skip',
                legendgroup=f'group_{training_id}'
            ))

            # 2. ä¸‹è¾¹ç•Œï¼ˆå¡«å……é˜´å½±ï¼‰
            fig.add_trace(go.Scatter(
                x=pred_timestamps_utc8,
                y=[p.close_min if p.close_min is not None else p.close for p in predictions],
                mode='lines',
                fill='tonexty',
                fillcolor=f'rgba({int(color[1:3], 16)}, {int(color[3:5], 16)}, {int(color[5:7], 16)}, 0.2)',
                line=dict(width=0),
                name=f'{version.split(" ")[0]} ä¸ç¡®å®šæ€§' if show_in_legend else '',
                showlegend=show_in_legend and has_uncertainty,
                hovertemplate='<b>ä¸ç¡®å®šæ€§èŒƒå›´</b><br>æœ€é«˜: %{customdata[0]:.2f}<br>æœ€ä½: %{y:.2f}<extra></extra>',
                customdata=[[p.close_max if p.close_max is not None else p.close] for p in predictions],
                legendgroup=f'group_{training_id}'
            ))

        # æ ¼å¼åŒ–æ¨ç†æ—¶é—´
        inference_time_str = format_datetime_short_beijing(inference_time)

        # 3. å¹³å‡å€¼çº¿æ¡
        fig.add_trace(go.Scatter(
            x=pred_timestamps_utc8,
            y=[p.close for p in predictions],
            mode='lines+markers',
            name=version,
            showlegend=show_in_legend,
            line=dict(color=color, width=2, dash='dash'),
            marker=dict(size=4),
            hovertemplate=f'<b>{version}</b><br>æ—¶é—´: %{{x}}<br>æ”¶ç›˜ä»·: %{{y:.2f}}<extra></extra>',
            legendgroup=f'group_{training_id}'
        ))

    def _empty_chart(self, message: str) -> go.Figure:
        """ç©ºå›¾è¡¨"""
        fig = go.Figure()
        fig.add_annotation(
            text=message,
            xref="paper", yref="paper",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=16)
        )
        fig.update_layout(height=600)
        return fig

    def load_agent_decisions(self, plan_id: int) -> pd.DataFrame:
        """åŠ è½½Agentå†³ç­–è®°å½•ï¼ˆå³ä¾§ï¼‰"""
        try:
            with get_db() as db:
                decisions = db.query(AgentDecision).filter(
                    AgentDecision.plan_id == plan_id
                ).order_by(desc(AgentDecision.decision_time)).limit(50).all()

                if not decisions:
                    return pd.DataFrame()

                df_data = []
                for decision in decisions:
                    status_emoji = {
                        'completed': 'âœ…',
                        'failed': 'âŒ',
                        'partial': 'âš ï¸'
                    }.get(decision.status, 'â“')

                    df_data.append({
                        'ID': decision.id,
                        'æ—¶é—´': format_datetime_full_beijing(decision.decision_time),
                        'å†³ç­–ç±»å‹': decision.decision_type or 'N/A',
                        'çŠ¶æ€': f"{status_emoji} {decision.status}",
                        'æ¨¡å‹ç‰ˆæœ¬': f"v{decision.training_record_id}" if decision.training_record_id else 'N/A',
                        'å·¥å…·è°ƒç”¨': len(decision.tool_calls) if decision.tool_calls else 0
                    })

                return pd.DataFrame(df_data)

        except Exception as e:
            logger.error(f"åŠ è½½Agentå†³ç­–å¤±è´¥: {e}")
            return pd.DataFrame()

    def load_inference_records(self, plan_id: int) -> pd.DataFrame:
        """åŠ è½½Kronosæ¨ç†è®°å½•åˆ—è¡¨"""
        try:
            records = InferenceService.list_inference_records(plan_id)
            if not records:
                return pd.DataFrame()

            df_data = []
            for record in records:
                has_pred_emoji = 'âœ…' if record['has_predictions'] else 'âšª'
                inference_time_str = format_datetime_short_beijing(record['inference_time']) if record['inference_time'] else 'N/A'

                df_data.append({
                    'ID': record['training_record_id'],
                    'ç‰ˆæœ¬': record['version'],
                    'æ¨ç†æ—¶é—´': inference_time_str,
                    'é¢„æµ‹æ•°æ®': f"{has_pred_emoji} {record['predictions_count']}æ¡",
                    'æ•°æ®èŒƒå›´': record.get('date_range', 'N/A'),
                    'è®­ç»ƒå®Œæˆ': format_datetime_short_beijing(record['train_end_time']) if record['train_end_time'] else 'N/A'
                })

            return pd.DataFrame(df_data)

        except Exception as e:
            logger.error(f"åŠ è½½æ¨ç†è®°å½•å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_inference_data_timestamp_range(self, plan_id: int, lookback_window: int = None, data_offset: int = None) -> str:
        """åŸºäºæœ€æ–°Kçº¿æ•°æ®å’Œå›çœ‹çª—å£åŠ¨æ€è®¡ç®—æ¨ç†æ•°æ®ç‚¹æ—¶é—´æˆ³èŒƒå›´"""
        try:
            with get_db() as db:
                # è·å–äº¤æ˜“è®¡åˆ’ä¿¡æ¯
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "**ğŸ“Š æ¨ç†æ•°æ®ç‚¹èŒƒå›´**\n\nè®¡åˆ’ä¸å­˜åœ¨"

                # è·å–æœ€æ–°çš„Kçº¿æ•°æ®ï¼ˆæœ€åçš„æ•°æ®ç‚¹ï¼‰
                latest_kline = db.query(KlineData).filter(
                    KlineData.inst_id == plan.inst_id,
                    KlineData.interval == plan.interval
                ).order_by(KlineData.timestamp.desc()).first()

                if not latest_kline:
                    return "**ğŸ“Š æ¨ç†æ•°æ®ç‚¹èŒƒå›´**\n\næš‚æ— Kçº¿æ•°æ®"

                # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æˆ–é»˜è®¤å€¼
                if lookback_window is None:
                    # ä»è®¡åˆ’çš„å¾®è°ƒå‚æ•°ä¸­è·å–å›çœ‹çª—å£ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                    lookback_window = 200  # é»˜è®¤200ä¸ªæ•°æ®ç‚¹
                    if plan.finetune_params and isinstance(plan.finetune_params, dict):
                        lookback_window = plan.finetune_params.get('lookback_window', 200)

                if data_offset is None:
                    data_offset = 0  # é»˜è®¤æ— åç§»

                # è®¡ç®—æ¨ç†æ•°æ®çš„èµ·å§‹æ—¶é—´æˆ³
                # æ¨ç†ä½¿ç”¨çš„æ•°æ®ç‚¹èŒƒå›´ï¼šä»æœ€æ–°æ•°æ®ç‚¹å‘å‰æ¨ lookback_window + data_offset ä¸ªæ•°æ®ç‚¹
                total_data_points = lookback_window + data_offset

                # è·å–ç”¨äºæ¨ç†çš„æ•°æ®èµ·å§‹ç‚¹
                start_kline = db.query(KlineData).filter(
                    KlineData.inst_id == plan.inst_id,
                    KlineData.interval == plan.interval,
                    KlineData.timestamp <= latest_kline.timestamp
                ).order_by(KlineData.timestamp.desc()).offset(total_data_points - 1).first()

                if not start_kline:
                    # å¦‚æœæ•°æ®ç‚¹ä¸å¤Ÿï¼Œè·å–æœ€æ—©çš„æ•°æ®ç‚¹
                    start_kline = db.query(KlineData).filter(
                        KlineData.inst_id == plan.inst_id,
                        KlineData.interval == plan.interval
                    ).order_by(KlineData.timestamp.asc()).first()

                # è®¡ç®—æ•°æ®ç‚¹æ€»æ•°
                total_count = db.query(KlineData).filter(
                    KlineData.inst_id == plan.inst_id,
                    KlineData.interval == plan.interval,
                    KlineData.timestamp >= start_kline.timestamp,
                    KlineData.timestamp <= latest_kline.timestamp
                ).count()

                # æ ¼å¼åŒ–æ—¶é—´èŒƒå›´æ˜¾ç¤º
                start_time = format_datetime_beijing(start_kline.timestamp, '%Y-%m-%d %H:%M')
                end_time = format_datetime_beijing(latest_kline.timestamp, '%Y-%m-%d %H:%M')

                # è®¡ç®—æ—¶é—´è·¨åº¦
                time_diff = latest_kline.timestamp - start_kline.timestamp
                days = time_diff.days
                hours = time_diff.seconds // 3600

                time_span = ""
                if days > 0:
                    time_span = f"{days}å¤©"
                if hours > 0:
                    time_span += f"{hours}å°æ—¶" if time_span else f"{hours}å°æ—¶"

                range_info = f"""**ğŸ“Š æ¨ç†æ•°æ®ç‚¹èŒƒå›´**

**ğŸ“… æ—¶é—´èŒƒå›´**: {start_time} ~ {end_time}
**ğŸ“ˆ æ•°æ®ç‚¹æ•°é‡**: {total_count}æ¡
**â±ï¸ æ—¶é—´è·¨åº¦**: {time_span or 'ä¸è¶³1å°æ—¶'}
**ğŸ”§ å›çœ‹çª—å£**: {lookback_window}ä¸ªæ•°æ®ç‚¹
**ğŸ“ æ•°æ®åç§»**: {data_offset}ä¸ªæ•°æ®ç‚¹
**ğŸ’¡ æœ€æ–°æ•°æ®**: {format_datetime_full_beijing(latest_kline.timestamp)}"""

                return range_info

        except Exception as e:
            logger.error(f"è·å–æ¨ç†æ•°æ®ç‚¹æ—¶é—´æˆ³èŒƒå›´å¤±è´¥: {e}")
            return "**ğŸ“Š æ¨ç†æ•°æ®ç‚¹èŒƒå›´**\n\nè·å–å¤±è´¥: " + str(e)

    def get_data_range_info(self, plan_id: int) -> str:
        """è·å–æ•°æ®è¾“å…¥çš„å›çœ‹æ•°æ®æ—¥æœŸæ—¶é—´èŒƒå›´ä¿¡æ¯"""
        try:
            # è·å–æœ€æ–°çš„æ¨ç†è®°å½•ä¸­çš„æ•°æ®èŒƒå›´
            records = InferenceService.list_inference_records(plan_id)
            if not records:
                return "**ğŸ“Š Dataè¾“å…¥ä¿¡æ¯**\n\næš‚æ— æ¨ç†è®°å½•"

            # ä½¿ç”¨æœ€æ–°çš„æ¨ç†è®°å½•çš„æ•°æ®èŒƒå›´
            latest_record = records[0]  # recordsæ˜¯æŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åˆ—çš„

            if latest_record.get('datetime_range') and latest_record.get('datetime_range') != 'N/A':
                data_range_info = f"""**ğŸ“Š Dataè¾“å…¥ä¿¡æ¯**

**æ•°æ®æ—¶é—´èŒƒå›´**: {latest_record.get('datetime_range')}

**è®­ç»ƒç‰ˆæœ¬**: {latest_record.get('version', 'N/A')}
**è®­ç»ƒå®Œæˆæ—¶é—´**: {format_datetime_beijing(latest_record.get('train_end_time'), '%Y-%m-%d %H:%M') if latest_record.get('train_end_time') else 'N/A'}
**é¢„æµ‹æ•°æ®æ¡æ•°**: {latest_record.get('predictions_count', 0)}æ¡"""
            else:
                data_range_info = f"""**ğŸ“Š Dataè¾“å…¥ä¿¡æ¯**

**æ•°æ®æ—¶é—´èŒƒå›´**: æš‚æ— æ•°æ®
**è®­ç»ƒç‰ˆæœ¬**: {latest_record.get('version', 'N/A')}
**è®­ç»ƒå®Œæˆæ—¶é—´**: {format_datetime_beijing(latest_record.get('train_end_time'), '%Y-%m-%d %H:%M') if latest_record.get('train_end_time') else 'N/A'}
**é¢„æµ‹æ•°æ®æ¡æ•°**: {latest_record.get('predictions_count', 0)}æ¡"""

            return data_range_info

        except Exception as e:
            logger.error(f"è·å–æ•°æ®èŒƒå›´ä¿¡æ¯å¤±è´¥: {e}")
            return "**ğŸ“Š Dataè¾“å…¥ä¿¡æ¯**\n\nè·å–æ•°æ®èŒƒå›´ä¿¡æ¯å¤±è´¥"

    def get_agent_decision_detail(self, decision_id: int) -> str:
        """è·å–Agentå†³ç­–è¯¦æƒ…"""
        try:
            with get_db() as db:
                decision = db.query(AgentDecision).filter(
                    AgentDecision.id == decision_id
                ).first()

                if not decision:
                    return "å†³ç­–è®°å½•ä¸å­˜åœ¨"

                # è·å–äº¤æ˜“è®¡åˆ’ä¿¡æ¯ä»¥æ˜¾ç¤ºäº¤æ˜“é™åˆ¶
                plan = db.query(TradingPlan).filter(
                    TradingPlan.id == decision.plan_id
                ).first()

                trading_limits_info = ""
                if plan and plan.trading_limits:
                    limits = plan.trading_limits
                    trading_limits_info = f"""
### ğŸ’° äº¤æ˜“é™åˆ¶é…ç½®

- **å¯ç”¨è´¦æˆ·èµ„é‡‘**: {limits.get('available_usdt_amount', 'N/A')} USDT
- **å¯ç”¨èµ„é‡‘æ¯”ä¾‹**: {limits.get('available_usdt_percentage', 'N/A')}%
- **å¹³æ‘Šæ“ä½œå•é‡**: {limits.get('avg_order_count', 'N/A')} ç¬”
- **æ­¢æŸæ¯”ä¾‹**: {limits.get('stop_loss_percentage', 'N/A')}%
- **æœ€å¤§æŒä»“**: {limits.get('max_position_size', 'N/A')}
- **æœ€å¤§è®¢å•é‡‘é¢**: {limits.get('max_order_amount', 'N/A')} USDT

"""

                detail = f"""
## ğŸ“‹ Agentå†³ç­–è¯¦æƒ… (ID: {decision.id})

**å†³ç­–æ—¶é—´**: {format_datetime_full_beijing(decision.decision_time)}
**å†³ç­–ç±»å‹**: `{decision.decision_type}`
**çŠ¶æ€**: `{decision.status}`
**ä½¿ç”¨æ¨¡å‹**: v{decision.training_record_id} | **LLM**: {decision.llm_model or 'N/A'}

{trading_limits_info}

---

### ğŸ’­ å†³ç­–ç†ç”±
{decision.reasoning or 'æ— '}

---

### ğŸ› ï¸ å·¥å…·è°ƒç”¨
{self._format_tool_calls(decision.tool_calls, decision.tool_results)}

---

### ğŸ“¦ å…³è”è®¢å•
{self._format_order_ids(decision.order_ids)}
"""
                return detail

        except Exception as e:
            logger.error(f"è·å–å†³ç­–è¯¦æƒ…å¤±è´¥: {e}")
            return f"è·å–å¤±è´¥: {str(e)}"

    def _format_tool_calls(self, tool_calls, tool_results) -> str:
        """æ ¼å¼åŒ–å·¥å…·è°ƒç”¨"""
        if not tool_calls:
            return "æ— å·¥å…·è°ƒç”¨"

        lines = []
        for i, call in enumerate(tool_calls, 1):
            tool_name = call.get('name', 'unknown')
            tool_args = call.get('arguments', {})
            result = tool_results[i-1] if tool_results and len(tool_results) >= i else {}

            lines.append(f"**{i}. {tool_name}**")
            lines.append(f"   - å‚æ•°: `{tool_args}`")
            lines.append(f"   - ç»“æœ: `{result}`")
            lines.append("")

        return "\n".join(lines)

    def _format_order_ids(self, order_ids) -> str:
        """æ ¼å¼åŒ–è®¢å•ID"""
        if not order_ids:
            return "æ— å…³è”è®¢å•"

        return ", ".join([f"`{oid}`" for oid in order_ids])

    def get_latest_agent_decision_output(self, plan_id: int):
        """
        è·å–æœ€æ–°çš„Agentå†³ç­–è¾“å‡ºï¼ˆChatbotæ ¼å¼ï¼‰ï¼ŒåŒ…å«æœ€æ–°çš„é¢„æµ‹æ•°æ®é¢„è§ˆ

        Returns:
            List[Dict]: Chatbot messages æ ¼å¼ [{"role": "assistant", "content": ...}]
        """
        try:
            with get_db() as db:
                # è·å–æœ€æ–°çš„Agentå†³ç­–
                decision = db.query(AgentDecision).filter(
                    AgentDecision.plan_id == plan_id
                ).order_by(desc(AgentDecision.decision_time)).first()

                # è·å–æœ€æ–°çš„å·²å®Œæˆè®­ç»ƒè®°å½•
                latest_training = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status == 'completed',
                        TrainingRecord.is_active == True
                    )
                ).order_by(desc(TrainingRecord.created_at)).first()

                # æ„å»ºè¾“å‡ºå†…å®¹
                output_parts = []

                # æ·»åŠ é¢„æµ‹æ•°æ®é¢„è§ˆéƒ¨åˆ†
                if latest_training:
                    # è·å–æœ€åä¸€æ¬¡æ¨ç†çš„é¢„æµ‹æ•°æ®
                    from sqlalchemy import func
                    latest_batch = db.query(
                        PredictionData.inference_batch_id,
                        func.max(PredictionData.created_at).label('max_time')
                    ).filter(
                        PredictionData.training_record_id == latest_training.id
                    ).group_by(
                        PredictionData.inference_batch_id
                    ).order_by(
                        func.max(PredictionData.created_at).desc()
                    ).first()

                    if latest_batch:
                        # è·å–è¯¥æ‰¹æ¬¡çš„æ‰€æœ‰é¢„æµ‹æ•°æ®
                        predictions_query = db.query(PredictionData).filter(
                            and_(
                                PredictionData.training_record_id == latest_training.id,
                                PredictionData.inference_batch_id == latest_batch.inference_batch_id
                            )
                        ).order_by(PredictionData.timestamp).all()

                        if predictions_query:
                            predictions = []
                            for pred in predictions_query:
                                predictions.append({
                                    'timestamp': pred.timestamp,
                                    'open': pred.open,
                                    'high': pred.high,
                                    'low': pred.low,
                                    'close': pred.close,
                                    'volume': pred.volume
                                })

                            # æ ¼å¼åŒ–é¢„æµ‹æ•°æ®é¢„è§ˆ
                            pred_output = self._format_prediction_preview(predictions, latest_batch.inference_batch_id, latest_training.version)
                            output_parts.append(pred_output)

                # æ·»åŠ AI Agentå†³ç­–ç»“æœéƒ¨åˆ†
                if decision:
                    decision_output = f"""## ğŸ¤– AI Agent æœ€æ–°æ¨ç†ç»“æœ

**å†³ç­–æ—¶é—´**: {format_datetime_full_beijing(decision.decision_time)}
**å†³ç­–ç±»å‹**: {decision.decision_type or 'N/A'}
**çŠ¶æ€**: {decision.status}
**ä½¿ç”¨æ¨¡å‹**: v{decision.training_record_id} | **LLM**: {decision.llm_model or 'N/A'}

---

### ğŸ’­ AIåˆ†æä¸æ¨ç†

{decision.reasoning or 'æ— '}

---

### ğŸ› ï¸ å·¥å…·è°ƒç”¨

"""
                    # æ ¼å¼åŒ–å·¥å…·è°ƒç”¨
                    if decision.tool_calls:
                        for i, call in enumerate(decision.tool_calls, 1):
                            tool_name = call.get('name', 'unknown')
                            tool_args = call.get('arguments', {})
                            decision_output += f"**{i}. {tool_name}**\n"
                            decision_output += f"   - å‚æ•°: `{tool_args}`\n"

                            # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                            if decision.tool_results and len(decision.tool_results) >= i:
                                result = decision.tool_results[i-1]
                                success = result.get('success', False)
                                status_emoji = 'âœ…' if success else 'âŒ'
                                decision_output += f"   - ç»“æœ: {status_emoji} {result.get('message', result.get('error', 'N/A'))}\n"
                            decision_output += "\n"
                    else:
                        decision_output += "æ— å·¥å…·è°ƒç”¨\n"

                    output_parts.append(decision_output)
                else:
                    # å¦‚æœæ²¡æœ‰å†³ç­–è®°å½•ï¼Œåªæ˜¾ç¤ºé¢„æµ‹æ•°æ®
                    if not output_parts:  # å¦‚æœä¹Ÿæ²¡æœ‰é¢„æµ‹æ•°æ®
                        output_parts.append("ç­‰å¾…æ¨ç†...\n\næš‚æ— AI Agentå†³ç­–è®°å½•")

                # åˆå¹¶æ‰€æœ‰è¾“å‡º
                combined_output = "\n\n---\n\n".join(output_parts)

                # è¿”å› messages æ ¼å¼
                return [{"role": "assistant", "content": combined_output}]

        except Exception as e:
            logger.error(f"è·å–æœ€æ–°Agentå†³ç­–è¾“å‡ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return [{"role": "assistant", "content": f"ç­‰å¾…æ¨ç†...\n\nâŒ è·å–å¤±è´¥: {str(e)}"}]

    def _format_prediction_preview(self, predictions: list, batch_id: str, version: str) -> str:
        """
        æ ¼å¼åŒ–é¢„æµ‹æ•°æ®é¢„è§ˆ

        Args:
            predictions: é¢„æµ‹æ•°æ®åˆ—è¡¨
            batch_id: æ¨ç†æ‰¹æ¬¡ID
            version: è®­ç»ƒç‰ˆæœ¬

        Returns:
            æ ¼å¼åŒ–åçš„é¢„æµ‹æ•°æ®é¢„è§ˆå­—ç¬¦ä¸²
        """
        try:
            if not predictions or len(predictions) == 0:
                return "## ğŸ“Š æœ€æ–°é¢„æµ‹æ•°æ®\n\næš‚æ— é¢„æµ‹æ•°æ®"

            # è®¡ç®—è¶‹åŠ¿
            first_pred = predictions[0]
            last_pred = predictions[-1]
            first_close = first_pred['close']
            last_close = last_pred['close']
            change_pct = ((last_close - first_close) / first_close) * 100

            # è·å–æ¦‚ç‡æŒ‡æ ‡ï¼ˆä»æ•°æ®åº“æŸ¥è¯¢ï¼‰
            upward_prob = None
            volatility_amp_prob = None
            sample_count = 1

            try:
                with get_db() as db:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªé¢„æµ‹æ•°æ®è·å–ç›¸å…³ä¿¡æ¯
                    pred_record = db.query(PredictionData).filter(
                        PredictionData.inference_batch_id == batch_id
                    ).first()

                    if pred_record:
                        upward_prob = pred_record.upward_probability
                        volatility_amp_prob = pred_record.volatility_amplification_probability
                        if pred_record.inference_params:
                            sample_count = pred_record.inference_params.get('sample_count', 1)
            except Exception as e:
                logger.error(f"è·å–æ¦‚ç‡æŒ‡æ ‡å¤±è´¥: {e}")

            # æ—¶é—´èŒƒå›´
            first_time = format_datetime_beijing(first_pred['timestamp'], '%Y-%m-%d %H:%M') if hasattr(first_pred['timestamp'], 'strftime') else str(first_pred['timestamp'])[:16]
            last_time = format_datetime_beijing(last_pred['timestamp'], '%Y-%m-%d %H:%M') if hasattr(last_pred['timestamp'], 'strftime') else str(last_pred['timestamp'])[:16]

            # ä»·æ ¼ç»Ÿè®¡
            close_prices = [p['close'] for p in predictions]
            min_close = min(close_prices)
            max_close = max(close_prices)

            # è¶‹åŠ¿åˆ¤æ–­
            trend = "ğŸ“ˆ ä¸Šæ¶¨è¶‹åŠ¿" if change_pct > 0 else "ğŸ“‰ ä¸‹è·Œè¶‹åŠ¿" if change_pct < 0 else "â¡ï¸ æ¨ªç›˜"
            trend_emoji = "ğŸ“ˆ" if change_pct > 0 else "ğŸ“‰" if change_pct < 0 else "â¡ï¸"

            # æ„å»ºè¾“å‡º
            output = f"""## ğŸ“Š æœ€æ–°é¢„æµ‹æ•°æ®é¢„è§ˆ

**æ‰¹æ¬¡ID**: {batch_id} | **è®­ç»ƒç‰ˆæœ¬**: {version}
**é¢„æµ‹å‘¨æœŸæ•°**: {len(predictions)} | **æ—¶é—´èŒƒå›´**: {first_time} ~ {last_time}

---

### ğŸ“ˆ ä»·æ ¼é¢„æµ‹

**å½“å‰ä»·æ ¼**: ${first_close:.4f}
**é¢„æµ‹ä»·æ ¼**: ${last_close:.4f}
**ä»·æ ¼åŒºé—´**: ${min_close:.4f} ~ ${max_close:.4f}
**é¢„æµ‹æ¶¨è·Œ**: {trend_emoji} {change_pct:+.2f}%
**è¶‹åŠ¿åˆ¤æ–­**: {trend}"""

            # æ·»åŠ æ¦‚ç‡æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
            if upward_prob is not None and volatility_amp_prob is not None:
                upward_percent = upward_prob * 100
                volatility_percent = volatility_amp_prob * 100

                # æ ¹æ®æ¦‚ç‡å€¼é€‰æ‹©è¡¨æƒ…å’Œé¢œè‰²
                if upward_percent >= 60:
                    upward_emoji = "ğŸ“ˆ"
                    upward_color = "green"
                elif upward_percent >= 40:
                    upward_emoji = "â¡ï¸"
                    upward_color = "orange"
                else:
                    upward_emoji = "ğŸ“‰"
                    upward_color = "red"

                if volatility_percent >= 60:
                    volatility_emoji = "âš¡"
                    volatility_color = "red"
                elif volatility_percent >= 40:
                    volatility_emoji = "ã€°ï¸"
                    volatility_color = "orange"
                else:
                    volatility_emoji = "ğŸ˜´"
                    volatility_color = "green"

                output += f"""

---

### ğŸ¯ æ¦‚ç‡æŒ‡æ ‡

<div style="display: flex; gap: 20px; margin: 10px 0;">
  <div style="flex: 1; padding: 15px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; color: white;">
    <div style="font-size: 14px; opacity: 0.9;">ä¸Šæ¶¨æ¦‚ç‡ï¼ˆæœªæ¥é¢„æµ‹æœŸï¼‰</div>
    <div style="font-size: 36px; font-weight: bold; margin: 10px 0;">{upward_emoji} {upward_percent:.1f}%</div>
    <div style="font-size: 12px; opacity: 0.8;">æ¨¡å‹å¯¹ä»·æ ¼ä¸Šæ¶¨çš„ç½®ä¿¡åº¦</div>
  </div>
  <div style="flex: 1; padding: 15px; background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); border-radius: 10px; color: white;">
    <div style="font-size: 14px; opacity: 0.9;">æ³¢åŠ¨æ€§æ”¾å¤§</div>
    <div style="font-size: 36px; font-weight: bold; margin: 10px 0;">{volatility_emoji} {volatility_percent:.1f}%</div>
    <div style="font-size: 12px; opacity: 0.8;">æœªæ¥æ³¢åŠ¨ç‡è¶…è¿‡å†å²çš„æ¦‚ç‡</div>
  </div>
</div>

**æ•°æ®æ¥æº**: åŸºäº {sample_count} æ¡è’™ç‰¹å¡ç½—è·¯å¾„"""

            # æ·»åŠ è¯¦ç»†é¢„æµ‹æ•°æ®é¢„è§ˆ
            output += f"""

---

### ğŸ“‹ é¢„æµ‹æ•°æ®è¯¦æƒ… (å‰10æ¡)

| åºå· | æ—¶é—´ | å¼€ç›˜ | æœ€é«˜ | æœ€ä½ | æ”¶ç›˜ |
|------|------|------|------|------|------|"""

            # æ˜¾ç¤ºå‰10æ¡è¯¦ç»†æ•°æ®
            for i, pred in enumerate(predictions[:10], 1):
                timestamp_str = format_datetime_short_beijing(pred['timestamp']) if hasattr(pred['timestamp'], 'strftime') else str(pred['timestamp'])[:16]
                output += f"\n| {i} | {timestamp_str} | ${pred['open']:.2f} | ${pred['high']:.2f} | ${pred['low']:.2f} | ${pred['close']:.2f} |"

            if len(predictions) > 10:
                output += f"\n... (å…±{len(predictions)}æ¡ï¼Œä»…æ˜¾ç¤ºå‰10æ¡)"

            output += f"""

---

**ğŸ’¡ æç¤º**: æ­¤é¢„æµ‹æ•°æ®å¯ç”¨äº AI Agent åˆ†æå’Œå†³ç­–ã€‚ç‚¹å‡»ã€Œæ‰‹åŠ¨æ¨ç†ã€æŒ‰é’®å¯ä»¥è®© AI Agent åŸºäºè¿™äº›æ•°æ®è¿›è¡Œäº¤æ˜“åˆ†æã€‚"""

            return output

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–é¢„æµ‹æ•°æ®é¢„è§ˆå¤±è´¥: {e}")
            return f"## ğŸ“Š æœ€æ–°é¢„æµ‹æ•°æ®\n\nâŒ æ ¼å¼åŒ–å¤±è´¥: {str(e)}"

    def get_finetune_params(self, plan_id: int) -> dict:
        """è·å–å¾®è°ƒå‚æ•°"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return {}
                return plan.finetune_params or {}
        except Exception as e:
            logger.error(f"è·å–å¾®è°ƒå‚æ•°å¤±è´¥: {e}")
            return {}

    def save_finetune_params(self, plan_id: int, params: dict) -> str:
        """ä¿å­˜å¾®è°ƒå‚æ•°"""
        try:
            with get_db() as db:
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'finetune_params': params
                })
                db.commit()
                logger.info(f"å¾®è°ƒå‚æ•°å·²ä¿å­˜: plan_id={plan_id}")
                return "âœ… å‚æ•°å·²ä¿å­˜"
        except Exception as e:
            logger.error(f"ä¿å­˜å¾®è°ƒå‚æ•°å¤±è´¥: {e}")
            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

    def get_llm_configs(self) -> list:
        """è·å–æ‰€æœ‰LLMé…ç½®"""
        try:
            with get_db() as db:
                from database.models import LLMConfig
                configs = db.query(LLMConfig).filter(LLMConfig.is_active == True).all()
                return [(f"{c.provider} - {c.model_name}", c.id) for c in configs]
        except Exception as e:
            logger.error(f"è·å–LLMé…ç½®å¤±è´¥: {e}")
            return []

    def get_prompt_templates(self) -> list:
        """è·å–æ‰€æœ‰æç¤ºè¯æ¨¡ç‰ˆ"""
        try:
            with get_db() as db:
                from database.models import AgentPromptTemplate
                templates = db.query(AgentPromptTemplate).filter(
                    AgentPromptTemplate.is_active == True
                ).all()
                return [(f"{t.name} ({t.category})", t.id) for t in templates]
        except Exception as e:
            logger.error(f"è·å–æç¤ºè¯æ¨¡ç‰ˆå¤±è´¥: {e}")
            return []

    def get_inference_params(self, plan_id: int) -> dict:
        """è·å–æ¨ç†å‚æ•°"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return {}

                finetune_params = plan.finetune_params or {}
                inference_config = finetune_params.get('inference', {})
                data_config = finetune_params.get('data', {})

                # ç¡®ä¿ç±»å‹è½¬æ¢ï¼šä»æ•°æ®åº“JSONBè¯»å–çš„æ•°å€¼å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢ä¸ºæ•°å­—
                return {
                    'lookback_window': int(data_config.get('lookback_window', 512)),
                    'predict_window': int(data_config.get('predict_window', 48)),
                    'temperature': float(inference_config.get('temperature', 1.0)),
                    'top_p': float(inference_config.get('top_p', 0.9)),
                    'sample_count': int(inference_config.get('sample_count', 30)),
                    'data_offset': int(inference_config.get('data_offset', 0))
                }
        except Exception as e:
            logger.error(f"è·å–æ¨ç†å‚æ•°å¤±è´¥: {e}")
            return {
                'lookback_window': 512,
                'predict_window': 48,
                'temperature': 1.0,
                'top_p': 0.9,
                'sample_count': 30,
                'data_offset': 0
            }

    def save_inference_params(
        self,
        plan_id: int,
        lookback_window: int,
        predict_window: int,
        temperature: float,
        top_p: float,
        sample_count: int,
        data_offset: int = 0
    ) -> str:
        """ä¿å­˜æ¨ç†å‚æ•°"""
        try:
            # éªŒè¯å‚æ•°èŒƒå›´
            if not (64 <= lookback_window <= 2048):
                return "âŒ Lookback Window å¿…é¡»åœ¨ 64 åˆ° 2048 ä¹‹é—´"

            if not (1 <= predict_window <= 512):
                return "âŒ Predict Window å¿…é¡»åœ¨ 1 åˆ° 512 ä¹‹é—´"

            if not (0.0 <= temperature <= 2.0):
                return "âŒ Temperature å¿…é¡»åœ¨ 0.0 åˆ° 2.0 ä¹‹é—´"

            if not (0.0 <= top_p <= 1.0):
                return "âŒ Top-p å¿…é¡»åœ¨ 0.0 åˆ° 1.0 ä¹‹é—´"

            if not (1 <= sample_count <= 100):
                return "âŒ Sample Count å¿…é¡»åœ¨ 1 åˆ° 100 ä¹‹é—´"

            if not (0 <= data_offset <= 1000):
                return "âŒ æ•°æ®åç§»å¿…é¡»åœ¨ 0 åˆ° 1000 ä¹‹é—´"

            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨"

                # è·å–ç°æœ‰çš„ finetune_params
                finetune_params = plan.finetune_params or {}
                if 'inference' not in finetune_params:
                    finetune_params['inference'] = {}
                if 'data' not in finetune_params:
                    finetune_params['data'] = {}

                # æ›´æ–°æ•°æ®çª—å£å‚æ•°ï¼ˆä¿å­˜åˆ° data é…ç½®ä¸­ï¼‰
                finetune_params['data']['lookback_window'] = int(lookback_window)
                finetune_params['data']['predict_window'] = int(predict_window)

                # æ›´æ–°æ¨ç†å‚æ•°
                finetune_params['inference']['temperature'] = float(temperature)
                finetune_params['inference']['top_p'] = float(top_p)
                finetune_params['inference']['sample_count'] = int(sample_count)
                finetune_params['inference']['data_offset'] = int(data_offset)

                # ä¿å­˜åˆ°æ•°æ®åº“
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'finetune_params': finetune_params
                })
                db.commit()

                logger.info(
                    f"æ¨ç†å‚æ•°å·²ä¿å­˜: plan_id={plan_id}, "
                    f"lookback={lookback_window}, predict={predict_window}, "
                    f"temperature={temperature}, top_p={top_p}, sample_count={sample_count}, data_offset={data_offset}"
                )
                return "âœ… æ¨ç†å‚æ•°å·²ä¿å­˜"
        except Exception as e:
            logger.error(f"ä¿å­˜æ¨ç†å‚æ•°å¤±è´¥: {e}")
            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

    def get_agent_config(self, plan_id: int) -> dict:
        """è·å–Agenté…ç½®"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return {}
                return {
                    'llm_config_id': plan.llm_config_id,
                    'agent_prompt': plan.agent_prompt or '',
                    'agent_tools_config': plan.agent_tools_config or {}
                }
        except Exception as e:
            logger.error(f"è·å–Agenté…ç½®å¤±è´¥: {e}")
            return {}

    def save_agent_config(self, plan_id: int, llm_config_id: int,
                         agent_prompt: str, tools_config: dict) -> str:
        """ä¿å­˜Agenté…ç½®"""
        try:
            with get_db() as db:
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'llm_config_id': llm_config_id,
                    'agent_prompt': agent_prompt,
                    'agent_tools_config': tools_config
                })
                db.commit()
                logger.info(f"Agenté…ç½®å·²ä¿å­˜: plan_id={plan_id}")
                return "âœ… Agenté…ç½®å·²ä¿å­˜"
        except Exception as e:
            logger.error(f"ä¿å­˜Agenté…ç½®å¤±è´¥: {e}")
            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

    def get_react_config(self, plan_id: int) -> dict:
        """è·å–ReActé…ç½®"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    # è¿”å›é»˜è®¤é…ç½®
                    return {
                        'max_iterations': 3,
                        'enable_thinking': True,
                        'tool_approval': False,
                        'thinking_style': 'è¯¦ç»†'
                    }

                react_config = plan.react_config or {}
                # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½æœ‰é»˜è®¤å€¼
                return {
                    'max_iterations': int(react_config.get('max_iterations', 3)),
                    'enable_thinking': bool(react_config.get('enable_thinking', True)),
                    'tool_approval': bool(react_config.get('tool_approval', False)),
                    'thinking_style': react_config.get('thinking_style', 'è¯¦ç»†')
                }
        except Exception as e:
            logger.error(f"è·å–ReActé…ç½®å¤±è´¥: {e}")
            return {
                'max_iterations': 3,
                'enable_thinking': True,
                'tool_approval': False,
                'thinking_style': 'è¯¦ç»†'
            }

    def save_react_config(self, plan_id: int, max_iterations: int, enable_thinking: bool,
                          tool_approval: bool, thinking_style: str) -> str:
        """ä¿å­˜ReActé…ç½®"""
        try:
            react_config = {
                'max_iterations': max_iterations,
                'enable_thinking': enable_thinking,
                'tool_approval': tool_approval,
                'thinking_style': thinking_style
            }

            with get_db() as db:
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'react_config': react_config
                })
                db.commit()
                logger.info(f"ReActé…ç½®å·²ä¿å­˜: plan_id={plan_id}, config={react_config}")
                return f"âœ… ReActé…ç½®å·²ä¿å­˜\n- æœ€å¤§æ¨ç†è½®æ•°: {max_iterations}\n- æ€è€ƒè¿‡ç¨‹æ˜¾ç¤º: {'å¯ç”¨' if enable_thinking else 'ç¦ç”¨'}\n- å·¥å…·å®¡æ‰¹: {'å¯ç”¨' if tool_approval else 'ç¦ç”¨'}\n- æ€è€ƒé£æ ¼: {thinking_style}"
        except Exception as e:
            logger.error(f"ä¿å­˜ReActé…ç½®å¤±è´¥: {e}")
            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

    def get_trading_limits_config(self, plan_id: int) -> dict:
        """è·å–äº¤æ˜“é™åˆ¶é…ç½®"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return {
                        'available_usdt_amount': 1000.0,
                        'available_usdt_percentage': 30.0,
                        'avg_order_count': 10,
                        'stop_loss_percentage': 20.0
                    }

                trading_limits = plan.trading_limits or {}
                # ç¡®ä¿ç±»å‹è½¬æ¢ï¼šä»æ•°æ®åº“JSONBè¯»å–çš„æ•°å€¼å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢ä¸ºæ•°å­—
                return {
                    'available_usdt_amount': float(trading_limits.get('available_usdt_amount', 1000.0)),
                    'available_usdt_percentage': float(trading_limits.get('available_usdt_percentage', 30.0)),
                    'avg_order_count': int(trading_limits.get('avg_order_count', 10)),
                    'stop_loss_percentage': float(trading_limits.get('stop_loss_percentage', 20.0))
                }
        except Exception as e:
            logger.error(f"è·å–äº¤æ˜“é™åˆ¶é…ç½®å¤±è´¥: {e}")
            return {
                'available_usdt_amount': 1000.0,
                'available_usdt_percentage': 30.0,
                'avg_order_count': 10,
                'stop_loss_percentage': 20.0
            }

    def save_trading_limits_config(
        self,
        plan_id: int,
        available_usdt_amount: float,
        available_usdt_percentage: float,
        avg_order_count: int,
        stop_loss_percentage: float
    ) -> str:
        """ä¿å­˜äº¤æ˜“é™åˆ¶é…ç½®"""
        try:
            # éªŒè¯å‚æ•°
            if available_usdt_amount < 0:
                return "âŒ å¯ç”¨USDTé‡‘é¢ä¸èƒ½ä¸ºè´Ÿæ•°"
            if not (0 <= available_usdt_percentage <= 100):
                return "âŒ å¯ç”¨èµ„é‡‘æ¯”ä¾‹å¿…é¡»åœ¨ 0% åˆ° 100% ä¹‹é—´"
            if avg_order_count < 1:
                return "âŒ å¹³æ‘Šå•é‡å¿…é¡»å¤§äº0"
            if not (0.1 <= stop_loss_percentage <= 100):
                return "âŒ æ­¢æŸæ¯”ä¾‹å¿…é¡»åœ¨ 0.1% åˆ° 100% ä¹‹é—´"

            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨"

                # è·å–ç°æœ‰çš„trading_limitsé…ç½®
                trading_limits = plan.trading_limits or {}

                # æ›´æ–°äº¤æ˜“é™åˆ¶é…ç½®
                trading_limits.update({
                    'available_usdt_amount': float(available_usdt_amount),
                    'available_usdt_percentage': float(available_usdt_percentage),
                    'avg_order_count': int(avg_order_count),
                    'stop_loss_percentage': float(stop_loss_percentage),
                    # ä¿ç•™åŸæœ‰çš„å…¼å®¹å­—æ®µ
                    'max_position_size': trading_limits.get('max_position_size', 1.0),
                    'max_order_amount': float(available_usdt_amount)
                })

                # ä¿å­˜åˆ°æ•°æ®åº“
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'trading_limits': trading_limits
                })
                db.commit()

                logger.info(
                    f"äº¤æ˜“é™åˆ¶é…ç½®å·²ä¿å­˜: plan_id={plan_id}, "
                    f"available_usdt={available_usdt_amount}, percentage={available_usdt_percentage}%, "
                    f"avg_orders={avg_order_count}, stop_loss={stop_loss_percentage}%"
                )
                return "âœ… äº¤æ˜“é™åˆ¶é…ç½®å·²ä¿å­˜"

        except Exception as e:
            logger.error(f"ä¿å­˜äº¤æ˜“é™åˆ¶é…ç½®å¤±è´¥: {e}")
            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

    def load_prompt_template(self, template_id: int) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡ç‰ˆå†…å®¹"""
        try:
            with get_db() as db:
                from database.models import AgentPromptTemplate
                template = db.query(AgentPromptTemplate).filter(
                    AgentPromptTemplate.id == template_id
                ).first()
                if template:
                    return template.content
                return ""
        except Exception as e:
            logger.error(f"åŠ è½½æç¤ºè¯æ¨¡ç‰ˆå¤±è´¥: {e}")
            return ""

    def get_automation_config(self, plan_id: int) -> dict:
        """è·å–è‡ªåŠ¨åŒ–é…ç½®ï¼ˆå››ä¸ªå¼€å…³å’Œæ—¶é—´è¡¨ï¼‰"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return {
                        'auto_finetune_enabled': False,
                        'auto_inference_enabled': False,
                        'auto_agent_enabled': False,
                        'auto_tool_execution_enabled': False,
                        'schedule': []
                    }
                return {
                    'auto_finetune_enabled': plan.auto_finetune_enabled or False,
                    'auto_inference_enabled': plan.auto_inference_enabled or False,
                    'auto_agent_enabled': plan.auto_agent_enabled or False,
                    'auto_tool_execution_enabled': plan.auto_tool_execution_enabled or False,
                    'schedule': plan.auto_finetune_schedule or []
                }
        except Exception as e:
            logger.error(f"è·å–è‡ªåŠ¨åŒ–é…ç½®å¤±è´¥: {e}")
            return {
                'auto_finetune_enabled': False,
                'auto_inference_enabled': False,
                'auto_agent_enabled': False,
                'auto_tool_execution_enabled': False,
                'schedule': []
            }

    def save_automation_config(self, plan_id: int, auto_finetune: bool, auto_inference: bool,
                               auto_agent: bool, auto_tool_execution: bool, schedule_times: str) -> str:
        """ä¿å­˜è‡ªåŠ¨åŒ–é…ç½®"""
        try:
            # è§£ææ—¶é—´è¡¨
            schedule_list = []
            if schedule_times and schedule_times.strip():
                time_parts = [t.strip() for t in schedule_times.split(',')]
                for time_str in time_parts:
                    # éªŒè¯æ—¶é—´æ ¼å¼ HH:MM
                    if len(time_str) == 5 and time_str.count(':') == 1:
                        try:
                            hour, minute = time_str.split(':')
                            if 0 <= int(hour) <= 23 and 0 <= int(minute) <= 59:
                                schedule_list.append(time_str)
                        except ValueError:
                            continue

            with get_db() as db:
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'auto_finetune_enabled': auto_finetune,
                    'auto_inference_enabled': auto_inference,
                    'auto_agent_enabled': auto_agent,
                    'auto_tool_execution_enabled': auto_tool_execution,
                    'auto_finetune_schedule': schedule_list
                })
                db.commit()
                logger.info(
                    f"è‡ªåŠ¨åŒ–é…ç½®å·²ä¿å­˜: plan_id={plan_id}, "
                    f"finetune={auto_finetune}, inference={auto_inference}, "
                    f"agent={auto_agent}, tool_exec={auto_tool_execution}, "
                    f"schedule={schedule_list}"
                )
                return f"âœ… è‡ªåŠ¨åŒ–é…ç½®å·²ä¿å­˜\nğŸ“… è®­ç»ƒæ—¶é—´è¡¨: {', '.join(schedule_list) if schedule_list else 'æœªé…ç½®'}"
        except Exception as e:
            logger.error(f"ä¿å­˜è‡ªåŠ¨åŒ–é…ç½®å¤±è´¥: {e}")
            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

    def get_automation_status_display(self, plan_id: int) -> str:
        """è·å–è‡ªåŠ¨åŒ–çŠ¶æ€æ˜¾ç¤º"""
        try:
            from services.automation_service import automation_service
            status = automation_service.get_automation_status(plan_id)

            if not status:
                return "### ğŸ“Š è‡ªåŠ¨åŒ–çŠ¶æ€\n\nâŒ æ— æ³•è·å–çŠ¶æ€ä¿¡æ¯"

            # æ„å»ºçŠ¶æ€æ˜¾ç¤º
            lines = ["### ğŸ“Š è‡ªåŠ¨åŒ–çŠ¶æ€"]
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

            # è‡ªåŠ¨åŒ–é…ç½®çŠ¶æ€
            lines.append("#### ğŸ¯ è‡ªåŠ¨åŒ–é…ç½®")
            finetune_status = "âœ…" if status.get('auto_finetune_enabled') else "âŒ"
            inference_status = "âœ…" if status.get('auto_inference_enabled') else "âŒ"
            agent_status = "âœ…" if status.get('auto_agent_enabled') else "âŒ"
            tool_status = "âœ…" if status.get('auto_tool_execution_enabled') else "âŒ"

            lines.append(f"- ğŸ§  è‡ªåŠ¨å¾®è°ƒè®­ç»ƒ: {finetune_status}")
            lines.append(f"- ğŸ”® è‡ªåŠ¨é¢„æµ‹æ¨ç†: {inference_status}")
            lines.append(f"- ğŸ¤– è‡ªåŠ¨Agentå†³ç­–: {agent_status}")
            lines.append(f"- âš¡ è‡ªåŠ¨å·¥å…·æ‰§è¡Œ: {tool_status}")

            # è°ƒåº¦å™¨çŠ¶æ€
            lines.append("")
            lines.append("#### ğŸ”„ è°ƒåº¦å™¨çŠ¶æ€")
            scheduler_emoji = "âœ…" if status.get('scheduler_running') else "âŒ"
            lines.append(f"- è°ƒåº¦å™¨è¿è¡ŒçŠ¶æ€: {scheduler_emoji}")

            if status.get('last_check_time'):
                last_check = format_datetime_full_beijing(status['last_check_time'])
                lines.append(f"- æœ€åæ£€æŸ¥æ—¶é—´: {last_check}")

            # å½“å‰ä»»åŠ¡çŠ¶æ€
            current_task = status.get('current_task', {})
            if current_task:
                lines.append("")
                lines.append("#### âš¡ å½“å‰ä»»åŠ¡")
                task_stage = current_task.get('stage', 'unknown')
                task_start = current_task.get('start_time')
                if task_start:
                    start_str = format_datetime_beijing(task_start, "%H:%M:%S")
                    lines.append(f"- ä»»åŠ¡é˜¶æ®µ: {task_stage}")
                    lines.append(f"- å¼€å§‹æ—¶é—´: {start_str}")
                    lines.append(f"- ä»»åŠ¡ID: {current_task.get('task_id', 'N/A')}")
            else:
                lines.append("")
                lines.append("#### âš¡ å½“å‰ä»»åŠ¡: æ— æ´»è·ƒä»»åŠ¡")

            # æœ€æ–°è®­ç»ƒè®°å½•
            latest_training = status.get('latest_auto_training')
            if latest_training:
                lines.append("")
                lines.append("#### ğŸ“ˆ æœ€æ–°è‡ªåŠ¨è®­ç»ƒ")
                lines.append(f"- è®­ç»ƒID: {latest_training['id']}")
                lines.append(f"- çŠ¶æ€: {latest_training['status']}")
                if latest_training['created_at']:
                    training_time = format_datetime_beijing(latest_training['created_at'], "%Y-%m-%d %H:%M")
                    lines.append(f"- è®­ç»ƒæ—¶é—´: {training_time}")

            # æ—¶é—´è¡¨é…ç½®
            schedule = status.get('auto_finetune_schedule', [])
            if schedule:
                lines.append("")
                lines.append("#### â° è®­ç»ƒæ—¶é—´è¡¨")
                for time_point in schedule:
                    lines.append(f"- {time_point}")

            return "\n".join(lines)

        except Exception as e:
            logger.error(f"è·å–è‡ªåŠ¨åŒ–çŠ¶æ€å¤±è´¥: {e}")
            return f"### ğŸ“Š è‡ªåŠ¨åŒ–çŠ¶æ€\n\nâŒ è·å–å¤±è´¥: {str(e)}"

    def get_scheduler_status_display(self) -> str:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€æ˜¾ç¤º"""
        try:
            from services.automation_service import automation_service
            running = automation_service.scheduler_running
            last_check = automation_service.last_check_time

            if running:
                status_emoji = "âœ… è¿è¡Œä¸­"
                status_text = "è°ƒåº¦å™¨æ­£åœ¨è¿è¡Œï¼Œä¼šæ¯åˆ†é’Ÿæ£€æŸ¥è‡ªåŠ¨åŒ–ä»»åŠ¡"
            else:
                status_emoji = "âŒ å·²åœæ­¢"
                status_text = "è°ƒåº¦å™¨å·²åœæ­¢ï¼Œä¸ä¼šè‡ªåŠ¨æ‰§è¡Œä»»åŠ¡"

            lines = [f"ğŸ”„ è°ƒåº¦å™¨çŠ¶æ€: {status_emoji}"]
            lines.append(status_text)

            if last_check:
                last_check_str = format_datetime_full_beijing(last_check)
                lines.append(f"æœ€åæ£€æŸ¥: {last_check_str}")

            return "\n".join(lines)

        except Exception as e:
            logger.error(f"è·å–è°ƒåº¦å™¨çŠ¶æ€å¤±è´¥: {e}")
            return "ğŸ”„ è°ƒåº¦å™¨çŠ¶æ€: âŒ è·å–å¤±è´¥"

    def start_automation_scheduler(self) -> str:
        """å¯åŠ¨è‡ªåŠ¨åŒ–è°ƒåº¦å™¨"""
        try:
            from services.automation_service import automation_service
            automation_service.start_scheduler()
            return "âœ… è‡ªåŠ¨åŒ–è°ƒåº¦å™¨å·²å¯åŠ¨"
        except Exception as e:
            logger.error(f"å¯åŠ¨è‡ªåŠ¨åŒ–è°ƒåº¦å™¨å¤±è´¥: {e}")
            return f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}"

    def stop_automation_scheduler(self) -> str:
        """åœæ­¢è‡ªåŠ¨åŒ–è°ƒåº¦å™¨"""
        try:
            from services.automation_service import automation_service
            automation_service.stop_scheduler()
            return "âœ… è‡ªåŠ¨åŒ–è°ƒåº¦å™¨å·²åœæ­¢"
        except Exception as e:
            logger.error(f"åœæ­¢è‡ªåŠ¨åŒ–è°ƒåº¦å™¨å¤±è´¥: {e}")
            return f"âŒ åœæ­¢å¤±è´¥: {str(e)}"

    def get_pending_tools_data(self, plan_id: int):
        """è·å–å¾…æ‰§è¡Œå·¥å…·æ•°æ®"""
        try:
            from services.automation_service import automation_service
            pending_tools = automation_service.get_pending_tool_executions(plan_id)

            data = []
            for tool in pending_tools:
                decision_time = format_datetime_full_beijing(tool.get('decision_time')) if tool.get('decision_time') else 'N/A'
                tool_name = tool.get('tool_name', 'N/A')
                tool_args = str(tool.get('tool_args', {})) if tool.get('tool_args') else '{}'
                status = tool.get('status', 'pending')

                # çŠ¶æ€æ˜ å°„
                status_map = {
                    'pending': 'â³ å¾…ç¡®è®¤',
                    'approved': 'âœ… å·²æ‰¹å‡†',
                    'rejected': 'âŒ å·²æ‹’ç»',
                    'executed': 'âœ… å·²æ‰§è¡Œ',
                    'failed': 'âŒ æ‰§è¡Œå¤±è´¥'
                }
                status_display = status_map.get(status, status)

                data.append([decision_time, tool_name, tool_args, status_display])

            return data

        except Exception as e:
            logger.error(f"è·å–å¾…æ‰§è¡Œå·¥å…·å¤±è´¥: {e}")
            return []

    def handle_pending_tool_action(self, plan_id: int, action: str, selected_row: dict) -> str:
        """å¤„ç†å¾…æ‰§è¡Œå·¥å…·æ“ä½œ"""
        try:
            if not selected_row or len(selected_row) < 2:
                return "âŒ è¯·é€‰æ‹©è¦æ“ä½œçš„å·¥å…·è®°å½•"

            decision_id = selected_row.get('decision_id')
            tool_name = selected_row.get('tool_name')

            if not decision_id or not tool_name:
                return "âŒ æ— æ•ˆçš„å·¥å…·è®°å½•"

            from services.automation_service import automation_service

            if action == "approve":
                result = automation_service.approve_pending_tool(plan_id, decision_id, tool_name)
            elif action == "reject":
                result = automation_service.reject_pending_tool(plan_id, decision_id, tool_name)
            else:
                return "âŒ æ— æ•ˆçš„æ“ä½œç±»å‹"

            return result

        except Exception as e:
            logger.error(f"å¤„ç†å·¥å…·æ“ä½œå¤±è´¥: {e}")
            return f"âŒ æ“ä½œå¤±è´¥: {str(e)}"

    def get_finetune_schedule(self, plan_id: int) -> list:
        """è·å–è‡ªåŠ¨å¾®è°ƒæ—¶é—´è¡¨"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return []
                return plan.auto_finetune_schedule or []
        except Exception as e:
            logger.error(f"è·å–è‡ªåŠ¨å¾®è°ƒæ—¶é—´è¡¨å¤±è´¥: {e}")
            return []

    def add_finetune_schedule_time(self, plan_id: int, time_str: str) -> tuple:
        """
        æ·»åŠ è‡ªåŠ¨å¾®è°ƒæ—¶é—´ç‚¹

        Args:
            plan_id: è®¡åˆ’ID
            time_str: æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼ HH:MM

        Returns:
            (ç»“æœæ¶ˆæ¯, æ›´æ–°åçš„æ—¶é—´è¡¨åˆ—è¡¨)
        """
        try:
            # éªŒè¯æ—¶é—´æ ¼å¼
            import re
            if not re.match(r'^\d{2}:\d{2}$', time_str):
                return "âŒ æ—¶é—´æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ HH:MM æ ¼å¼", []

            hour, minute = map(int, time_str.split(':'))
            if not (0 <= hour <= 23 and 0 <= minute <= 59):
                return "âŒ æ—¶é—´èŒƒå›´é”™è¯¯ï¼Œå°æ—¶åº”ä¸º 00-23ï¼Œåˆ†é’Ÿåº”ä¸º 00-59", []

            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨", []

                schedule = plan.auto_finetune_schedule or []

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if time_str in schedule:
                    return f"âš ï¸ æ—¶é—´ç‚¹ {time_str} å·²å­˜åœ¨", schedule

                # æ·»åŠ å¹¶æ’åº
                schedule.append(time_str)
                schedule.sort()

                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'auto_finetune_schedule': schedule
                })
                db.commit()

                logger.info(f"å·²æ·»åŠ è‡ªåŠ¨å¾®è°ƒæ—¶é—´ç‚¹: plan_id={plan_id}, time={time_str}")
                return f"âœ… å·²æ·»åŠ æ—¶é—´ç‚¹ {time_str}", schedule

        except Exception as e:
            logger.error(f"æ·»åŠ è‡ªåŠ¨å¾®è°ƒæ—¶é—´ç‚¹å¤±è´¥: {e}")
            return f"âŒ æ·»åŠ å¤±è´¥: {str(e)}", []

    def remove_finetune_schedule_time(self, plan_id: int, time_str: str) -> tuple:
        """
        åˆ é™¤è‡ªåŠ¨å¾®è°ƒæ—¶é—´ç‚¹

        Args:
            plan_id: è®¡åˆ’ID
            time_str: æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼ HH:MM

        Returns:
            (ç»“æœæ¶ˆæ¯, æ›´æ–°åçš„æ—¶é—´è¡¨åˆ—è¡¨)
        """
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨", []

                schedule = plan.auto_finetune_schedule or []

                if time_str not in schedule:
                    return f"âš ï¸ æ—¶é—´ç‚¹ {time_str} ä¸å­˜åœ¨", schedule

                schedule.remove(time_str)

                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'auto_finetune_schedule': schedule
                })
                db.commit()

                logger.info(f"å·²åˆ é™¤è‡ªåŠ¨å¾®è°ƒæ—¶é—´ç‚¹: plan_id={plan_id}, time={time_str}")
                return f"âœ… å·²åˆ é™¤æ—¶é—´ç‚¹ {time_str}", schedule

        except Exception as e:
            logger.error(f"åˆ é™¤è‡ªåŠ¨å¾®è°ƒæ—¶é—´ç‚¹å¤±è´¥: {e}")
            return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}", []

    def get_data_date_range(self, inst_id: str, interval: str):
        """
        è·å–Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´

        Returns:
            (min_date, max_date, count)
        """
        try:
            with get_db() as db:
                result = db.query(
                    func.min(KlineData.timestamp).label('min_date'),
                    func.max(KlineData.timestamp).label('max_date'),
                    func.count(KlineData.id).label('count')
                ).filter(
                    and_(
                        KlineData.inst_id == inst_id,
                        KlineData.interval == interval
                    )
                ).first()

                if result and result.min_date and result.max_date:
                    return result.min_date, result.max_date, result.count
                else:
                    return None, None, 0

        except Exception as e:
            logger.error(f"è·å–æ—¥æœŸèŒƒå›´å¤±è´¥: {e}")
            return None, None, 0

    def save_training_data_config(self, plan_id: int, start_date_str: str, end_date_str: str) -> tuple:
        """
        ä¿å­˜è®­ç»ƒæ•°æ®èŒƒå›´é…ç½®

        Args:
            plan_id: è®¡åˆ’ID
            start_date_str: å¼€å§‹æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
            end_date_str: ç»“æŸæ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)

        Returns:
            (ç»“æœæ¶ˆæ¯, æ•°æ®ç»Ÿè®¡ä¿¡æ¯)
        """
        try:
            from datetime import datetime

            # è§£ææ—¥æœŸ
            start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
            end_date = datetime.strptime(end_date_str, '%Y-%m-%d')

            if start_date >= end_date:
                return "âŒ å¼€å§‹æ—¥æœŸå¿…é¡»æ—©äºç»“æŸæ—¥æœŸ", ""

            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨", ""

                # ç»Ÿè®¡æ•°æ®é‡
                data_count = db.query(func.count(KlineData.id)).filter(
                    and_(
                        KlineData.inst_id == plan.inst_id,
                        KlineData.interval == plan.interval,
                        KlineData.timestamp >= start_date,
                        KlineData.timestamp <= end_date
                    )
                ).scalar()

                if data_count == 0:
                    return f"âš ï¸ è¯¥æ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ•°æ®", ""

                # è·å–ç°æœ‰çš„ finetune_params
                finetune_params = plan.finetune_params or {}
                if 'data' not in finetune_params:
                    finetune_params['data'] = {}

                # æ›´æ–°æ•°æ®èŒƒå›´é…ç½®
                finetune_params['data']['train_start_date'] = start_date_str
                finetune_params['data']['train_end_date'] = end_date_str

                # ä¿å­˜åˆ°æ•°æ®åº“
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'finetune_params': finetune_params,
                    'data_start_time': start_date,
                    'data_end_time': end_date
                })
                db.commit()

                logger.info(f"è®­ç»ƒæ•°æ®é…ç½®å·²ä¿å­˜: plan_id={plan_id}, range={start_date_str} to {end_date_str}, count={data_count}")

                # æ„å»ºç»Ÿè®¡ä¿¡æ¯
                stats_info = f"""**å·²é…ç½®è®­ç»ƒæ•°æ®èŒƒå›´**

ğŸ“… **æ—¥æœŸ**: {start_date_str} è‡³ {end_date_str}
ğŸ“Š **æ•°æ®ç‚¹**: {data_count} æ¡
âœ… **çŠ¶æ€**: é…ç½®å·²ä¿å­˜
"""
                return "âœ… è®­ç»ƒæ•°æ®é…ç½®å·²ä¿å­˜", stats_info

        except ValueError as e:
            return f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}", ""
        except Exception as e:
            logger.error(f"ä¿å­˜è®­ç»ƒæ•°æ®é…ç½®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}", ""

    def get_training_data_stats(self, plan_id: int) -> str:
        """
        è·å–è®­ç»ƒæ•°æ®ç»Ÿè®¡ä¿¡æ¯

        Args:
            plan_id: è®¡åˆ’ID

        Returns:
            str - Markdown æ ¼å¼çš„ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "**æ•°æ®ç»Ÿè®¡**: è®¡åˆ’ä¸å­˜åœ¨"

                # ä» finetune_params ä¸­è·å–é…ç½®çš„èŒƒå›´
                finetune_params = plan.finetune_params or {}
                data_config = finetune_params.get('data', {})
                train_start_date_str = data_config.get('train_start_date')
                train_end_date_str = data_config.get('train_end_date')

                # è·å–æ•°æ®åº“ä¸­çš„å®é™…èŒƒå›´
                min_date, max_date, total_count = self.get_data_date_range(plan.inst_id, plan.interval)

                if min_date is None or max_date is None:
                    return "**æ•°æ®ç»Ÿè®¡**: æš‚æ— æ•°æ®"

                # å¦‚æœæœ‰é…ç½®çš„è®­ç»ƒèŒƒå›´ï¼Œç»Ÿè®¡è¯¥èŒƒå›´å†…çš„æ•°æ®é‡
                if train_start_date_str and train_end_date_str:
                    from datetime import datetime
                    train_start = datetime.strptime(train_start_date_str, '%Y-%m-%d')
                    train_end = datetime.strptime(train_end_date_str, '%Y-%m-%d')

                    train_data_count = db.query(func.count(KlineData.id)).filter(
                        and_(
                            KlineData.inst_id == plan.inst_id,
                            KlineData.interval == plan.interval,
                            KlineData.timestamp >= train_start,
                            KlineData.timestamp <= train_end
                        )
                    ).scalar()

                    return f"""**è®­ç»ƒæ•°æ®ç»Ÿè®¡**

ğŸ“… **é…ç½®èŒƒå›´**: {train_start_date_str} ~ {train_end_date_str}
ğŸ“Š **è®­ç»ƒæ•°æ®ç‚¹**: {train_data_count} æ¡

---

ğŸ“… **å…¨éƒ¨æ•°æ®**: {format_datetime_beijing(min_date, '%Y-%m-%d')} ~ {format_datetime_beijing(max_date, '%Y-%m-%d')}
ğŸ“Š **æ€»æ•°æ®ç‚¹**: {total_count} æ¡
"""
                else:
                    return f"""**æ•°æ®ç»Ÿè®¡**

ğŸ“… **å…¨éƒ¨æ•°æ®**: {format_datetime_beijing(min_date, '%Y-%m-%d')} ~ {format_datetime_beijing(max_date, '%Y-%m-%d')}
ğŸ“Š **æ€»æ•°æ®ç‚¹**: {total_count} æ¡

âš ï¸ **æœªé…ç½®è®­ç»ƒèŒƒå›´**
"""

        except Exception as e:
            logger.error(f"è·å–è®­ç»ƒæ•°æ®ç»Ÿè®¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"**æ•°æ®ç»Ÿè®¡**: è·å–å¤±è´¥ - {str(e)}"

    def get_probability_indicators(self, plan_id: int) -> str:
        """
        è·å–æœ€æ–°é¢„æµ‹çš„æ¦‚ç‡æŒ‡æ ‡ï¼ˆä¸Šæ¶¨æ¦‚ç‡ã€æ³¢åŠ¨æ€§æ”¾å¤§æ¦‚ç‡ï¼‰

        Args:
            plan_id: è®¡åˆ’ID

        Returns:
            str - Markdown æ ¼å¼çš„æ¦‚ç‡æŒ‡æ ‡å±•ç¤º
        """
        try:
            with get_db() as db:
                # è·å–æœ€æ–°çš„å·²å®Œæˆè®­ç»ƒè®°å½•
                latest_training = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status == 'completed',
                        TrainingRecord.is_active == True
                    )
                ).order_by(desc(TrainingRecord.created_at)).first()

                if not latest_training:
                    return """
### ğŸ“Š æ¦‚ç‡æŒ‡æ ‡

æš‚æ— æ•°æ®ï¼ˆå°šæœªå®Œæˆæ¨ç†ï¼‰
"""

                # è·å–è¯¥è®­ç»ƒè®°å½•çš„æœ€æ–°ä¸€æ¡é¢„æµ‹æ•°æ®ï¼ˆæ¦‚ç‡æŒ‡æ ‡å¯¹æ‰€æœ‰æ—¶é—´ç‚¹ç›¸åŒï¼‰
                prediction = db.query(PredictionData).filter(
                    PredictionData.training_record_id == latest_training.id
                ).order_by(PredictionData.timestamp.desc()).first()

                if not prediction:
                    return """
### ğŸ“Š æ¦‚ç‡æŒ‡æ ‡

æš‚æ— æ•°æ®ï¼ˆå°šæœªå®Œæˆæ¨ç†ï¼‰
"""

                # è·å–æ¦‚ç‡æŒ‡æ ‡
                upward_prob = prediction.upward_probability
                volatility_amp_prob = prediction.volatility_amplification_probability

                # å¦‚æœæ²¡æœ‰æ¦‚ç‡æ•°æ®ï¼ˆæ—§ç‰ˆæœ¬æ¨ç†ç»“æœï¼‰
                if upward_prob is None or volatility_amp_prob is None:
                    return """
### ğŸ“Š æ¦‚ç‡æŒ‡æ ‡

âš ï¸ **å½“å‰é¢„æµ‹æ•°æ®ä¸åŒ…å«æ¦‚ç‡æŒ‡æ ‡**

è¯·é‡æ–°æ‰§è¡Œæ¨ç†ä»¥è·å–æœ€æ–°çš„æ¦‚ç‡æŒ‡æ ‡ï¼ˆéœ€è¦å¤šè·¯å¾„è’™ç‰¹å¡ç½—é‡‡æ ·ï¼‰
"""

                # æ ¼å¼åŒ–æ˜¾ç¤º
                upward_percent = upward_prob * 100
                volatility_percent = volatility_amp_prob * 100

                # æ ¹æ®æ¦‚ç‡å€¼é€‰æ‹©è¡¨æƒ…å’Œé¢œè‰²
                if upward_percent >= 60:
                    upward_emoji = "ğŸ“ˆ"
                    upward_color = "green"
                elif upward_percent >= 40:
                    upward_emoji = "â¡ï¸"
                    upward_color = "orange"
                else:
                    upward_emoji = "ğŸ“‰"
                    upward_color = "red"

                if volatility_percent >= 60:
                    volatility_emoji = "âš¡"
                    volatility_color = "red"
                elif volatility_percent >= 40:
                    volatility_emoji = "ã€°ï¸"
                    volatility_color = "orange"
                else:
                    volatility_emoji = "ğŸ˜´"
                    volatility_color = "green"

                return f"""
### ğŸ“Š æ¦‚ç‡æŒ‡æ ‡

<div style="display: flex; gap: 20px; margin: 10px 0;">
  <div style="flex: 1; padding: 15px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; color: white;">
    <div style="font-size: 14px; opacity: 0.9;">ä¸Šæ¶¨æ¦‚ç‡ï¼ˆæœªæ¥é¢„æµ‹æœŸï¼‰</div>
    <div style="font-size: 36px; font-weight: bold; margin: 10px 0;">{upward_emoji} {upward_percent:.1f}%</div>
    <div style="font-size: 12px; opacity: 0.8;">æ¨¡å‹å¯¹ä»·æ ¼ä¸Šæ¶¨çš„ç½®ä¿¡åº¦</div>
  </div>
  <div style="flex: 1; padding: 15px; background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); border-radius: 10px; color: white;">
    <div style="font-size: 14px; opacity: 0.9;">æ³¢åŠ¨æ€§æ”¾å¤§</div>
    <div style="font-size: 36px; font-weight: bold; margin: 10px 0;">{volatility_emoji} {volatility_percent:.1f}%</div>
    <div style="font-size: 12px; opacity: 0.8;">æœªæ¥æ³¢åŠ¨ç‡è¶…è¿‡å†å²çš„æ¦‚ç‡</div>
  </div>
</div>

**æ•°æ®æ¥æº**: è®­ç»ƒç‰ˆæœ¬ v{latest_training.id} | åŸºäº {prediction.inference_params.get('sample_count', 1)} æ¡è’™ç‰¹å¡ç½—è·¯å¾„
"""

        except Exception as e:
            logger.error(f"è·å–æ¦‚ç‡æŒ‡æ ‡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"""
### ğŸ“Š æ¦‚ç‡æŒ‡æ ‡

âŒ è·å–å¤±è´¥: {str(e)}
"""

    def set_training_date_range(self, inst_id: str, interval: str, days: int):
        """
        è®¾ç½®è®­ç»ƒæ•°æ®èŒƒå›´ï¼ˆå¿«æ·æŒ‰é’®ï¼‰

        Args:
            inst_id: äº¤æ˜“å¯¹
            interval: æ—¶é—´é¢—ç²’åº¦
            days: æœ€è¿‘å¤šå°‘å¤©

        Returns:
            (æ•°æ®èŒƒå›´ä¿¡æ¯, å¼€å§‹æ—¥æœŸ, ç»“æŸæ—¥æœŸ)
        """
        try:
            from datetime import timedelta
            min_date, max_date, count = self.get_data_date_range(inst_id, interval)

            if min_date is None or max_date is None:
                return (
                    "âš ï¸ **æ•°æ®èŒƒå›´**: æœªæ‰¾åˆ°æ•°æ®",
                    "",
                    ""
                )

            # è®¡ç®—å¼€å§‹æ—¥æœŸï¼ˆä»æœ€æ–°æ—¥æœŸå¾€å‰æ¨Nå¤©ï¼‰
            start_date = max_date - timedelta(days=days)

            # ç¡®ä¿å¼€å§‹æ—¥æœŸä¸æ—©äºæ•°æ®æœ€æ—©æ—¥æœŸ
            if start_date < min_date:
                start_date = min_date

            info = f"""
**æ•°æ®èŒƒå›´**: {format_datetime_beijing(min_date, '%Y-%m-%d')} è‡³ {format_datetime_beijing(max_date, '%Y-%m-%d')} (å…± {count} æ¡)

**å·²é€‰æ‹©**: æœ€è¿‘ {days} å¤© ({format_datetime_beijing(start_date, '%Y-%m-%d')} è‡³ {format_datetime_beijing(max_date, '%Y-%m-%d')})
"""

            return (
                info,
                format_datetime_beijing(start_date, '%Y-%m-%d'),
                format_datetime_beijing(max_date, '%Y-%m-%d')
            )

        except Exception as e:
            logger.error(f"è®¾ç½®è®­ç»ƒæ—¥æœŸèŒƒå›´å¤±è´¥: {e}")
            return (
                f"âŒ è®¾ç½®å¤±è´¥: {str(e)}",
                "",
                ""
            )

    async def manual_inference_async(self, plan_id: int) -> str:
        """æ‰‹åŠ¨æ‰§è¡ŒAI Agentæ¨ç†"""
        try:
            from services.agent_decision_service import AgentDecisionService
            from database.models import LLMConfig, AgentDecision
            import json

            # è·å–è®¡åˆ’é…ç½®
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨"

                # æ£€æŸ¥LLMé…ç½®
                if not plan.llm_config_id:
                    return "âŒ æœªé…ç½®LLMï¼Œè¯·å…ˆåœ¨Agenté…ç½®ä¸­é€‰æ‹©LLM"

                llm_config = db.query(LLMConfig).filter(LLMConfig.id == plan.llm_config_id).first()
                if not llm_config:
                    return "âŒ LLMé…ç½®ä¸å­˜åœ¨"

            # è·å–æœ€æ–°çš„è®­ç»ƒè®°å½•
            with get_db() as db:
                latest_training = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status == 'completed',
                        TrainingRecord.is_active == True
                    )
                ).order_by(desc(TrainingRecord.created_at)).first()

                if not latest_training:
                    return "âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒè®°å½•ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ"

            # è§¦å‘AI Agentå†³ç­–
            decision_id = await AgentDecisionService.trigger_decision(plan_id, latest_training.id)

            if not decision_id:
                return "âŒ AI Agentå†³ç­–è§¦å‘å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—"

            # è·å–å†³ç­–ç»“æœ
            with get_db() as db:
                decision = db.query(AgentDecision).filter(
                    AgentDecision.id == decision_id
                ).first()

                if not decision:
                    return "âŒ æ— æ³•è·å–å†³ç­–ç»“æœ"

            # æ„å»ºè¿”å›ç»“æœ
            result_md = f"""## âœ… AI Agent æ¨ç†å®Œæˆ

**å†³ç­–æ—¶é—´**: {format_datetime_full_beijing(decision.decision_time)}

**LLM**: {llm_config.provider} / {llm_config.model_name}

**è®­ç»ƒç‰ˆæœ¬**: v{latest_training.version}

---

### ğŸ’­ AIåˆ†æä¸æ¨ç†

{decision.reasoning or 'æ— '}

---

### ğŸ› ï¸ å·¥å…·è°ƒç”¨

"""
            tool_calls = decision.tool_calls or []
            if tool_calls:
                for i, call in enumerate(tool_calls, 1):
                    result_md += f"**{i}. {call.get('name', 'unknown')}**\n"
                    result_md += f"   - å‚æ•°: `{call.get('arguments', {})}`\n"

                    # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                    if decision.tool_results and len(decision.tool_results) >= i:
                        result = decision.tool_results[i-1]
                        success = result.get('success', False)
                        status_emoji = 'âœ…' if success else 'âŒ'
                        result_md += f"   - ç»“æœ: {status_emoji} {result.get('message', result.get('error', 'N/A'))}\n"
                    result_md += "\n"
            else:
                result_md += "æ— å·¥å…·è°ƒç”¨\n"

            return result_md

        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ æ¨ç†å¤±è´¥: {str(e)}"

    async def manual_inference_stream(self, plan_id: int):
        """æ‰‹åŠ¨æ‰§è¡ŒAI Agentæ¨ç†ï¼ˆæµå¼è¾“å‡ºï¼‰"""
        try:
            # å‘é€å¼€å§‹æ¶ˆæ¯
            yield [{"role": "assistant", "content": "ğŸ¤– æ­£åœ¨å¯åŠ¨ AI Agent ReAct æ¨ç†..."}]

            # ä½¿ç”¨ ReAct+Tool Use æµå¼æ–¹æ³•
            from services.agent_decision_service import AgentDecisionService
            from database.models import TrainingRecord
            from database.db import get_db
            from sqlalchemy import and_, desc

            # è·å–è®¡åˆ’ä¿¡æ¯
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    yield [{"role": "assistant", "content": "âŒ è®¡åˆ’ä¸å­˜åœ¨"}]
                    return

                # è·å–æœ€æ–°çš„è®­ç»ƒè®°å½•
                latest_training = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status == 'completed',
                        TrainingRecord.is_active == True
                    )
                ).order_by(desc(TrainingRecord.created_at)).first()

                if not latest_training:
                    yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒè®°å½•ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ"}]
                    return

            # ä½¿ç”¨ AgentDecisionService çš„ ReAct+Tool Use æµå¼æ–¹æ³•
            async for message in AgentDecisionService.react_tool_use_stream(
                plan_id=plan_id,
                training_id=latest_training.id if latest_training else None
            ):
                yield message

        except Exception as e:
            logger.error(f"ReActæ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield [{"role": "assistant", "content": f"âŒ æ¨ç†è¿‡ç¨‹å‡ºé”™: {str(e)}"}]

    async def continue_inference_stream(self, plan_id: int):
        """ç»§ç»­AI Agentæ¨ç†ï¼ˆç”¨æˆ·ç¡®è®¤å·¥å…·åï¼‰"""
        try:
            # å‘é€ç»§ç»­æ¶ˆæ¯
            yield [{"role": "assistant", "content": "ğŸ”„ ç»§ç»­æ‰§è¡Œ AI Agent æ¨ç†..."}]

            from services.agent_decision_service import AgentDecisionService
            from services.agent_confirmation_service import confirmation_service

            # è·å–å¾…ç¡®è®¤çš„å·¥å…·å¹¶æ‰§è¡Œ
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    yield [{"role": "assistant", "content": "âŒ è®¡åˆ’ä¸å­˜åœ¨"}]
                    return

                # è·å–å·²ç¡®è®¤çš„å·¥å…·
                confirmed_tools = confirmation_service.get_confirmed_tools(plan_id)

                if not confirmed_tools:
                    yield [{"role": "assistant", "content": "âš ï¸ æ²¡æœ‰å¾…æ‰§è¡Œçš„å·²ç¡®è®¤å·¥å…·"}]
                    return

                yield [{"role": "assistant", "content": f"ğŸ“‹ æ‰§è¡Œ {len(confirmed_tools)} ä¸ªå·²ç¡®è®¤çš„å·¥å…·è°ƒç”¨..."}]

                # æ‰§è¡Œå·²ç¡®è®¤çš„å·¥å…·
                for tool in confirmed_tools:
                    tool_name = tool['tool_name']
                    tool_args = tool['tool_args']

                    yield [{"role": "assistant", "content": f"\nğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}"}]

                    # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œï¼ˆè¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„å·¥å…·æ‰§è¡Œï¼‰
                    from services.agent_tool_executor import AgentToolExecutor
                    executor = AgentToolExecutor(
                        api_key="test",  # è¿™é‡Œåº”è¯¥ä»é…ç½®ä¸­è·å–
                        secret_key="test",
                        passphrase="test",
                        is_demo=True
                    )

                    result = await executor.execute_tool(tool_name, tool_args)

                    if result['success']:
                        yield [{"role": "assistant", "content": f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ: {result.get('message', 'OK')}"}]
                    else:
                        yield [{"role": "assistant", "content": f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {result.get('error', 'Unknown error')}"}]

                yield [{"role": "assistant", "content": "\nğŸ‰ AI Agent æ¨ç†å®Œæˆï¼"}]

        except Exception as e:
            logger.error(f"ç»§ç»­æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield [{"role": "assistant", "content": f"âŒ ç»§ç»­æ¨ç†å¤±è´¥: {str(e)}"}]

    def _build_system_message(self, plan):
        """æ„å»ºç³»ç»Ÿæ¶ˆæ¯"""
        if plan.agent_prompt:
            return plan.agent_prompt

        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“AIåŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æå¸‚åœºæ•°æ®å¹¶åšå‡ºäº¤æ˜“å†³ç­–ã€‚

**äº¤æ˜“å¯¹**: {plan.inst_id}
**æ—¶é—´å‘¨æœŸ**: {plan.interval}
**ç¯å¢ƒ**: {'æ¨¡æ‹Ÿç›˜' if plan.is_demo else 'å®ç›˜'}

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åˆ†æKronosæ¨¡å‹çš„ä»·æ ¼é¢„æµ‹æ•°æ®
2. ç»“åˆå½“å‰è´¦æˆ·çŠ¶æ€å’ŒæŒä»“æƒ…å†µ
3. åšå‡ºåˆç†çš„äº¤æ˜“å†³ç­–ï¼ˆä¹°å…¥/å–å‡º/æŒæœ‰ï¼‰
4. å¿…è¦æ—¶è°ƒç”¨å·¥å…·æ‰§è¡Œäº¤æ˜“æ“ä½œ

è¯·å§‹ç»ˆè°¨æ…å†³ç­–ï¼Œæ§åˆ¶é£é™©ã€‚
"""

    def _build_user_message_with_prediction(self, plan, predictions):
        """æ„å»ºåŒ…å«é¢„æµ‹æ•°æ®çš„ç”¨æˆ·æ¶ˆæ¯"""
        if not predictions or len(predictions) == 0:
            return "âš ï¸ æ— é¢„æµ‹æ•°æ®å¯ç”¨ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒå’Œæ¨ç†ã€‚"

        # è®¡ç®—è¶‹åŠ¿
        first_close = predictions[0]['close']
        last_close = predictions[-1]['close']
        change_pct = ((last_close - first_close) / first_close) * 100

        # æå–å…³é”®æ•°æ®ç‚¹
        first_5 = predictions[:5] if len(predictions) >= 5 else predictions
        last_5 = predictions[-5:] if len(predictions) >= 5 else []

        # æ—¶é—´èŒƒå›´
        first_time = format_datetime_beijing(predictions[0]['timestamp'], '%Y-%m-%d %H:%M') if hasattr(predictions[0]['timestamp'], 'strftime') else str(predictions[0]['timestamp'])[:16]
        last_time = format_datetime_beijing(predictions[-1]['timestamp'], '%Y-%m-%d %H:%M') if hasattr(predictions[-1]['timestamp'], 'strftime') else str(predictions[-1]['timestamp'])[:16]

        # ä»·æ ¼ç»Ÿè®¡
        close_prices = [p['close'] for p in predictions]
        min_close = min(close_prices)
        max_close = max(close_prices)

        pred_summary = f"""**é¢„æµ‹æ—¶é•¿**: æœªæ¥ {len(predictions)} ä¸ªå‘¨æœŸ

**æ—¶é—´èŒƒå›´**: {first_time} ~ {last_time}

**å½“å‰ä»·æ ¼**: ${first_close:.4f}

**é¢„æµ‹ä»·æ ¼**: ${last_close:.4f}

**ä»·æ ¼åŒºé—´**: ${min_close:.4f} ~ ${max_close:.4f}

**é¢„æµ‹æ¶¨è·Œ**: {change_pct:+.2f}%

**è¶‹åŠ¿åˆ¤æ–­**: {'ğŸ“ˆ ä¸Šæ¶¨è¶‹åŠ¿' if change_pct > 0 else 'ğŸ“‰ ä¸‹è·Œè¶‹åŠ¿' if change_pct < 0 else 'â¡ï¸ æ¨ªç›˜'}
"""

        message = f"""## ğŸ“Š Kronosæ¨¡å‹é¢„æµ‹åˆ†æ

{pred_summary}

### é¢„æµ‹æ•°æ®ï¼ˆå‰5ä¸ªå‘¨æœŸï¼‰

"""
        for i, p in enumerate(first_5, 1):
            timestamp_str = format_datetime_beijing(p['timestamp'], '%Y-%m-%d %H:%M') if hasattr(p['timestamp'], 'strftime') else str(p['timestamp'])[:19]
            message += f"{i}. **{timestamp_str}** - å¼€: ${p['open']:.2f}, é«˜: ${p['high']:.2f}, ä½: ${p['low']:.2f}, æ”¶: ${p['close']:.2f}\n"

        if last_5:
            message += "\n...\n\n### é¢„æµ‹æ•°æ®ï¼ˆå5ä¸ªå‘¨æœŸï¼‰\n\n"

            for i, p in enumerate(last_5, 1):
                timestamp_str = format_datetime_beijing(p['timestamp'], '%Y-%m-%d %H:%M') if hasattr(p['timestamp'], 'strftime') else str(p['timestamp'])[:19]
                message += f"{i}. **{timestamp_str}** - å¼€: ${p['open']:.2f}, é«˜: ${p['high']:.2f}, ä½: ${p['low']:.2f}, æ”¶: ${p['close']:.2f}\n"

        message += f"""

## ğŸ¯ è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡

1. åˆ†æé¢„æµ‹è¶‹åŠ¿å’Œå…³é”®ä»·æ ¼æ°´å¹³
2. æŸ¥è¯¢å½“å‰è´¦æˆ·ä½™é¢å’ŒæŒä»“æƒ…å†µ
3. åŸºäºé¢„æµ‹å’Œè´¦æˆ·çŠ¶æ€ï¼Œåˆ¶å®šäº¤æ˜“ç­–ç•¥
4. å¦‚æœåˆé€‚ï¼Œæ‰§è¡Œäº¤æ˜“æ“ä½œ

è¯·æä¾›è¯¦ç»†çš„åˆ†æå’Œå†³ç­–ç†ç”±ã€‚
"""

        return message

    def _get_tool_definitions(self, plan):
        """è·å–å·¥å…·å®šä¹‰"""
        tools_config = plan.agent_tools_config or {}
        tools = []

        if tools_config.get('get_account_balance', True):
            tools.append({
                "type": "function",
                "function": {
                    "name": "get_account_balance",
                    "description": "æŸ¥è¯¢è´¦æˆ·ä½™é¢",
                    "parameters": {"type": "object", "properties": {}}
                }
            })

        if tools_config.get('get_positions', True):
            tools.append({
                "type": "function",
                "function": {
                    "name": "get_positions",
                    "description": "æŸ¥è¯¢å½“å‰æŒä»“",
                    "parameters": {"type": "object", "properties": {}}
                }
            })

        if tools_config.get('get_pending_orders', True):
            tools.append({
                "type": "function",
                "function": {
                    "name": "get_pending_orders",
                    "description": "æŸ¥è¯¢æŒ‚å•åˆ—è¡¨",
                    "parameters": {"type": "object", "properties": {}}
                }
            })

        if tools_config.get('place_order', True):
            tools.append({
                "type": "function",
                "function": {
                    "name": "place_order",
                    "description": "ä¸‹å•",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "side": {"type": "string", "enum": ["buy", "sell"]},
                            "size": {"type": "number"},
                            "price": {"type": "number"}
                        },
                        "required": ["side", "size"]
                    }
                }
            })

        return tools if tools else None

    def get_prediction_text(self, training_id: int) -> str:
        """
        è·å–é¢„æµ‹æ•°æ®çš„æ–‡æœ¬æ ¼å¼ï¼ˆä¾›AI Agentä½¿ç”¨ï¼‰

        Args:
            training_id: è®­ç»ƒè®°å½•ID

        Returns:
            é¢„æµ‹æ•°æ®çš„æ–‡æœ¬æè¿°
        """
        try:
            predictions = InferenceService.get_prediction_data(training_id)

            if not predictions or len(predictions) == 0:
                return "âš ï¸ æš‚æ— é¢„æµ‹æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œ\"é¢„æµ‹äº¤æ˜“æ•°æ®\"æˆ–\"Mocké¢„æµ‹\""

            # è·å–æ¦‚ç‡æŒ‡æ ‡ï¼ˆä»æ•°æ®åº“ï¼‰
            upward_prob = None
            volatility_amp_prob = None
            sample_count = 1

            with get_db() as db:
                pred = db.query(PredictionData).filter(
                    PredictionData.training_record_id == training_id
                ).order_by(PredictionData.timestamp.desc()).first()

                if pred:
                    upward_prob = pred.upward_probability
                    volatility_amp_prob = pred.volatility_amplification_probability
                    if pred.inference_params:
                        sample_count = pred.inference_params.get('sample_count', 1)

            # æ„å»ºæ–‡æœ¬æ ¼å¼
            text_lines = []
            text_lines.append(f"ğŸ“Š é¢„æµ‹æ•°æ®ç»Ÿè®¡")
            text_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            text_lines.append(f"é¢„æµ‹æ•°æ®æ¡æ•°: {len(predictions)}æ¡")

            # æ˜¾ç¤ºæ¦‚ç‡æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
            if upward_prob is not None and volatility_amp_prob is not None:
                text_lines.append(f"è’™ç‰¹å¡ç½—è·¯å¾„: {sample_count}æ¡")
                text_lines.append(f"")
                text_lines.append(f"ğŸ“Š æ¦‚ç‡æŒ‡æ ‡")
                text_lines.append(f"  â€¢ ä¸Šæ¶¨æ¦‚ç‡: {upward_prob*100:.1f}%")
                text_lines.append(f"  â€¢ æ³¢åŠ¨æ€§æ”¾å¤§æ¦‚ç‡: {volatility_amp_prob*100:.1f}%")

            first_pred = predictions[0]
            last_pred = predictions[-1]

            # æ—¶é—´èŒƒå›´
            first_time = format_datetime_beijing(first_pred['timestamp'], '%Y-%m-%d %H:%M') if hasattr(first_pred['timestamp'], 'strftime') else str(first_pred['timestamp'])[:16]
            last_time = format_datetime_beijing(last_pred['timestamp'], '%Y-%m-%d %H:%M') if hasattr(last_pred['timestamp'], 'strftime') else str(last_pred['timestamp'])[:16]
            text_lines.append(f"")
            text_lines.append(f"æ—¶é—´èŒƒå›´: {first_time} ~ {last_time}")

            # ä»·æ ¼ç»Ÿè®¡
            close_prices = [p['close'] for p in predictions]
            min_close = min(close_prices)
            max_close = max(close_prices)
            first_close = close_prices[0]
            last_close = close_prices[-1]

            text_lines.append(f"")
            text_lines.append(f"ä»·æ ¼åŒºé—´: ${min_close:.2f} ~ ${max_close:.2f}")
            text_lines.append(f"èµ·å§‹ä»·æ ¼: ${first_close:.2f}")
            text_lines.append(f"ç»“æŸä»·æ ¼: ${last_close:.2f}")

            # è¶‹åŠ¿åˆ¤æ–­
            change_pct = ((last_close - first_close) / first_close) * 100
            trend = "ğŸ“ˆ ä¸Šæ¶¨è¶‹åŠ¿" if change_pct > 0 else "ğŸ“‰ ä¸‹è·Œè¶‹åŠ¿" if change_pct < 0 else "â¡ï¸ æ¨ªç›˜"
            text_lines.append(f"é¢„æµ‹æ¶¨è·Œ: {change_pct:+.2f}%")
            text_lines.append(f"è¶‹åŠ¿åˆ¤æ–­: {trend}")

            text_lines.append(f"")
            text_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            text_lines.append(f"ğŸ“‹ è¯¦ç»†é¢„æµ‹æ•°æ® (å‰10æ¡)")
            text_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

            # æ˜¾ç¤ºå‰10æ¡è¯¦ç»†æ•°æ®
            for i, pred in enumerate(predictions[:10], 1):
                timestamp_str = format_datetime_short_beijing(pred['timestamp']) if hasattr(pred['timestamp'], 'strftime') else str(pred['timestamp'])[:16]
                text_lines.append(
                    f"{i:2d}. {timestamp_str} | "
                    f"å¼€: ${pred['open']:7.2f} | é«˜: ${pred['high']:7.2f} | "
                    f"ä½: ${pred['low']:7.2f} | æ”¶: ${pred['close']:7.2f}"
                )

            if len(predictions) > 10:
                text_lines.append(f"... (å…±{len(predictions)}æ¡ï¼Œä»…æ˜¾ç¤ºå‰10æ¡)")

            return "\n".join(text_lines)

        except Exception as e:
            logger.error(f"è·å–é¢„æµ‹æ•°æ®æ–‡æœ¬å¤±è´¥: {e}")
            return f"âŒ è·å–é¢„æµ‹æ•°æ®å¤±è´¥: {str(e)}"

    async def execute_inference_async(self, training_id: int) -> str:
        """æ‰§è¡ŒKronosæ¨¡å‹æ¨ç†"""
        try:
            success = await InferenceService.start_inference(training_id)
            if success:
                return f"âœ… æ¨ç†å·²å®Œæˆï¼Œè®­ç»ƒè®°å½•ID: {training_id}"
            else:
                return f"âŒ æ¨ç†å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—"
        except Exception as e:
            logger.error(f"æ‰§è¡Œæ¨ç†å¤±è´¥: {e}")
            return f"âŒ æ¨ç†å¤±è´¥: {str(e)}"

    async def mock_predictions_async(self, training_id: int) -> str:
        """ç”ŸæˆMocké¢„æµ‹æ•°æ®"""
        try:
            result = InferenceService.mock_prediction_data(training_id, predict_window=48)
            if result['success']:
                return f"âœ… Mockæ•°æ®å·²ç”Ÿæˆï¼Œå…± {result['predictions_count']} æ¡"
            else:
                return f"âŒ ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        except Exception as e:
            logger.error(f"ç”ŸæˆMockæ•°æ®å¤±è´¥: {e}")
            return f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"

    async def start_training_async(self, plan_id: int, train_start_date: str = None, train_end_date: str = None):
        """
        å¼€å§‹è®­ç»ƒï¼ˆå¼‚æ­¥ï¼‰- ä½¿ç”¨ç”Ÿæˆå™¨å®æ—¶è¿”å›è¿›åº¦

        Args:
            plan_id: è®¡åˆ’ID
            train_start_date: è®­ç»ƒå¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨è®¡åˆ’é…ç½®
            train_end_date: è®­ç»ƒç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨è®¡åˆ’é…ç½®

        Yields:
            è®­ç»ƒè¿›åº¦æ¶ˆæ¯
        """
        try:
            from datetime import datetime
            import time

            # å¦‚æœæŒ‡å®šäº†æ—¥æœŸèŒƒå›´ï¼Œä¸´æ—¶æ›´æ–°è®¡åˆ’çš„æ•°æ®æ—¶é—´èŒƒå›´
            if train_start_date and train_end_date:
                try:
                    start_dt = datetime.strptime(train_start_date, '%Y-%m-%d')
                    end_dt = datetime.strptime(train_end_date, '%Y-%m-%d')

                    # ä¸´æ—¶æ›´æ–°è®¡åˆ’çš„æ•°æ®æ—¶é—´èŒƒå›´
                    with get_db() as db:
                        db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                            'data_start_time': start_dt,
                            'data_end_time': end_dt
                        })
                        db.commit()

                    logger.info(f"å·²æ›´æ–°è®­ç»ƒæ•°æ®èŒƒå›´: {train_start_date} è‡³ {train_end_date}")

                except ValueError as e:
                    yield f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}"
                    return

            # å¯åŠ¨è®­ç»ƒ
            training_id = await TrainingService.start_training(plan_id, manual=True)
            if not training_id:
                yield "âŒ è®­ç»ƒå¯åŠ¨å¤±è´¥"
                return

            yield f"âœ… è®­ç»ƒå·²å¯åŠ¨ï¼Œè®°å½•ID: {training_id}\n\nå¼€å§‹è®­ç»ƒ..."

            # è½®è¯¢è®­ç»ƒè¿›åº¦
            last_progress = -1
            max_wait_time = 3600  # æœ€å¤šç­‰å¾…1å°æ—¶
            start_time = time.time()

            while True:
                # æ£€æŸ¥è¶…æ—¶
                if time.time() - start_time > max_wait_time:
                    yield "\n\nâš ï¸ è®­ç»ƒè¶…æ—¶ï¼ˆè¶…è¿‡1å°æ—¶ï¼‰"
                    break

                # è·å–è¿›åº¦
                progress_info = TrainingService.get_training_progress(training_id)

                if progress_info:
                    current_progress = progress_info['progress']
                    stage = progress_info['stage']
                    message = progress_info['message']

                    # åªåœ¨è¿›åº¦å˜åŒ–æ—¶æ›´æ–°
                    if abs(current_progress - last_progress) > 0.01:
                        progress_percent = int(current_progress * 100)
                        progress_bar = 'â–ˆ' * (progress_percent // 2) + 'â–‘' * (50 - progress_percent // 2)
                        yield f"\n\n**è®­ç»ƒè¿›åº¦**: {progress_percent}%\n\n`{progress_bar}`\n\n**é˜¶æ®µ**: {stage}\n\n**çŠ¶æ€**: {message}"
                        last_progress = current_progress

                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    if stage == 'completed':
                        yield f"\n\nâœ… è®­ç»ƒå®Œæˆï¼è®°å½•ID: {training_id}"
                        break
                    elif stage == 'failed':
                        yield f"\n\nâŒ è®­ç»ƒå¤±è´¥: {message}"
                        break

                # æ£€æŸ¥è®­ç»ƒè®°å½•çŠ¶æ€
                with get_db() as db:
                    record = db.query(TrainingRecord).filter(
                        TrainingRecord.id == training_id
                    ).first()

                    if record:
                        if record.status == 'completed':
                            yield f"\n\nâœ… è®­ç»ƒå®Œæˆï¼\n\n- TokenizeræŸå¤±: {record.train_metrics.get('tokenizer_loss', 'N/A')}\n- PredictoræŸå¤±: {record.train_metrics.get('predictor_loss', 'N/A')}"
                            break
                        elif record.status == 'failed':
                            yield f"\n\nâŒ è®­ç»ƒå¤±è´¥: {record.error_message or 'æœªçŸ¥é”™è¯¯'}"
                            break

                # ç­‰å¾…ä¸€æ®µæ—¶é—´å†æŸ¥è¯¢
                await asyncio.sleep(2)

        except Exception as e:
            logger.error(f"è®­ç»ƒç›‘æ§å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield f"\n\nâŒ é”™è¯¯: {str(e)}"

    async def start_websocket_async(self, plan_id: int) -> str:
        """å¯åŠ¨WebSocketï¼ˆå¼‚æ­¥ï¼‰"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨"

                # ä½¿ç”¨å…¨å±€è¿æ¥ç®¡ç†å™¨
                from services.ws_connection_manager import ws_connection_manager

                # è·å–æˆ–åˆ›å»ºWebSocketè¿æ¥
                ws_service = ws_connection_manager.get_or_create_connection(
                    inst_id=plan.inst_id,
                    interval=plan.interval,
                    is_demo=plan.is_demo,
                    ui_callback=None
                )

                if ws_service:
                    # æ›´æ–°è®¡åˆ’çš„ws_connectedçŠ¶æ€
                    db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                        'ws_connected': True
                    })
                    db.commit()
                    return "âœ… WebSocketå·²å¯åŠ¨"
                else:
                    return "âŒ WebSocketå¯åŠ¨å¤±è´¥"

        except Exception as e:
            logger.error(f"å¯åŠ¨WebSocketå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}"

    async def stop_websocket_async(self, plan_id: int) -> str:
        """åœæ­¢WebSocketï¼ˆå¼‚æ­¥ï¼‰"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨"

                # ä½¿ç”¨å…¨å±€è¿æ¥ç®¡ç†å™¨
                from services.ws_connection_manager import ws_connection_manager

                # åœæ­¢WebSocket (stop_connectionæ˜¯åŒæ­¥æ–¹æ³•)
                ws_connection_manager.stop_connection(
                    inst_id=plan.inst_id,
                    interval=plan.interval,
                    is_demo=plan.is_demo
                )

                # æ›´æ–°è®¡åˆ’çš„ws_connectedçŠ¶æ€
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'ws_connected': False
                })
                db.commit()
                return "âœ… WebSocketå·²åœæ­¢"

        except Exception as e:
            logger.error(f"åœæ­¢WebSocketå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ åœæ­¢å¤±è´¥: {str(e)}"

    async def start_plan_async(self, plan_id: int) -> str:
        """å¯åŠ¨è®¡åˆ’ï¼ˆå¯åŠ¨å®šæ—¶ä»»åŠ¡ï¼‰"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨"

                # æ›´æ–°è®¡åˆ’çŠ¶æ€
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'status': 'running'
                })
                db.commit()

                # å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
                from services.schedule_service import ScheduleService
                success = await ScheduleService.start_schedule(plan_id)

                # å¯åŠ¨è‡ªåŠ¨åŒ–è°ƒåº¦å™¨ï¼ˆå¦‚æœé…ç½®äº†è‡ªåŠ¨åŒ–ï¼‰
                automation_status = ""
                if plan.auto_finetune_enabled or plan.auto_inference_enabled or plan.auto_agent_enabled or plan.auto_tool_execution_enabled:
                    try:
                        from services.automation_service import automation_service
                        automation_service.start_scheduler()
                        automation_status = "\nğŸ¤– è‡ªåŠ¨åŒ–è°ƒåº¦å™¨å·²å¯åŠ¨"
                        logger.info(f"è‡ªåŠ¨åŒ–è°ƒåº¦å™¨å·²å¯åŠ¨: plan_id={plan_id}")
                    except Exception as e:
                        logger.error(f"å¯åŠ¨è‡ªåŠ¨åŒ–è°ƒåº¦å™¨å¤±è´¥: {e}")
                        automation_status = f"\nâš ï¸ è‡ªåŠ¨åŒ–è°ƒåº¦å™¨å¯åŠ¨å¤±è´¥: {str(e)}"

                # å¯åŠ¨è´¦æˆ·WebSocketè¿æ¥
                if plan.okx_api_key and plan.okx_secret_key and plan.okx_passphrase:
                    from services.account_ws_manager import account_ws_manager
                    account_ws_manager.get_or_create_connection(
                        api_key=plan.okx_api_key,
                        secret_key=plan.okx_secret_key,
                        passphrase=plan.okx_passphrase,
                        is_demo=plan.is_demo,
                        plan_id=plan_id
                    )
                    logger.info(f"è´¦æˆ·WebSocketå·²å¯åŠ¨: plan_id={plan_id}")

                logger.info(f"è®¡åˆ’å·²å¯åŠ¨: plan_id={plan_id}, schedule_success={success}")

                result_msg = "âœ… è®¡åˆ’å·²å¯åŠ¨"
                if success:
                    # è·å–å·²åˆ›å»ºçš„ä»»åŠ¡ä¿¡æ¯
                    jobs = ScheduleService.get_plan_jobs(plan_id)
                    job_info = f"å·²åˆ›å»º {len(jobs)} ä¸ªå®šæ—¶ä»»åŠ¡"
                    result_msg += f"\nâœ… {job_info}"
                else:
                    result_msg += "\nâš ï¸ å®šæ—¶ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼ˆå¯èƒ½æœªé…ç½®æ—¶é—´è¡¨ï¼‰"

                result_msg += automation_status

                return result_msg

        except Exception as e:
            logger.error(f"å¯åŠ¨è®¡åˆ’å¤±è´¥: {e}")
            return f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}"

    async def stop_plan_async(self, plan_id: int) -> str:
        """åœæ­¢è®¡åˆ’ï¼ˆåœæ­¢å®šæ—¶ä»»åŠ¡ï¼‰"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return "âŒ è®¡åˆ’ä¸å­˜åœ¨"

                # æ›´æ–°è®¡åˆ’çŠ¶æ€
                db.query(TradingPlan).filter(TradingPlan.id == plan_id).update({
                    'status': 'stopped'
                })
                db.commit()

                # åœæ­¢è´¦æˆ·WebSocketè¿æ¥
                if plan.okx_api_key:
                    from services.account_ws_manager import account_ws_manager
                    account_ws_manager.stop_connection(
                        api_key=plan.okx_api_key,
                        is_demo=plan.is_demo,
                        plan_id=plan_id
                    )
                    logger.info(f"è´¦æˆ·WebSocketå·²åœæ­¢: plan_id={plan_id}")

                # åœæ­¢å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
                from services.schedule_service import ScheduleService
                success = await ScheduleService.stop_schedule(plan_id)

                logger.info(f"è®¡åˆ’å·²åœæ­¢: plan_id={plan_id}, schedule_success={success}")
                return "âœ… è®¡åˆ’å·²åœæ­¢\nâœ… æ‰€æœ‰å®šæ—¶ä»»åŠ¡å·²ç§»é™¤"

        except Exception as e:
            logger.error(f"åœæ­¢è®¡åˆ’å¤±è´¥: {e}")
            return f"âŒ åœæ­¢å¤±è´¥: {str(e)}"

    def get_account_info(self, plan_id: int) -> str:
        """è·å–è´¦æˆ·ä¿¡æ¯ï¼ˆMarkdownæ ¼å¼ï¼‰"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan or not plan.okx_api_key:
                    return "### ğŸ’° è´¦æˆ·ä¿¡æ¯\n\næœªé…ç½®OKX API Key"

                from services.account_ws_manager import account_ws_manager

                # è·å–è¿æ¥çŠ¶æ€
                status = account_ws_manager.get_connection_status(
                    api_key=plan.okx_api_key,
                    is_demo=plan.is_demo
                )

                if not status['connected']:
                    return f"### ğŸ’° è´¦æˆ·ä¿¡æ¯\n\nâšª æœªè¿æ¥\n\n{'æ¨¡æ‹Ÿç›˜' if plan.is_demo else 'çœŸå®ç›˜'}"

                # è·å–è´¦æˆ·æ•°æ®
                account_info = account_ws_manager.get_account_info(
                    api_key=plan.okx_api_key,
                    is_demo=plan.is_demo
                )

                if not account_info:
                    return "### ğŸ’° è´¦æˆ·ä¿¡æ¯\n\nâšª æš‚æ— æ•°æ®"

                balances = account_info.get('balances', {})
                positions = account_info.get('positions', [])
                last_update = account_info.get('last_update')

                # æ„å»ºMarkdown
                lines = ["### ğŸ’° è´¦æˆ·ä¿¡æ¯\n"]
                lines.append(f"**ç¯å¢ƒ**: {'ğŸ§ª æ¨¡æ‹Ÿç›˜' if plan.is_demo else 'ğŸ’° çœŸå®ç›˜'}")
                lines.append(f"**çŠ¶æ€**: ğŸŸ¢ å·²è¿æ¥")

                if last_update:
                    lines.append(f"**æ›´æ–°æ—¶é—´**: {format_datetime_beijing(last_update, '%H:%M:%S')}")

                lines.append("\n---\n")

                # ä½™é¢ä¿¡æ¯
                if balances:
                    lines.append("**è´¦æˆ·ä½™é¢**:\n")
                    for ccy, data in balances.items():
                        available = data.get('available', 0)
                        balance = data.get('balance', 0)
                        equity = data.get('equity', 0)
                        lines.append(f"- **{ccy}**: å¯ç”¨ {available:.4f} | ä½™é¢ {balance:.4f} | æƒç›Š {equity:.4f}")
                else:
                    lines.append("**è´¦æˆ·ä½™é¢**: æš‚æ— æ•°æ®")

                lines.append("\n---\n")

                # æŒä»“ä¿¡æ¯
                if positions:
                    lines.append(f"**æŒä»“** ({len(positions)}ä¸ª):\n")
                    for pos in positions[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        inst_id = pos.get('inst_id', 'N/A')
                        pos_qty = pos.get('pos', 0)
                        avg_price = pos.get('avg_price', 0)
                        upl = pos.get('upl', 0)
                        upl_ratio = pos.get('upl_ratio', 0)

                        upl_emoji = 'ğŸ“ˆ' if upl >= 0 else 'ğŸ“‰'
                        lines.append(
                            f"- {upl_emoji} **{inst_id}**: {pos_qty} @ {avg_price:.4f} | "
                            f"ç›ˆäº {upl:+.2f} ({upl_ratio:+.2%})"
                        )
                else:
                    lines.append("**æŒä»“**: æ— ")

                return "\n".join(lines)

        except Exception as e:
            logger.error(f"è·å–è´¦æˆ·ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"### ğŸ’° è´¦æˆ·ä¿¡æ¯\n\nâŒ è·å–å¤±è´¥: {str(e)}"

    def get_orders_info(self, plan_id: int) -> pd.DataFrame:
        """è·å–è®¢å•è®°å½•ï¼ˆé€šè¿‡ REST APIï¼‰"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan or not plan.okx_api_key:
                    return pd.DataFrame()

                from services.okx_rest_service import OKXRestService

                # åˆ›å»º REST API æœåŠ¡
                rest_service = OKXRestService(
                    api_key=plan.okx_api_key,
                    secret_key=plan.okx_secret_key,
                    passphrase=plan.okx_passphrase,
                    is_demo=plan.is_demo
                )

                # è·å–è®¢å•åˆ—è¡¨ï¼ˆSPOT ç±»å‹ï¼‰
                orders = rest_service.get_all_orders(
                    inst_type="SPOT",
                    inst_id=None,  # è·å–æ‰€æœ‰äº¤æ˜“å¯¹
                    limit=50
                )

                if not orders:
                    return pd.DataFrame()

                # æ„å»ºDataFrame
                df_data = []
                for order in orders:
                    side_emoji = 'ğŸŸ¢' if order['side'] == 'buy' else 'ğŸ”´'
                    state_map = {
                        'live': 'â³ æœªæˆäº¤',
                        'partially_filled': 'â¸ï¸ éƒ¨åˆ†æˆäº¤',
                        'filled': 'âœ… å®Œå…¨æˆäº¤',
                        'canceled': 'âŒ å·²å–æ¶ˆ',
                        'mmp_canceled': 'âŒ MMPå–æ¶ˆ',
                        'failed': 'âŒ å¤±è´¥'
                    }
                    state_emoji = state_map.get(order['state'], f"â“ {order['state']}")

                    # è½¬æ¢æ—¶é—´æˆ³
                    create_time = format_datetime_beijing(datetime.fromtimestamp(int(order['cTime']) / 1000), '%m-%d %H:%M:%S')
                    update_time = format_datetime_beijing(datetime.fromtimestamp(int(order['uTime']) / 1000), '%m-%d %H:%M:%S')

                    df_data.append({
                        'è®¢å•ID': order['ordId'][:10] + '...',
                        'äº¤æ˜“å¯¹': order['instId'],
                        'æ–¹å‘': f"{side_emoji} {order['side']}",
                        'ç±»å‹': order['ordType'],
                        'ä»·æ ¼': f"{float(order['px']):.4f}" if order.get('px') else 'å¸‚ä»·',
                        'æ•°é‡': f"{float(order['sz']):.4f}",
                        'å·²æˆäº¤': f"{float(order.get('accFillSz', 0)):.4f}",
                        'çŠ¶æ€': state_emoji,
                        'åˆ›å»ºæ—¶é—´': create_time,
                        'æ›´æ–°æ—¶é—´': update_time
                    })

                return pd.DataFrame(df_data)

        except Exception as e:
            logger.error(f"è·å–è®¢å•ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()

    def clear_agent_records(self, plan_id: int) -> str:
        """æ¸…é™¤AI Agentæ¨ç†è®°å½•"""
        try:
            if not plan_id:
                return "âŒ è¯·å…ˆé€‰æ‹©è®¡åˆ’"

            with get_db() as db:
                # åˆ é™¤è¯¥è®¡åˆ’çš„æ‰€æœ‰Agentå†³ç­–è®°å½•
                deleted_count = db.query(AgentDecision).filter(
                    AgentDecision.plan_id == plan_id
                ).delete()

                db.commit()

                logger.info(f"æ¸…é™¤è®¡åˆ’ {plan_id} çš„ {deleted_count} æ¡AI Agentæ¨ç†è®°å½•")

                return f"âœ… å·²æ¸…é™¤ {deleted_count} æ¡æ¨ç†è®°å½•"

        except Exception as e:
            logger.error(f"æ¸…é™¤æ¨ç†è®°å½•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return f"âŒ æ¸…é™¤å¤±è´¥: {str(e)}"

    def get_pending_tools(self, plan_id: int) -> pd.DataFrame:
        """è·å–å¾…ç¡®è®¤å·¥å…·åˆ—è¡¨"""
        try:
            tools = confirmation_service.get_pending_tools(plan_id)

            if not tools:
                return pd.DataFrame(columns=[
                    'ID', 'å·¥å…·åç§°', 'å‚æ•°', 'åˆ›å»ºæ—¶é—´', 'çŠ¶æ€'
                ])

            # æ„å»ºDataFrame
            df_data = []
            for tool in tools:
                # æ ¼å¼åŒ–æ—¶é—´
                created_at = tool.get('created_at', 'N/A')
                if created_at != 'N/A':
                    try:
                        if hasattr(created_at, 'strftime'):
                            created_at = created_at.strftime('%m-%d %H:%M:%S')
                        else:
                            created_at = str(created_at)
                    except:
                        created_at = str(created_at)

                # æ ¼å¼åŒ–å‚æ•°
                tool_args = tool.get('tool_args', {})
                if isinstance(tool_args, dict):
                    args_str = ', '.join([f"{k}: {v}" for k, v in tool_args.items()])
                else:
                    args_str = str(tool_args)

                # çŠ¶æ€æ˜ å°„
                status = tool.get('status', 'pending')
                status_map = {
                    'pending': 'â³ å¾…ç¡®è®¤',
                    'approved': 'âœ… å·²æ‰¹å‡†',
                    'rejected': 'âŒ å·²æ‹’ç»',
                    'executed': 'âœ… å·²æ‰§è¡Œ',
                    'failed': 'âŒ æ‰§è¡Œå¤±è´¥'
                }
                status_display = status_map.get(status, status)

                df_data.append({
                    'ID': tool.get('id', ''),
                    'å·¥å…·åç§°': tool.get('tool_name', 'N/A'),
                    'å‚æ•°': args_str,
                    'åˆ›å»ºæ—¶é—´': created_at,
                    'çŠ¶æ€': status_display
                })

            return pd.DataFrame(df_data)

        except Exception as e:
            logger.error(f"è·å–å¾…ç¡®è®¤å·¥å…·å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame(columns=[
                'ID', 'å·¥å…·åç§°', 'å‚æ•°', 'åˆ›å»ºæ—¶é—´', 'çŠ¶æ€'
            ])

    def get_tool_confirmation_history(self, plan_id: int, limit: int = 20) -> List[Dict]:
        """è·å–å·¥å…·ç¡®è®¤å†å²"""
        try:
            return confirmation_service.get_tool_execution_history(plan_id, limit)
        except Exception as e:
            logger.error(f"è·å–å·¥å…·ç¡®è®¤å†å²å¤±è´¥: {e}")
            return []

    async def confirm_tools(self, plan_id: int, selected_tools: str, action: str) -> str:
        """ç¡®è®¤å·¥å…·è°ƒç”¨"""
        try:
            if not selected_tools.strip():
                return "âŒ è¯·é€‰æ‹©è¦æ“ä½œçš„å·¥å…·"

            # è§£æé€‰æ‹©çš„å·¥å…·ID
            tool_ids = [int(tid.strip()) for tid in selected_tools.split(',') if tid.strip().isdigit()]

            if not tool_ids:
                return "âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å·¥å…·ID"

            approved = action == "approve"
            confirmed_by = "user" if approved else "user_rejected"

            # æ‰¹é‡ç¡®è®¤
            result = await confirmation_service.batch_confirm_tools(
                pending_tool_ids=tool_ids,
                approved=approved,
                confirmed_by=confirmed_by
            )

            if result['success']:
                action_text = "åŒæ„" if approved else "æ‹’ç»"
                return f"âœ… å·²{action_text} {len(tool_ids)} ä¸ªå·¥å…·è°ƒç”¨ï¼š\n{result['message']}"
            else:
                return f"âŒ æ“ä½œå¤±è´¥ï¼š{result.get('message', 'æœªçŸ¥é”™è¯¯')}"

        except Exception as e:
            logger.error(f"ç¡®è®¤å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            return f"âŒ ç¡®è®¤å¤±è´¥ï¼š{str(e)}"

    def cleanup_expired_tools(self, plan_id: int) -> str:
        """æ¸…ç†è¿‡æœŸå·¥å…·"""
        try:
            result = confirmation_service.cleanup_expired_tools()
            if result['success']:
                return f"âœ… {result['message']}"
            else:
                return f"âŒ æ¸…ç†å¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸå·¥å…·å¤±è´¥: {e}")
            return f"âŒ æ¸…ç†å¤±è´¥ï¼š{str(e)}"

    def load_task_executions(self, plan_id: int) -> pd.DataFrame:
        """åŠ è½½ä»»åŠ¡æ‰§è¡Œè®°å½•"""
        try:
            from services.scheduler_service import scheduler_service

            # è·å–ä»»åŠ¡å†å²
            task_history = scheduler_service.get_task_history(plan_id, limit=100)

            if not task_history:
                return pd.DataFrame(columns=[
                    'ID', 'ä»»åŠ¡ç±»å‹', 'ä»»åŠ¡åç§°', 'çŠ¶æ€', 'è®¡åˆ’æ—¶é—´', 'å¼€å§‹æ—¶é—´',
                    'å®Œæˆæ—¶é—´', 'æ‰§è¡Œæ—¶é•¿(ç§’)', 'è§¦å‘æ–¹å¼', 'è¿›åº¦(%)'
                ]).astype({
                    'ID': 'int',
                    'æ‰§è¡Œæ—¶é•¿(ç§’)': 'int',
                    'è¿›åº¦(%)': 'int'
                })

            # æ„å»ºDataFrame
            df_data = []
            for task in task_history:
                df_data.append({
                    'ID': task['id'],
                    'ä»»åŠ¡ç±»å‹': task['type_display'],
                    'ä»»åŠ¡åç§°': task['task_name'],
                    'çŠ¶æ€': task['status_display'],
                    'è®¡åˆ’æ—¶é—´': task['scheduled_time'] or '',
                    'å¼€å§‹æ—¶é—´': task['started_at'] or '',
                    'å®Œæˆæ—¶é—´': task['completed_at'] or '',
                    'æ‰§è¡Œæ—¶é•¿(ç§’)': task['duration_seconds'] or 0,  # ç¡®ä¿æ•°å­—ç±»å‹
                    'è§¦å‘æ–¹å¼': task['trigger_type'],
                    'è¿›åº¦(%)': task['progress_percentage'] or 0  # ç¡®ä¿æ•°å­—ç±»å‹
                })

            # åˆ›å»ºDataFrame
            df = pd.DataFrame(df_data)

            # ç¡®ä¿æ•°å­—åˆ—çš„ç±»å‹æ­£ç¡®
            if 'æ‰§è¡Œæ—¶é•¿(ç§’)' in df.columns:
                df['æ‰§è¡Œæ—¶é•¿(ç§’)'] = pd.to_numeric(df['æ‰§è¡Œæ—¶é•¿(ç§’)'], errors='coerce').fillna(0).astype(int)
            if 'è¿›åº¦(%)' in df.columns:
                df['è¿›åº¦(%)'] = pd.to_numeric(df['è¿›åº¦(%)'], errors='coerce').fillna(0).astype(int)

            return df

        except Exception as e:
            logger.error(f"åŠ è½½ä»»åŠ¡æ‰§è¡Œè®°å½•å¤±è´¥: {e}")
            return pd.DataFrame(columns=[
                    'ID', 'ä»»åŠ¡ç±»å‹', 'ä»»åŠ¡åç§°', 'çŠ¶æ€', 'è®¡åˆ’æ—¶é—´', 'å¼€å§‹æ—¶é—´',
                    'å®Œæˆæ—¶é—´', 'æ‰§è¡Œæ—¶é•¿(ç§’)', 'è§¦å‘æ–¹å¼', 'è¿›åº¦(%)'
                ]).astype({
                    'ID': 'int',
                    'æ‰§è¡Œæ—¶é•¿(ç§’)': 'int',
                    'è¿›åº¦(%)': 'int'
                })
