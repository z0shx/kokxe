"""
é…ç½®ä¸­å¿ƒç•Œé¢
"""
import gradio as gr
import pandas as pd
from typing import List, Tuple, Optional
from services.config_service import ConfigService
from utils.logger import setup_logger
from ui.constants import DataFrameHeaders, create_empty_dataframe
from ui.ui_utils import UIHelper

logger = setup_logger(__name__, "config_center_ui.log")


class ConfigCenterUI:
    """é…ç½®ä¸­å¿ƒç•Œé¢"""

    def __init__(self):
        self.config_service = ConfigService()

    # ========== LLM é…ç½®ç®¡ç† ==========

    @UIHelper.create_error_handler("åŠ è½½LLMé…ç½®")
    def load_llm_configs(self) -> pd.DataFrame:
        """åŠ è½½ LLM é…ç½®åˆ—è¡¨"""
        configs = self.config_service.get_all_llm_configs(active_only=False)

        if not configs:
            return create_empty_dataframe(DataFrameHeaders.LLM_CONFIG)

        data = []
        for config in configs:
            data.append({
                "ID": config.id,
                "åç§°": config.name,
                "æä¾›å•†": config.provider,
                "æ¨¡å‹": config.model_name or "-",
                "çŠ¶æ€": "å¯ç”¨" if config.is_active else "ç¦ç”¨",
                "é»˜è®¤": "âœ“" if config.is_default else ""
            })

        return pd.DataFrame(data)

    def create_llm_config(
        self,
        name: str,
        provider: str,
        api_key: str,
        api_base_url: str,
        model_name: str,
        max_tokens: int,
        temperature: float,
        top_p: float,
        is_default: bool
    ) -> Tuple[str, pd.DataFrame]:
        """åˆ›å»º LLM é…ç½®"""
        try:
            if not name or not provider:
                return "âŒ è¯·å¡«å†™é…ç½®åç§°å’Œæä¾›å•†", self.load_llm_configs()

            config_id = self.config_service.create_llm_config(
                name=name,
                provider=provider,
                api_key=api_key,
                api_base_url=api_base_url,
                model_name=model_name,
                max_tokens=int(max_tokens),
                temperature=float(temperature),
                top_p=float(top_p),
                is_default=is_default
            )

            if config_id:
                return f"âœ… åˆ›å»ºæˆåŠŸï¼é…ç½® ID: {config_id}", self.load_llm_configs()
            else:
                return "âŒ åˆ›å»ºå¤±è´¥", self.load_llm_configs()

        except Exception as e:
            logger.error(f"åˆ›å»º LLM é…ç½®å¤±è´¥: {e}")
            return f"âŒ åˆ›å»ºå¤±è´¥: {str(e)}", self.load_llm_configs()

    def delete_llm_config(self, config_id: int) -> Tuple[str, pd.DataFrame]:
        """åˆ é™¤ LLM é…ç½®"""
        try:
            if not config_id or config_id <= 0:
                return "âŒ è¯·é€‰æ‹©è¦åˆ é™¤çš„é…ç½®", self.load_llm_configs()

            success = self.config_service.delete_llm_config(int(config_id))

            if success:
                return f"âœ… åˆ é™¤æˆåŠŸï¼é…ç½® ID: {config_id}", self.load_llm_configs()
            else:
                return "âŒ åˆ é™¤å¤±è´¥", self.load_llm_configs()

        except Exception as e:
            logger.error(f"åˆ é™¤ LLM é…ç½®å¤±è´¥: {e}")
            return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}", self.load_llm_configs()

    def get_llm_config_choices(self) -> List[Tuple[str, int]]:
        """è·å– LLM é…ç½®é€‰é¡¹ï¼ˆç”¨äºä¸‹æ‹‰æ¡†ï¼‰"""
        try:
            configs = self.config_service.get_all_llm_configs(active_only=True)
            return [(f"{cfg.name} ({cfg.provider})", cfg.id) for cfg in configs]
        except Exception as e:
            logger.error(f"è·å– LLM é…ç½®é€‰é¡¹å¤±è´¥: {e}")
            return []

    # ========== Agent æç¤ºè¯æ¨¡ç‰ˆç®¡ç† ==========

    @UIHelper.create_error_handler("åŠ è½½æç¤ºè¯æ¨¡ç‰ˆ")
    def load_prompt_templates(self) -> pd.DataFrame:
        """åŠ è½½ Agent æç¤ºè¯æ¨¡ç‰ˆåˆ—è¡¨"""
        templates = self.config_service.get_all_prompt_templates(active_only=False)

        if not templates:
            return create_empty_dataframe(DataFrameHeaders.PROMPT_TEMPLATE)

        data = []
        for template in templates:
            desc = template.description or ""
            if len(desc) > 50:
                desc = desc[:50] + "..."

            data.append({
                "ID": template.id,
                "åç§°": template.name,
                "åˆ†ç±»": template.category or "-",
                "æè¿°": desc,
                "çŠ¶æ€": "å¯ç”¨" if template.is_active else "ç¦ç”¨",
                "é»˜è®¤": "âœ“" if template.is_default else ""
            })

        return pd.DataFrame(data)

    def create_prompt_template(
        self,
        name: str,
        content: str,
        description: str,
        category: str,
        is_default: bool
    ) -> Tuple[str, pd.DataFrame]:
        """åˆ›å»º Agent æç¤ºè¯æ¨¡ç‰ˆ"""
        try:
            if not name or not content:
                return "âŒ è¯·å¡«å†™æ¨¡ç‰ˆåç§°å’Œå†…å®¹", self.load_prompt_templates()

            template_id = self.config_service.create_prompt_template(
                name=name,
                content=content,
                description=description,
                category=category,
                is_default=is_default
            )

            if template_id:
                return f"âœ… åˆ›å»ºæˆåŠŸï¼æ¨¡ç‰ˆ ID: {template_id}", self.load_prompt_templates()
            else:
                return "âŒ åˆ›å»ºå¤±è´¥", self.load_prompt_templates()

        except Exception as e:
            logger.error(f"åˆ›å»º Agent æç¤ºè¯æ¨¡ç‰ˆå¤±è´¥: {e}")
            return f"âŒ åˆ›å»ºå¤±è´¥: {str(e)}", self.load_prompt_templates()

    def delete_prompt_template(self, template_id: int) -> Tuple[str, pd.DataFrame]:
        """åˆ é™¤ Agent æç¤ºè¯æ¨¡ç‰ˆ"""
        try:
            if not template_id or template_id <= 0:
                return "âŒ è¯·é€‰æ‹©è¦åˆ é™¤çš„æ¨¡ç‰ˆ", self.load_prompt_templates()

            success = self.config_service.delete_prompt_template(int(template_id))

            if success:
                return f"âœ… åˆ é™¤æˆåŠŸï¼æ¨¡ç‰ˆ ID: {template_id}", self.load_prompt_templates()
            else:
                return "âŒ åˆ é™¤å¤±è´¥", self.load_prompt_templates()

        except Exception as e:
            logger.error(f"åˆ é™¤ Agent æç¤ºè¯æ¨¡ç‰ˆå¤±è´¥: {e}")
            return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}", self.load_prompt_templates()

    def get_prompt_template_choices(self) -> List[Tuple[str, str]]:
        """è·å– Agent æç¤ºè¯æ¨¡ç‰ˆé€‰é¡¹ï¼ˆç”¨äºä¸‹æ‹‰æ¡†ï¼‰"""
        try:
            templates = self.config_service.get_all_prompt_templates(active_only=True)
            return [(tpl.name, tpl.content) for tpl in templates]
        except Exception as e:
            logger.error(f"è·å– Agent æç¤ºè¯æ¨¡ç‰ˆé€‰é¡¹å¤±è´¥: {e}")
            return []

    def load_template_content(self, template_name: str) -> str:
        """åŠ è½½æ¨¡ç‰ˆå†…å®¹"""
        try:
            templates = self.config_service.get_all_prompt_templates(active_only=True)
            for template in templates:
                if template.name == template_name:
                    return template.content
            return ""
        except Exception as e:
            logger.error(f"åŠ è½½æ¨¡ç‰ˆå†…å®¹å¤±è´¥: {e}")
            return ""

    # ========== UI æ„å»º ==========

    def build_ui(self):
        """æ„å»ºç•Œé¢"""
        with gr.Column():
            gr.Markdown("## é…ç½®ä¸­å¿ƒ")

            with gr.Tabs():
                # Tab 1: LLM é…ç½®ç®¡ç†
                with gr.Tab("LLM é…ç½®"):
                    gr.Markdown("### LLM é…ç½®ç®¡ç†")
                    gr.Markdown("ç®¡ç† AI Agent ä½¿ç”¨çš„ LLM é…ç½®ï¼ˆClaudeã€Qwenã€Ollamaã€OpenAIï¼‰")

                    with gr.Row():
                        # å·¦ä¾§ï¼šé…ç½®åˆ—è¡¨
                        with gr.Column(scale=2):
                            llm_configs_table = gr.DataFrame(
                                value=self.load_llm_configs(),
                                label="LLM é…ç½®åˆ—è¡¨",
                                interactive=False
                            )

                            with gr.Row():
                                llm_refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", size="sm")
                                llm_delete_id = gr.Number(
                                    label="é…ç½® ID",
                                    value=0,
                                    minimum=0,
                                    scale=1
                                )
                                llm_delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤", variant="stop", size="sm")

                        # å³ä¾§ï¼šåˆ›å»ºé…ç½®
                        with gr.Column(scale=3):
                            gr.Markdown("#### æ–°å»º LLM é…ç½®")

                            llm_name = gr.Textbox(
                                label="é…ç½®åç§°",
                                placeholder="ä¾‹å¦‚ï¼šClaude Sonnet 3.5"
                            )

                            llm_provider = gr.Dropdown(
                                label="LLM æä¾›å•†",
                                choices=["claude", "qwen", "ollama", "openai"],
                                value="claude"
                            )

                            with gr.Row():
                                llm_api_key = gr.Textbox(
                                    label="API Key",
                                    type="password",
                                    placeholder="sk-xxx..."
                                )

                                llm_api_base_url = gr.Textbox(
                                    label="API Base URL",
                                    placeholder="https://api.anthropic.com (å¯é€‰)"
                                )

                            llm_model_name = gr.Textbox(
                                label="æ¨¡å‹åç§°",
                                placeholder="claude-3-5-sonnet-20241022"
                            )

                            with gr.Row():
                                llm_max_tokens = gr.Number(
                                    label="æœ€å¤§ Token æ•°",
                                    value=4096,
                                    minimum=1,
                                    maximum=200000
                                )

                                llm_temperature = gr.Slider(
                                    label="æ¸©åº¦ (Temperature)",
                                    minimum=0.0,
                                    maximum=2.0,
                                    value=0.7,
                                    step=0.1
                                )

                                llm_top_p = gr.Slider(
                                    label="Top P",
                                    minimum=0.0,
                                    maximum=1.0,
                                    value=1.0,
                                    step=0.05
                                )

                            llm_is_default = gr.Checkbox(
                                label="è®¾ä¸ºé»˜è®¤é…ç½®",
                                value=False
                            )

                            llm_create_btn = gr.Button("â• åˆ›å»ºé…ç½®", variant="primary")

                            llm_result = gr.Textbox(
                                label="æ“ä½œç»“æœ",
                                interactive=False
                            )

                    # äº‹ä»¶ç»‘å®š
                    llm_refresh_btn.click(
                        fn=lambda: self.load_llm_configs(),
                        inputs=[],
                        outputs=[llm_configs_table]
                    )

                    llm_create_btn.click(
                        fn=lambda name, provider, api_key, api_base_url, model_name, max_tokens, temperature, top_p, is_default: self.create_llm_config(
                            name, provider, api_key, api_base_url, model_name, max_tokens, temperature, top_p, is_default
                        ),
                        inputs=[
                            llm_name, llm_provider, llm_api_key, llm_api_base_url,
                            llm_model_name, llm_max_tokens, llm_temperature, llm_top_p,
                            llm_is_default
                        ],
                        outputs=[llm_result, llm_configs_table]
                    )

                    llm_delete_btn.click(
                        fn=lambda config_id: self.delete_llm_config(config_id),
                        inputs=[llm_delete_id],
                        outputs=[llm_result, llm_configs_table]
                    )

                # Tab 2: Agent æç¤ºè¯æ¨¡ç‰ˆç®¡ç†
                with gr.Tab("Agent æç¤ºè¯æ¨¡ç‰ˆ"):
                    gr.Markdown("### Agent æç¤ºè¯æ¨¡ç‰ˆç®¡ç†")
                    gr.Markdown("ç®¡ç†å¯å¤ç”¨çš„ Agent æç¤ºè¯æ¨¡ç‰ˆ")

                    with gr.Row():
                        # å·¦ä¾§ï¼šæ¨¡ç‰ˆåˆ—è¡¨
                        with gr.Column(scale=2):
                            prompt_templates_table = gr.DataFrame(
                                value=self.load_prompt_templates(),
                                label="æç¤ºè¯æ¨¡ç‰ˆåˆ—è¡¨",
                                interactive=False
                            )

                            with gr.Row():
                                prompt_refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", size="sm")
                                prompt_delete_id = gr.Number(
                                    label="æ¨¡ç‰ˆ ID",
                                    value=0,
                                    minimum=0,
                                    scale=1
                                )
                                prompt_delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤", variant="stop", size="sm")

                        # å³ä¾§ï¼šåˆ›å»ºæ¨¡ç‰ˆ
                        with gr.Column(scale=3):
                            gr.Markdown("#### æ–°å»ºæç¤ºè¯æ¨¡ç‰ˆ")

                            prompt_name = gr.Textbox(
                                label="æ¨¡ç‰ˆåç§°",
                                placeholder="ä¾‹å¦‚ï¼šä¿å®ˆå‹ç­–ç•¥"
                            )

                            prompt_category = gr.Dropdown(
                                label="åˆ†ç±»",
                                choices=["conservative", "aggressive", "balanced", "custom"],
                                value="balanced"
                            )

                            prompt_description = gr.Textbox(
                                label="æ¨¡ç‰ˆæè¿°",
                                placeholder="ç®€è¦æè¿°æ­¤æ¨¡ç‰ˆçš„ç”¨é€”å’Œç‰¹ç‚¹",
                                lines=2
                            )

                            prompt_content = gr.Textbox(
                                label="æç¤ºè¯å†…å®¹",
                                placeholder="è¾“å…¥è¯¦ç»†çš„ Agent æç¤ºè¯...",
                                lines=10
                            )

                            prompt_is_default = gr.Checkbox(
                                label="è®¾ä¸ºé»˜è®¤æ¨¡ç‰ˆ",
                                value=False
                            )

                            prompt_create_btn = gr.Button("â• åˆ›å»ºæ¨¡ç‰ˆ", variant="primary")

                            prompt_result = gr.Textbox(
                                label="æ“ä½œç»“æœ",
                                interactive=False
                            )

                    # äº‹ä»¶ç»‘å®š
                    prompt_refresh_btn.click(
                        fn=lambda: self.load_prompt_templates(),
                        inputs=[],
                        outputs=[prompt_templates_table]
                    )

                    prompt_create_btn.click(
                        fn=lambda name, content, description, category, is_default: self.create_prompt_template(
                            name, content, description, category, is_default
                        ),
                        inputs=[
                            prompt_name, prompt_content, prompt_description,
                            prompt_category, prompt_is_default
                        ],
                        outputs=[prompt_result, prompt_templates_table]
                    )

                    prompt_delete_btn.click(
                        fn=lambda template_id: self.delete_prompt_template(template_id),
                        inputs=[prompt_delete_id],
                        outputs=[prompt_result, prompt_templates_table]
                    )


def create_config_center_ui():
    """åˆ›å»ºé…ç½®ä¸­å¿ƒç•Œé¢"""
    ui = ConfigCenterUI()
    return ui.build_ui()
