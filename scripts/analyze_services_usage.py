#!/usr/bin/env python3
"""
åˆ†æ services ç›®å½•ä¸‹å„æœåŠ¡çš„ä½¿ç”¨æƒ…å†µ
è¯†åˆ«å†—ä½™ã€è¿‡æœŸå’Œå¤±æ•ˆçš„ä»£ç 
"""

import os
import re
import ast
import sys
from pathlib import Path
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

class ServiceAnalyzer:
    """æœåŠ¡ä½¿ç”¨æƒ…å†µåˆ†æå™¨"""

    def __init__(self):
        self.services_dir = Path(__file__).parent.parent / "services"
        self.project_root = Path(__file__).parent.parent
        self.import_graph = defaultdict(set)
        self.service_stats = {}
        self.redundant_files = []
        self.outdated_files = []

    def analyze_service(self, service_path):
        """åˆ†æå•ä¸ªæœåŠ¡æ–‡ä»¶"""
        service_name = service_path.stem
        stats = {
            'name': service_name,
            'path': str(service_path),
            'size': service_path.stat().st_size,
            'lines': 0,
            'classes': [],
            'functions': [],
            'imports': [],
            'exported_names': [],
            'used_by': set(),
            'uses': set(),
            'is_entry_point': False,
            'is_test': False,
            'has_main': False,
            'last_modified': service_path.stat().st_mtime
        }

        try:
            with open(service_path, 'r', encoding='utf-8') as f:
                content = f.read()
                stats['lines'] = len(content.splitlines())

            # è§£æ AST
            tree = ast.parse(content)

            # æå–ç±»å’Œå‡½æ•°
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    stats['classes'].append(node.name)
                elif isinstance(node, ast.FunctionDef):
                    stats['functions'].append(node.name)

            # æå–å¯¼å…¥å’Œå¯¼å‡º
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        stats['imports'].append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        for alias in node.names:
                            if alias.name == '*':
                                stats['imports'].append(f"{node.module}.*")
                            else:
                                stats['imports'].append(f"{node.module}.{alias.name}")

            # æ£€æŸ¥ç‰¹æ®Šæ ‡è®°
            if '__main__' in content:
                stats['has_main'] = True

            if 'test' in service_name.lower() or 'Test' in content:
                stats['is_test'] = True

        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶å¤±è´¥ {service_path}: {e}")

        return stats

    def find_imports_in_project(self):
        """åœ¨æ•´ä¸ªé¡¹ç›®ä¸­æŸ¥æ‰¾å¯¼å…¥å…³ç³»"""
        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files:
            if file_path == Path(__file__):
                continue  # è·³è¿‡åˆ†æè„šæœ¬æœ¬èº«

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # æŸ¥æ‰¾å¯¹ services æ¨¡å—çš„å¯¼å…¥
                pattern = r'from\s+services\.(\w+)(?:\.(\w+))?\s+import'
                matches = re.findall(pattern, content)

                for match in matches:
                    service_name = match[0]
                    imported_name = match[1] if match[1] else ''

                    # è®°å½•ä¾èµ–å…³ç³»
                    if service_name in self.service_stats:
                        self.service_stats[service_name]['used_by'].add(str(file_path.relative_to(self.project_root)))

                        # è®°å½•å¯¼å‡ºçš„åç§°
                        if imported_name and imported_name not in self.service_stats[service_name]['exported_names']:
                            self.service_stats[service_name]['exported_names'].append(imported_name)

            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    def identify_redundant_files(self):
        """è¯†åˆ«å†—ä½™æ–‡ä»¶"""
        for service_name, stats in self.service_stats.items():
            # è·³è¿‡æ ¸å¿ƒæ–‡ä»¶
            if service_name in ['__init__', 'unified_scheduler', 'scheduler_config']:
                continue

            # æ£€æŸ¥æ˜¯å¦è¢«ä½¿ç”¨
            is_used = len(stats['used_by']) > 0
            is_scheduler_related = service_name in ['scheduler_service', 'schedule_service']
            is_agent_related = 'agent' in service_name.lower()
            is_ws_related = 'ws' in service_name.lower() or 'websocket' in service_name.lower()

            # ç‰¹æ®Šæ£€æŸ¥ï¼šè°ƒåº¦å™¨æœåŠ¡å·²è¢«ç»Ÿä¸€è°ƒåº¦å™¨æ›¿ä»£
            if is_scheduler_related:
                stats['redundant_reason'] = "å·²è¢« unified_scheduler æ›¿ä»£"
                self.redundant_files.append(stats)

            # æ£€æŸ¥é‡å¤çš„ WebSocket ç›¸å…³æœåŠ¡
            elif is_ws_related and len([s for s in self.service_stats.keys() if 'ws' in s.lower() or 'websocket' in s.lower()]) > 1:
                # æ£€æŸ¥åŠŸèƒ½é‡å¤
                if service_name in ['ws_data_service'] and not is_used:  # å¯èƒ½çš„é‡å¤
                    stats['redundant_reason'] = "WebSocket æ•°æ®æœåŠ¡å¯èƒ½ä¸å…¶ä»–æœåŠ¡é‡å¤"
                    self.redundant_files.append(stats)

            # æ£€æŸ¥æœªä½¿ç”¨çš„æ–‡ä»¶
            elif not is_used and not stats['is_entry_point']:
                if not service_name.endswith('_service') or len(stats['classes']) == 0:
                    stats['redundant_reason'] = "æœªè¢«ä½¿ç”¨ä¸”éæœåŠ¡ç±»æ–‡ä»¶"
                    self.redundant_files.append(stats)

    def identify_potentially_outdated(self):
        """è¯†åˆ«å¯èƒ½è¿‡æ—¶çš„æ–‡ä»¶"""
        current_time = Path(__file__).stat().st_mtime
        thirty_days_ago = current_time - (30 * 24 * 60 * 60)

        for service_name, stats in self.service_stats.items():
            # è·³è¿‡æ ¸å¿ƒæ–‡ä»¶å’Œå·²è¯†åˆ«çš„å†—ä½™æ–‡ä»¶
            if service_name in ['__init__', 'unified_scheduler', 'scheduler_config']:
                continue
            if stats in self.redundant_files:
                continue

            # æ£€æŸ¥æ˜¯å¦é•¿æ—¶é—´æœªä¿®æ”¹
            if stats['last_modified'] < thirty_days_ago:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«åºŸå¼ƒæ ‡è®°
                try:
                    with open(stats['path'], 'r', encoding='utf-8') as f:
                        content = f.read()

                    outdated_indicators = [
                        'DEPRECATED',
                        'TODO: remove',
                        'FIXME: obsolete',
                        '# LEGACY',
                        '# @deprecated'
                    ]

                    if any(indicator in content for indicator in outdated_indicators):
                        stats['outdated_reason'] = "åŒ…å«åºŸå¼ƒæ ‡è®°"
                        self.outdated_files.append(stats)

                except Exception:
                    pass

    def check_for_similar_services(self):
        """æ£€æŸ¥åŠŸèƒ½ç›¸ä¼¼çš„æœåŠ¡"""
        # æ£€æŸ¥ WebSocket ç›¸å…³æœåŠ¡
        ws_services = [name for name in self.service_stats.keys()
                      if any(keyword in name.lower() for keyword in ['ws', 'websocket', 'connection'])]

        # æ£€æŸ¥ Agent ç›¸å…³æœåŠ¡
        agent_services = [name for name in self.service_stats.keys()
                         if 'agent' in name.lower()]

        # æ£€æŸ¥æ•°æ®ç›¸å…³æœåŠ¡
        data_services = [name for name in self.service_stats.keys()
                        if any(keyword in name.lower() for keyword in ['data', 'sync'])]

        return {
            'websocket_services': ws_services,
            'agent_services': agent_services,
            'data_services': data_services
        }

    def analyze(self):
        """æ‰§è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ” å¼€å§‹åˆ†æ services ç›®å½•...")

        # åˆ†ææ‰€æœ‰æœåŠ¡æ–‡ä»¶
        for service_file in self.services_dir.glob("*.py"):
            if service_file.name == "__init__.py":
                continue

            stats = self.analyze_service(service_file)
            self.service_stats[service_file.stem] = stats

        print(f"âœ… åˆ†æäº† {len(self.service_stats)} ä¸ªæœåŠ¡æ–‡ä»¶")

        # æŸ¥æ‰¾å¯¼å…¥å…³ç³»
        print("ğŸ”— åˆ†æé¡¹ç›®ä¸­çš„å¯¼å…¥å…³ç³»...")
        self.find_imports_in_project()

        # è¯†åˆ«å†—ä½™æ–‡ä»¶
        print("ğŸ” è¯†åˆ«å†—ä½™æ–‡ä»¶...")
        self.identify_redundant_files()

        # è¯†åˆ«è¿‡æ—¶æ–‡ä»¶
        print("ğŸ“… è¯†åˆ«è¿‡æ—¶æ–‡ä»¶...")
        self.identify_potentially_outdated()

        # æ£€æŸ¥ç›¸ä¼¼æœåŠ¡
        print("ğŸ”€ æ£€æŸ¥ç›¸ä¼¼æœåŠ¡...")
        similar_services = self.check_for_similar_services()

        return {
            'total_services': len(self.service_stats),
            'redundant_files': self.redundant_files,
            'outdated_files': self.outdated_files,
            'similar_services': similar_services,
            'service_stats': self.service_stats
        }

    def print_report(self, results):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“Š SERVICES ç›®å½•åˆ†ææŠ¥å‘Š")
        print("=" * 80)

        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  æ€»æœåŠ¡æ–‡ä»¶æ•°: {results['total_services']}")

        print(f"\nğŸ—‘ï¸  å†—ä½™æ–‡ä»¶ ({len(results['redundant_files'])} ä¸ª):")
        if results['redundant_files']:
            for file_info in results['redundant_files']:
                print(f"  âŒ {file_info['name']}")
                print(f"     åŸå› : {file_info.get('redundant_reason', 'æœªçŸ¥')}")
                print(f"     å¤§å°: {file_info['size']} bytes")
                print(f"     è¡Œæ•°: {file_info['lines']}")
        else:
            print("  âœ… æœªå‘ç°å†—ä½™æ–‡ä»¶")

        print(f"\nğŸ“… è¿‡æ—¶æ–‡ä»¶ ({len(results['outdated_files'])} ä¸ª):")
        if results['outdated_files']:
            for file_info in results['outdated_files']:
                print(f"  âš ï¸  {file_info['name']}")
                print(f"     åŸå› : {file_info.get('outdated_reason', 'æœªçŸ¥')}")
        else:
            print("  âœ… æœªå‘ç°è¿‡æ—¶æ–‡ä»¶")

        print(f"\nğŸ”€ ç›¸ä¼¼åŠŸèƒ½æœåŠ¡:")
        for category, services in results['similar_services'].items():
            if len(services) > 1:
                print(f"  {category}: {', '.join(services)}")

        print(f"\nğŸ“‹ ä½¿ç”¨æƒ…å†µç»Ÿè®¡:")
        unused_count = 0
        for name, stats in results['service_stats'].items():
            if not stats['used_by'] and not stats['is_entry_point'] and name not in ['__init__']:
                unused_count += 1

        print(f"  æœªè¢«ä½¿ç”¨çš„æœåŠ¡: {unused_count} ä¸ª")

        if unused_count > 0:
            print("\n  æœªä½¿ç”¨çš„æœåŠ¡åˆ—è¡¨:")
            for name, stats in results['service_stats'].items():
                if not stats['used_by'] and not stats['is_entry_point'] and name not in ['__init__']:
                    print(f"    - {name} ({stats['lines']} lines)")

    def generate_removal_plan(self, results):
        """ç”Ÿæˆå®‰å…¨çš„ç§»é™¤è®¡åˆ’"""
        plan = {
            'safe_to_remove': [],
            'needs_review': [],
            'keep': []
        }

        for file_info in results['redundant_files']:
            # è°ƒåº¦å™¨æœåŠ¡å·²è¢«ç»Ÿä¸€è°ƒåº¦å™¨æ›¿ä»£ï¼Œå¯ä»¥å®‰å…¨ç§»é™¤
            if file_info['name'] in ['scheduler_service', 'schedule_service']:
                # ç­‰å¾…ç¡®è®¤åå†ç§»é™¤
                plan['needs_review'].append({
                    'file': file_info['name'],
                    'reason': 'è°ƒåº¦å™¨æœåŠ¡å·²è¢«ç»Ÿä¸€è°ƒåº¦å™¨æ›¿ä»£',
                    'action': 'ç§»é™¤ï¼ˆç¡®è®¤ç»Ÿä¸€è°ƒåº¦å™¨æ­£å¸¸å·¥ä½œåï¼‰',
                    'dependencies': file_info['used_by']
                })

        return plan

def main():
    """ä¸»å‡½æ•°"""
    analyzer = ServiceAnalyzer()
    results = analyzer.analyze()

    # æ‰“å°æŠ¥å‘Š
    analyzer.print_report(results)

    # ç”Ÿæˆç§»é™¤è®¡åˆ’
    print(f"\n" + "=" * 80)
    print("ğŸ—‘ï¸  æ¸…ç†å»ºè®®")
    print("=" * 80)

    removal_plan = analyzer.generate_removal_plan(results)

    print(f"\nğŸ” éœ€è¦äººå·¥å®¡æŸ¥çš„æ–‡ä»¶:")
    for item in removal_plan['needs_review']:
        print(f"  ğŸ“ {item['file']}.py")
        print(f"     åŸå› : {item['reason']}")
        print(f"     å»ºè®®: {item['action']}")
        if item['dependencies']:
            print(f"     è¢«ä»¥ä¸‹æ–‡ä»¶å¼•ç”¨: {', '.join(item['dependencies'])}")
        print()

    return results

if __name__ == "__main__":
    main()