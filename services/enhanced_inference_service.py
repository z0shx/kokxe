"""
å¢å¼ºçš„æ¨ç†æœåŠ¡ V2 - å®Œå…¨é‡æ„ç‰ˆæœ¬
å½»åº•è§£å†³thinkingå’Œæ–‡æœ¬æ··åˆé—®é¢˜
"""
import json
import asyncio
from typing import Dict, List, AsyncGenerator, Optional
from database.models import TradingPlan, PredictionData
from database.db import get_db
from utils.logger import setup_logger
from services.enhanced_conversation_service import enhanced_conversation_service, ConversationType
from services.enhanced_agent_stream_service import enhanced_agent_stream_service

logger = setup_logger(__name__, "enhanced_inference_v2.log")


class EnhancedInferenceServiceV2:
    """å¢å¼ºçš„æ¨ç†æœåŠ¡ - V2 å®Œå…¨é‡æ„ç‰ˆæœ¬"""

    @classmethod
    async def execute_manual_inference(cls, plan_id: int) -> AsyncGenerator[List[Dict], None]:
        """
        æ‰§è¡Œæ‰‹åŠ¨æ¨ç† - V2ç‰ˆæœ¬ï¼Œå®Œå…¨åˆ†ç¦»thinkingå’Œæ­£æ–‡

        Args:
            plan_id: è®¡åˆ’ID

        Yields:
            Chatbotæ¶ˆæ¯åˆ—è¡¨ - æ¯æ¬¡åªæ›´æ–°ä¸€ä¸ªéƒ¨åˆ†ï¼Œé¿å…æ··åˆ
        """
        try:
            # 1. åˆå§‹åŒ–å¯¹è¯ï¼ˆé‡ç½®ä¸Šä¸‹æ–‡ï¼‰
            conversation_id = await enhanced_agent_stream_service.initialize_conversation(
                plan_id=plan_id,
                conversation_type=ConversationType.AUTO_INFERENCE,
                reset_context=True
            )

            # 2. æ·»åŠ é¢„æµ‹æ•°æ®æ¶ˆæ¯
            prediction_success = await enhanced_agent_stream_service.add_prediction_data_message(
                conversation_id=conversation_id,
                plan_id=plan_id,
                trigger_event="manual_inference"
            )

            if not prediction_success:
                yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ"}]
                return

            # 3. è·å–å½“å‰å¯¹è¯çŠ¶æ€ç”¨äºæ˜¾ç¤ºï¼ˆå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
            current_messages = enhanced_conversation_service.get_conversation_messages(conversation_id)
            formatted_messages = enhanced_conversation_service.format_for_chatbot(current_messages)

            # ç«‹å³è¿”å›å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬ç³»ç»Ÿæç¤ºè¯å’Œé¢„æµ‹æ•°æ®ï¼‰
            yield formatted_messages

            # 4. å¼€å§‹AIåˆ†æå¯¹è¯ - å®Œå…¨é‡æ„çš„æµå¼å¤„ç†
            thinking_complete = False
            analysis_complete = False

            # çŠ¶æ€è·Ÿè¸ª
            current_thinking_display = ""
            current_analysis_display = ""
            last_sent_message = None

            async for chunk_str in enhanced_agent_stream_service.chat_with_tools_stream(
                conversation_id=conversation_id,
                user_message="",  # ç©ºæ¶ˆæ¯ï¼Œè®©AIåŸºäºé¢„æµ‹æ•°æ®è¿›è¡Œåˆ†æ
                use_thinking_mode=True
            ):
                try:
                    chunk_data = json.loads(chunk_str)
                    chunk_type = chunk_data.get("type", "")
                    chunk_content = chunk_data.get("content", "")

                    should_send_update = False
                    new_message = None

                    if chunk_type == "thinking":
                        # å¤„ç†thinkingå¢é‡
                        current_thinking_display += chunk_content
                        thinking_complete = False

                        # åªå‘é€thinkingéƒ¨åˆ†ï¼Œä¸åŒ…å«analysis
                        new_message = {
                            "role": "assistant",
                            "content": cls._format_thinking_section(current_thinking_display),
                            "metadata": {
                                "streaming": True,
                                "section": "thinking",
                                "complete": False,
                                "has_analysis": bool(current_analysis_display)
                            }
                        }
                        should_send_update = True

                    elif chunk_type == "content":
                        # å¤„ç†analysiså¢é‡
                        current_analysis_display += chunk_content
                        analysis_complete = False
                        thinking_complete = True  # å¼€å§‹analysisæ„å‘³ç€thinkingå¯èƒ½å®Œæˆäº†

                        # æ„å»ºå®Œæ•´æ˜¾ç¤ºï¼šthinking + analysis
                        display_content = cls._build_combined_display(
                            current_thinking_display,
                            current_analysis_display
                        )

                        new_message = {
                            "role": "assistant",
                            "content": display_content,
                            "metadata": {
                                "streaming": True,
                                "section": "combined",
                                "thinking_complete": thinking_complete,
                                "analysis_complete": False,
                                "has_thinking": bool(current_thinking_display),
                                "has_analysis": bool(current_analysis_display)
                            }
                        }
                        should_send_update = True

                    elif chunk_type in ["tool_call", "tool_result", "error"]:
                        # å¤„ç†å·¥å…·ç›¸å…³æ¶ˆæ¯
                        tool_content = cls._format_tool_message(chunk_data)
                        current_analysis_display += tool_content

                        # é‡æ–°æ„å»ºå®Œæ•´æ˜¾ç¤º
                        display_content = cls._build_combined_display(
                            current_thinking_display,
                            current_analysis_display
                        )

                        new_message = {
                            "role": "assistant",
                            "content": display_content,
                            "metadata": {
                                "streaming": True,
                                "section": "tool_update",
                                "tool_type": chunk_type,
                                "thinking_complete": thinking_complete,
                                "analysis_complete": False,
                                "has_thinking": bool(current_thinking_display),
                                "has_analysis": bool(current_analysis_display)
                            }
                        }
                        should_send_update = True

                    # åªæœ‰å½“éœ€è¦æ›´æ–°ä¸”å†…å®¹ç¡®å®å‘ç”Ÿå˜åŒ–æ—¶æ‰å‘é€
                    if should_send_update and new_message:
                        # é¿å…å‘é€é‡å¤å†…å®¹
                        if not last_sent_message or new_message["content"] != last_sent_message["content"]:
                            response_messages = formatted_messages + [new_message]
                            yield response_messages
                            last_sent_message = new_message

                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†æ¨ç†å—å¤±è´¥: {e}")
                    continue

            # 5. æ¨ç†å®Œæˆ - å‘é€æœ€ç»ˆå®Œæˆæ¶ˆæ¯
            thinking_complete = True
            analysis_complete = True

            # æ„å»ºæœ€ç»ˆå®Œæ•´æ˜¾ç¤º
            final_content = cls._build_final_display(
                current_thinking_display,
                current_analysis_display
            )

            final_message = {
                "role": "assistant",
                "content": final_content,
                "metadata": {
                    "completed": True,
                    "final": True,
                    "thinking_complete": True,
                    "analysis_complete": True,
                    "has_thinking": bool(current_thinking_display),
                    "has_analysis": bool(current_analysis_display)
                }
            }

            final_response = formatted_messages + [final_message]
            yield final_response

        except Exception as e:
            logger.error(f"æ‰§è¡Œæ‰‹åŠ¨æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            yield [{"role": "assistant", "content": f"âŒ æ¨ç†è¿‡ç¨‹å‡ºé”™: {str(e)}"}]

    @classmethod
    def _format_thinking_section(cls, thinking_content: str) -> str:
        """æ ¼å¼åŒ–thinkingéƒ¨åˆ†ï¼Œä½¿ç”¨æŠ˜å æ˜¾ç¤º"""
        if not thinking_content.strip():
            return ""

        return f"<details>\n<summary>ğŸ§  AIæ€è€ƒè¿‡ç¨‹</summary>\n\n{thinking_content}\n</details>"

    @classmethod
    def _build_combined_display(cls, thinking_content: str, analysis_content: str) -> str:
        """æ„å»ºç»„åˆæ˜¾ç¤ºï¼šthinking + analysis"""
        parts = []

        # æ·»åŠ thinkingéƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
        if thinking_content.strip():
            parts.append(cls._format_thinking_section(thinking_content))

        # æ·»åŠ analysiséƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
        if analysis_content.strip():
            if parts:  # å¦‚æœå·²æœ‰thinkingï¼Œæ·»åŠ åˆ†éš”ç¬¦
                parts.append("\n\n---\n\n")
            parts.append(analysis_content)

        # å¦‚æœéƒ½æ²¡æœ‰å†…å®¹ï¼Œæ˜¾ç¤ºå ä½ç¬¦
        if not parts:
            return "ğŸ¤” AIæ­£åœ¨æ€è€ƒä¸­..."

        return "".join(parts)

    @classmethod
    def _build_final_display(cls, thinking_content: str, analysis_content: str) -> str:
        """æ„å»ºæœ€ç»ˆå®Œæˆæ˜¾ç¤º"""
        parts = []

        # æ·»åŠ thinkingéƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
        if thinking_content.strip():
            parts.append(f"<details>\n<summary>ğŸ§  AIæ€è€ƒè¿‡ç¨‹</summary>\n\n{thinking_content}\n\nâœ… æ€è€ƒå®Œæˆ\n</details>")

        # æ·»åŠ analysiséƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
        if analysis_content.strip():
            if parts:
                parts.append("\n\n---\n\n")
            parts.append(analysis_content + "\n\nâœ… **æ¨ç†å®Œæˆ**")

        # å¦‚æœéƒ½æ²¡æœ‰å†…å®¹ï¼Œæ˜¾ç¤ºå®Œæˆæ¶ˆæ¯
        if not parts:
            return "âœ… æ¨ç†å®Œæˆ"

        return "".join(parts)

    @classmethod
    def _format_tool_message(cls, chunk_data: Dict) -> str:
        """æ ¼å¼åŒ–å·¥å…·æ¶ˆæ¯"""
        chunk_type = chunk_data.get("type", "")

        if chunk_type == "tool_call":
            tool_name = chunk_data.get("tool_name", "æœªçŸ¥å·¥å…·")
            arguments = chunk_data.get("arguments", {})
            args_str = json.dumps(arguments, indent=2, ensure_ascii=False)
            return f"\n\nğŸ› ï¸ **å·¥å…·è°ƒç”¨**: `{tool_name}`\n\nğŸ“‹ **å‚æ•°**:\n```json\n{args_str}\n```\n\nâ³ æ­£åœ¨æ‰§è¡Œ..."

        elif chunk_type == "tool_result":
            tool_name = chunk_data.get("tool_name", "æœªçŸ¥å·¥å…·")
            result = chunk_data.get("result", {})
            success = result.get("success", False)
            status_emoji = "âœ…" if success else "âŒ"
            result_str = json.dumps(result, indent=2, ensure_ascii=False)
            return f"\n\nğŸ› ï¸ **å·¥å…·æ‰§è¡Œç»“æœ**: `{tool_name}` {status_emoji}\n\n```json\n{result_str}\n```\n\nğŸ”„ ç»§ç»­åˆ†æ..."

        elif chunk_type == "error":
            error_msg = chunk_data.get("content", "æœªçŸ¥é”™è¯¯")
            return f"\n\nâŒ **æ¨ç†é”™è¯¯**: {error_msg}"

        return ""

    @classmethod
    async def continue_conversation(
        cls,
        plan_id: int,
        user_message: str,
        conversation_type: ConversationType = ConversationType.MANUAL_CHAT
    ) -> AsyncGenerator[List[Dict], None]:
        """
        ç»§ç»­å¯¹è¯ - V2ç‰ˆæœ¬ï¼Œå®Œå…¨åˆ†ç¦»thinkingå’Œæ­£æ–‡
        """
        try:
            # è·å–æˆ–åˆ›å»ºå¯¹è¯ä¼šè¯
            conversation_id = await enhanced_agent_stream_service.initialize_conversation(
                plan_id=plan_id,
                conversation_type=conversation_type,
                reset_context=False
            )

            # è·å–å¯¹è¯å†å²
            current_messages = enhanced_conversation_service.get_conversation_messages(conversation_id)
            formatted_messages = enhanced_conversation_service.format_for_chatbot(current_messages)

            # ç«‹å³è¿”å›å†å²æ¶ˆæ¯
            yield formatted_messages

            # å¼€å§‹æµå¼å¯¹è¯ - ä½¿ç”¨ç›¸åŒçš„åˆ†ç¦»é€»è¾‘
            thinking_complete = False
            analysis_complete = False
            current_thinking_display = ""
            current_analysis_display = ""
            last_sent_message = None

            async for chunk_str in enhanced_agent_stream_service.chat_with_tools_stream(
                conversation_id=conversation_id,
                user_message=user_message,
                use_thinking_mode=True
            ):
                try:
                    chunk_data = json.loads(chunk_str)
                    chunk_type = chunk_data.get("type", "")
                    chunk_content = chunk_data.get("content", "")

                    should_send_update = False
                    new_message = None

                    if chunk_type == "thinking":
                        current_thinking_display += chunk_content
                        thinking_complete = False

                        new_message = {
                            "role": "assistant",
                            "content": cls._format_thinking_section(current_thinking_display),
                            "metadata": {
                                "streaming": True,
                                "section": "thinking",
                                "complete": False,
                                "has_analysis": bool(current_analysis_display)
                            }
                        }
                        should_send_update = True

                    elif chunk_type == "content":
                        current_analysis_display += chunk_content
                        analysis_complete = False
                        thinking_complete = True

                        display_content = cls._build_combined_display(
                            current_thinking_display,
                            current_analysis_display
                        )

                        new_message = {
                            "role": "assistant",
                            "content": display_content,
                            "metadata": {
                                "streaming": True,
                                "section": "combined",
                                "thinking_complete": thinking_complete,
                                "analysis_complete": False,
                                "has_thinking": bool(current_thinking_display),
                                "has_analysis": bool(current_analysis_display)
                            }
                        }
                        should_send_update = True

                    elif chunk_type in ["tool_call", "tool_result", "error"]:
                        tool_content = cls._format_tool_message(chunk_data)
                        current_analysis_display += tool_content

                        display_content = cls._build_combined_display(
                            current_thinking_display,
                            current_analysis_display
                        )

                        new_message = {
                            "role": "assistant",
                            "content": display_content,
                            "metadata": {
                                "streaming": True,
                                "section": "tool_update",
                                "tool_type": chunk_type,
                                "thinking_complete": thinking_complete,
                                "analysis_complete": False,
                                "has_thinking": bool(current_thinking_display),
                                "has_analysis": bool(current_analysis_display)
                            }
                        }
                        should_send_update = True

                    if should_send_update and new_message:
                        if not last_sent_message or new_message["content"] != last_sent_message["content"]:
                            response_messages = formatted_messages + [new_message]
                            yield response_messages
                            last_sent_message = new_message

                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†å¯¹è¯å—å¤±è´¥: {e}")
                    continue

            # å¯¹è¯å®Œæˆ
            thinking_complete = True
            analysis_complete = True

            final_content = cls._build_final_display(
                current_thinking_display,
                current_analysis_display
            )

            final_message = {
                "role": "assistant",
                "content": final_content,
                "metadata": {
                    "completed": True,
                    "final": True,
                    "thinking_complete": True,
                    "analysis_complete": True,
                    "has_thinking": bool(current_thinking_display),
                    "has_analysis": bool(current_analysis_display)
                }
            }

            final_response = formatted_messages + [final_message]
            yield final_response

        except Exception as e:
            logger.error(f"ç»§ç»­å¯¹è¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            yield [{"role": "assistant", "content": f"âŒ å¯¹è¯è¿‡ç¨‹å‡ºé”™: {str(e)}"}]

    @classmethod
    def get_latest_prediction_data(cls, plan_id: int) -> Optional[PredictionData]:
        """è·å–æœ€æ–°çš„é¢„æµ‹æ•°æ®"""
        try:
            with get_db() as db:
                return db.query(PredictionData).filter(
                    PredictionData.plan_id == plan_id,
                    PredictionData.status == "success"
                ).order_by(PredictionData.created_at.desc()).first()

        except Exception as e:
            logger.error(f"è·å–æœ€æ–°é¢„æµ‹æ•°æ®å¤±è´¥: {e}")
            return None


# åˆ›å»ºå…¨å±€å®ä¾‹
enhanced_inference_service = EnhancedInferenceServiceV2()