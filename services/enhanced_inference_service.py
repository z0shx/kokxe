"""
å¢å¼ºçš„æ¨ç†æœåŠ¡
é‡æ„ç‰ˆï¼šä½¿ç”¨æ–°çš„å¯¹è¯ç®¡ç†å’Œæµå¼æœåŠ¡
"""
import json
import asyncio
from typing import Dict, List, AsyncGenerator, Optional
from database.models import TradingPlan, PredictionData
from database.db import get_db
from utils.logger import setup_logger
from services.enhanced_conversation_service import enhanced_conversation_service, ConversationType
from services.enhanced_agent_stream_service import enhanced_agent_stream_service
from services.kline_event_service import kline_event_service

logger = setup_logger(__name__, "enhanced_inference.log")


class EnhancedInferenceService:
    """å¢å¼ºçš„æ¨ç†æœåŠ¡"""

    @classmethod
    async def execute_manual_inference(cls, plan_id: int) -> AsyncGenerator[List[Dict], None]:
        """
        æ‰§è¡Œæ‰‹åŠ¨æ¨ç†

        Args:
            plan_id: è®¡åˆ’ID

        Yields:
            Chatbotæ¶ˆæ¯åˆ—è¡¨
        """
        try:
            # 1. åˆå§‹åŒ–å¯¹è¯ï¼ˆé‡ç½®ä¸Šä¸‹æ–‡ï¼‰
            conversation_id = await enhanced_agent_stream_service.initialize_conversation(
                plan_id=plan_id,
                conversation_type=ConversationType.AUTO_INFERENCE,
                reset_context=True
            )

            # 2. æ·»åŠ é¢„æµ‹æ•°æ®æ¶ˆæ¯
            prediction_success = await enhanced_agent_stream_service.add_prediction_data_message(
                conversation_id=conversation_id,
                plan_id=plan_id,
                trigger_event="manual_inference"
            )

            if not prediction_success:
                yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ"}]
                return

            # 3. è·å–å½“å‰å¯¹è¯çŠ¶æ€ç”¨äºæ˜¾ç¤ºï¼ˆå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
            current_messages = enhanced_conversation_service.get_conversation_messages(conversation_id)
            formatted_messages = enhanced_conversation_service.format_for_chatbot(current_messages)

            # ç«‹å³è¿”å›å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬ç³»ç»Ÿæç¤ºè¯å’Œé¢„æµ‹æ•°æ®ï¼‰
            yield formatted_messages

            # 4. å¼€å§‹AIåˆ†æå¯¹è¯
            thinking_content = ""      # åˆ†ç¦»thinkingå†…å®¹
            analysis_content = ""      # åˆ†ç¦»æ­£æ–‡åˆ†æå†…å®¹
            chunk_count = 0
            thinking_completed = False  # æ ‡è®°thinkingæ˜¯å¦å®Œæˆ

            async for chunk_str in enhanced_agent_stream_service.chat_with_tools_stream(
                conversation_id=conversation_id,
                user_message="",  # ç©ºæ¶ˆæ¯ï¼Œè®©AIåŸºäºé¢„æµ‹æ•°æ®è¿›è¡Œåˆ†æ
                use_thinking_mode=True
            ):
                try:
                    chunk_data = json.loads(chunk_str)
                    chunk_type = chunk_data.get("type", "")
                    content = chunk_data.get("content", "")
                    chunk_count = chunk_data.get("chunk_count", 0)

                    # åˆ†åˆ«å¤„ç†thinkingå’Œæ­£æ–‡å†…å®¹
                    if chunk_type == "thinking_start":
                        thinking_content = "ğŸ§  **AIæ€è€ƒè¿‡ç¨‹**\n\n"
                        thinking_completed = False

                    elif chunk_type == "thinking":
                        # ç´¯ç§¯thinkingå†…å®¹
                        thinking_content += content
                        thinking_completed = False

                    elif chunk_type == "content":
                        # æ­£æ–‡å¼€å§‹ï¼Œæ ‡è®°thinkingå®Œæˆ
                        if not thinking_completed:
                            thinking_completed = True

                        # ç´¯ç§¯æ­£æ–‡å†…å®¹
                        if analysis_content:
                            # å¦‚æœå·²æœ‰å†…å®¹ï¼Œæ·»åŠ åˆ†éš”ç¬¦
                            analysis_content += "\n\n" + content
                        else:
                            analysis_content = content

                    elif chunk_type == "tool_call_start":
                        thinking_completed = True  # å·¥å…·è°ƒç”¨å¼€å§‹æ—¶thinkingåº”è¯¥å®Œæˆ
                        tool_name = chunk_data.get("tool_name", "")
                        tool_section = f"\n\nğŸ› ï¸ **è°ƒç”¨å·¥å…·**: `{tool_name}`\n\nâ³ æ­£åœ¨æ‰§è¡Œ..."

                        if analysis_content:
                            analysis_content += tool_section
                        else:
                            analysis_content = tool_section

                    elif chunk_type == "tool_call":
                        thinking_completed = True
                        tool_name = chunk_data.get("tool_name", "")
                        arguments = chunk_data.get("arguments", {})
                        args_str = json.dumps(arguments, indent=2, ensure_ascii=False)
                        tool_section = f"\n\nğŸ› ï¸ **å·¥å…·è°ƒç”¨**: `{tool_name}`\n\nğŸ“‹ **å‚æ•°**:\n```json\n{args_str}\n```\n\nâ³ æ­£åœ¨æ‰§è¡Œ..."

                        if analysis_content:
                            analysis_content += tool_section
                        else:
                            analysis_content = tool_section

                    elif chunk_type == "tool_result":
                        tool_name = chunk_data.get("tool_name", "")
                        result = chunk_data.get("result", {})
                        success = result.get("success", False)
                        status_emoji = "âœ…" if success else "âŒ"

                        result_str = json.dumps(result, indent=2, ensure_ascii=False)
                        tool_section = f"\n\nğŸ› ï¸ **å·¥å…·æ‰§è¡Œç»“æœ**: `{tool_name}` {status_emoji}\n\n```json\n{result_str}\n```\n\nğŸ”„ ç»§ç»­åˆ†æ..."

                        if analysis_content:
                            analysis_content += tool_section
                        else:
                            analysis_content = tool_section

                    elif chunk_type == "error":
                        error_msg = chunk_data.get("content", "æœªçŸ¥é”™è¯¯")
                        error_section = f"\n\nâŒ **æ¨ç†é”™è¯¯**: {error_msg}"

                        if analysis_content:
                            analysis_content += error_section
                        else:
                            analysis_content = error_section

                    # æ„å»ºç»„åˆå†…å®¹ï¼šthinkingï¼ˆå¦‚æœå­˜åœ¨ï¼‰ + æ­£æ–‡
                    combined_content = ""
                    message_metadata = {
                        "streaming": True,
                        "chunk_count": chunk_count,
                        "has_thinking": bool(thinking_content),
                        "thinking_completed": thinking_completed
                    }

                    if thinking_content:
                        combined_content = thinking_content
                        # æ·»åŠ thinkingéƒ¨åˆ†çš„æŠ˜å å…ƒæ•°æ®
                        message_metadata.update({
                            "collapsible_sections": [{
                                "type": "thinking",
                                "default_collapsed": True,  # thinkingéƒ¨åˆ†é»˜è®¤æŠ˜å 
                                "title": "ğŸ§  AIæ€è€ƒè¿‡ç¨‹",
                                "completed": thinking_completed
                            }]
                        })

                    if analysis_content:
                        if combined_content:
                            # åœ¨thinkingå’Œæ­£æ–‡ä¹‹é—´æ·»åŠ åˆ†éš”çº¿
                            combined_content += "\n\n---\n\n**åˆ†æç»“æœ**\n\n" + analysis_content
                        else:
                            combined_content = analysis_content

                    # æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼šç³»ç»Ÿä¸Šä¸‹æ–‡ + AIå›å¤
                    assistant_message = {
                        "role": "assistant",
                        "content": combined_content,
                        "metadata": message_metadata
                    }

                    complete_messages = formatted_messages + [assistant_message]
                    yield complete_messages

                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†æ¨ç†å—å¤±è´¥: {e}")
                    continue

            # æ¨ç†å®Œæˆ - æœ€ç»ˆæ•´ç†
            thinking_completed = True
            final_content = ""

            if thinking_content:
                final_content = thinking_content

            if analysis_content:
                if final_content:
                    final_content += "\n\n---\n\n**æœ€ç»ˆåˆ†æ**\n\n" + analysis_content + "\n\nâœ… **æ¨ç†å®Œæˆ**"
                else:
                    final_content = analysis_content + "\n\nâœ… **æ¨ç†å®Œæˆ**"

            # æ„å»ºæœ€ç»ˆæ¶ˆæ¯
            final_metadata = {
                "completed": True,
                "final": True,
                "has_thinking": bool(thinking_content),
                "thinking_completed": True
            }

            if thinking_content:
                # æ·»åŠ thinkingéƒ¨åˆ†çš„æŠ˜å å…ƒæ•°æ®
                final_metadata.update({
                    "collapsible_sections": [{
                        "type": "thinking",
                        "default_collapsed": True,  # thinkingéƒ¨åˆ†é»˜è®¤æŠ˜å 
                        "title": "ğŸ§  AIæ€è€ƒè¿‡ç¨‹",
                        "completed": True
                    }]
                })

            final_message = {
                "role": "assistant",
                "content": final_content,
                "metadata": final_metadata
            }

            final_complete_messages = formatted_messages + [final_message]
            yield final_complete_messages

        except Exception as e:
            logger.error(f"æ‰§è¡Œæ‰‹åŠ¨æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            yield [{"role": "assistant", "content": f"âŒ æ¨ç†è¿‡ç¨‹å‡ºé”™: {str(e)}"}]

    @classmethod
    async def continue_conversation(
        cls,
        plan_id: int,
        user_message: str,
        conversation_type: ConversationType = ConversationType.MANUAL_CHAT
    ) -> AsyncGenerator[List[Dict], None]:
        """
        ç»§ç»­å¯¹è¯

        Args:
            plan_id: è®¡åˆ’ID
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_type: å¯¹è¯ç±»å‹

        Yields:
            Chatbotæ¶ˆæ¯åˆ—è¡¨
        """
        try:
            # è·å–æˆ–åˆ›å»ºå¯¹è¯ï¼ˆä¸é‡ç½®ä¸Šä¸‹æ–‡ï¼‰
            conversation_id = await enhanced_agent_stream_service.initialize_conversation(
                plan_id=plan_id,
                conversation_type=conversation_type,
                reset_context=False
            )

            # è·å–å½“å‰å¯¹è¯çŠ¶æ€ï¼ˆå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
            current_messages = enhanced_conversation_service.get_conversation_messages(conversation_id)
            formatted_messages = enhanced_conversation_service.format_for_chatbot(current_messages)

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°æ˜¾ç¤º
            messages_with_user = formatted_messages + [
                {"role": "user", "content": user_message}
            ]

            yield messages_with_user

            # å¼€å§‹AIå›å¤
            thinking_content = ""      # åˆ†ç¦»thinkingå†…å®¹
            analysis_content = ""      # åˆ†ç¦»æ­£æ–‡åˆ†æå†…å®¹
            chunk_count = 0
            thinking_completed = False  # æ ‡è®°thinkingæ˜¯å¦å®Œæˆ

            async for chunk_str in enhanced_agent_stream_service.chat_with_tools_stream(
                conversation_id=conversation_id,
                user_message=user_message,
                use_thinking_mode=True
            ):
                try:
                    chunk_data = json.loads(chunk_str)
                    chunk_type = chunk_data.get("type", "")
                    content = chunk_data.get("content", "")
                    chunk_count = chunk_data.get("chunk_count", 0)

                    # åˆ†åˆ«å¤„ç†thinkingå’Œæ­£æ–‡å†…å®¹
                    if chunk_type == "thinking_start":
                        thinking_content = "ğŸ§  **AIæ€è€ƒè¿‡ç¨‹**\n\n"
                        thinking_completed = False

                    elif chunk_type == "thinking":
                        # ç´¯ç§¯thinkingå†…å®¹
                        thinking_content += content
                        thinking_completed = False

                    elif chunk_type == "content":
                        # æ­£æ–‡å¼€å§‹ï¼Œæ ‡è®°thinkingå®Œæˆ
                        if not thinking_completed:
                            thinking_completed = True

                        # ç´¯ç§¯æ­£æ–‡å†…å®¹
                        if analysis_content:
                            analysis_content += "\n\n" + content
                        else:
                            analysis_content = content

                    elif chunk_type == "tool_call_start":
                        thinking_completed = True
                        tool_name = chunk_data.get("tool_name", "")
                        tool_section = f"\n\nğŸ› ï¸ **è°ƒç”¨å·¥å…·**: `{tool_name}`\n\nâ³ æ­£åœ¨æ‰§è¡Œ..."

                        if analysis_content:
                            analysis_content += tool_section
                        else:
                            analysis_content = tool_section

                    elif chunk_type == "tool_call":
                        thinking_completed = True
                        tool_name = chunk_data.get("tool_name", "")
                        arguments = chunk_data.get("arguments", {})
                        args_str = json.dumps(arguments, indent=2, ensure_ascii=False)
                        tool_section = f"\n\nğŸ› ï¸ **å·¥å…·è°ƒç”¨**: `{tool_name}`\n\nğŸ“‹ **å‚æ•°**:\n```json\n{args_str}\n```\n\nâ³ æ­£åœ¨æ‰§è¡Œ..."

                        if analysis_content:
                            analysis_content += tool_section
                        else:
                            analysis_content = tool_section

                    elif chunk_type == "tool_result":
                        tool_name = chunk_data.get("tool_name", "")
                        result = chunk_data.get("result", {})
                        success = result.get("success", False)
                        status_emoji = "âœ…" if success else "âŒ"

                        result_str = json.dumps(result, indent=2, ensure_ascii=False)
                        tool_section = f"\n\nğŸ› ï¸ **å·¥å…·æ‰§è¡Œç»“æœ**: `{tool_name}` {status_emoji}\n\n```json\n{result_str}\n```\n\nğŸ”„ ç»§ç»­å¯¹è¯..."

                        if analysis_content:
                            analysis_content += tool_section
                        else:
                            analysis_content = tool_section

                    elif chunk_type == "error":
                        error_msg = chunk_data.get("content", "æœªçŸ¥é”™è¯¯")
                        error_section = f"\n\nâŒ **å›å¤é”™è¯¯**: {error_msg}"

                        if analysis_content:
                            analysis_content += error_section
                        else:
                            analysis_content = error_section

                    # æ„å»ºç»„åˆå†…å®¹ï¼šthinkingï¼ˆå¦‚æœå­˜åœ¨ï¼‰ + æ­£æ–‡
                    combined_content = ""
                    message_metadata = {
                        "streaming": True,
                        "chunk_count": chunk_count,
                        "has_thinking": bool(thinking_content),
                        "thinking_completed": thinking_completed
                    }

                    if thinking_content:
                        combined_content = thinking_content
                        # æ·»åŠ thinkingéƒ¨åˆ†çš„æŠ˜å å…ƒæ•°æ®
                        message_metadata.update({
                            "collapsible_sections": [{
                                "type": "thinking",
                                "default_collapsed": True,  # thinkingéƒ¨åˆ†é»˜è®¤æŠ˜å 
                                "title": "ğŸ§  AIæ€è€ƒè¿‡ç¨‹",
                                "completed": thinking_completed
                            }]
                        })

                    if analysis_content:
                        if combined_content:
                            combined_content += "\n\n---\n\n**å›å¤å†…å®¹**\n\n" + analysis_content
                        else:
                            combined_content = analysis_content

                    # æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼šå†å²æ¶ˆæ¯ + ç”¨æˆ·æ¶ˆæ¯ + AIå›å¤
                    assistant_message = {
                        "role": "assistant",
                        "content": combined_content,
                        "metadata": message_metadata
                    }

                    complete_messages = messages_with_user + [assistant_message]
                    yield complete_messages

                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†å¯¹è¯å—å¤±è´¥: {e}")
                    continue

            # å¯¹è¯å®Œæˆ - æœ€ç»ˆæ•´ç†
            thinking_completed = True
            final_content = ""

            if thinking_content:
                final_content = thinking_content

            if analysis_content:
                if final_content:
                    final_content += "\n\n---\n\n**æœ€ç»ˆå›å¤**\n\n" + analysis_content + "\n\nâœ… **å›å¤å®Œæˆ**"
                else:
                    final_content = analysis_content + "\n\nâœ… **å›å¤å®Œæˆ**"

            # æ„å»ºæœ€ç»ˆæ¶ˆæ¯
            final_metadata = {
                "completed": True,
                "final": True,
                "has_thinking": bool(thinking_content),
                "thinking_completed": True
            }

            if thinking_content:
                # æ·»åŠ thinkingéƒ¨åˆ†çš„æŠ˜å å…ƒæ•°æ®
                final_metadata.update({
                    "collapsible_sections": [{
                        "type": "thinking",
                        "default_collapsed": True,  # thinkingéƒ¨åˆ†é»˜è®¤æŠ˜å 
                        "title": "ğŸ§  AIæ€è€ƒè¿‡ç¨‹",
                        "completed": True
                    }]
                })

            final_message = {
                "role": "assistant",
                "content": final_content,
                "metadata": final_metadata
            }

            final_complete_messages = messages_with_user + [final_message]
            yield final_complete_messages

        except Exception as e:
            logger.error(f"ç»§ç»­å¯¹è¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            yield [{"role": "assistant", "content": f"âŒ å¯¹è¯è¿‡ç¨‹å‡ºé”™: {str(e)}"}]

    @classmethod
    async def handle_kline_event_trigger(cls, plan_id: int, inst_id: str, kline_data: dict):
        """
        å¤„ç†Kçº¿äº‹ä»¶è§¦å‘

        Args:
            plan_id: è®¡åˆ’ID
            inst_id: äº¤æ˜“å¯¹
            kline_data: Kçº¿æ•°æ®
        """
        try:
            # è·å–æˆ–åˆ›å»ºKçº¿äº‹ä»¶å¯¹è¯
            conversation_id = await enhanced_agent_stream_service.initialize_conversation(
                plan_id=plan_id,
                conversation_type=ConversationType.KLINE_EVENT,
                reset_context=False  # ä¸é‡ç½®ä¸Šä¸‹æ–‡ï¼Œç»§ç»­ä¹‹å‰çš„å¯¹è¯
            )

            # æ„å»ºäº‹ä»¶æ¶ˆæ¯
            event_message = f"""ğŸ”” **æ–°Kçº¿æ•°æ®äº‹ä»¶**

**äº¤æ˜“å¯¹**: {inst_id}
**æ›´æ–°æ—¶é—´**: {kline_data.get('timestamp', datetime.utcnow()).strftime('%Y-%m-%d %H:%M:%S UTC')}
**æ”¶ç›˜ä»·**: {kline_data.get('close', 0)}
**æˆäº¤é‡**: {kline_data.get('volume', 0)}

è¯·åŸºäºæœ€æ–°å¸‚åœºæ•°æ®æ›´æ–°åˆ†æå¹¶è€ƒè™‘æ˜¯å¦éœ€è¦è°ƒæ•´äº¤æ˜“ç­–ç•¥ã€‚"""

            # è‡ªåŠ¨ç»§ç»­å¯¹è¯ï¼ˆåŸºäºäº‹ä»¶æ•°æ®ï¼‰
            await enhanced_agent_stream_service.chat_with_tools_stream(
                conversation_id=conversation_id,
                user_message=event_message,
                use_thinking_mode=True
            )

            logger.info(f"Kçº¿äº‹ä»¶è§¦å‘å¯¹è¯å®Œæˆ: plan_id={plan_id}, conversation_id={conversation_id}")

        except Exception as e:
            logger.error(f"å¤„ç†Kçº¿äº‹ä»¶è§¦å‘å¤±è´¥: {e}")

    @classmethod
    def get_latest_conversation_messages(
        cls,
        plan_id: int,
        conversation_type: ConversationType = ConversationType.MANUAL_CHAT
    ) -> List[Dict]:
        """
        è·å–æœ€æ–°çš„å¯¹è¯æ¶ˆæ¯

        Args:
            plan_id: è®¡åˆ’ID
            conversation_type: å¯¹è¯ç±»å‹

        Returns:
            Chatbotæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        """
        try:
            conversation = enhanced_conversation_service.get_latest_conversation_by_type(
                plan_id=plan_id,
                conversation_type=conversation_type
            )

            if not conversation:
                return [{"role": "assistant", "content": "æš‚æ— å¯¹è¯è®°å½•"}]

            messages = enhanced_conversation_service.get_conversation_messages(conversation.id)
            return enhanced_conversation_service.format_for_chatbot(messages)

        except Exception as e:
            logger.error(f"è·å–æœ€æ–°å¯¹è¯æ¶ˆæ¯å¤±è´¥: {e}")
            return [{"role": "assistant", "content": f"è·å–å¯¹è¯å¤±è´¥: {str(e)}"}]


# å…¨å±€å®ä¾‹
enhanced_inference_service = EnhancedInferenceService()