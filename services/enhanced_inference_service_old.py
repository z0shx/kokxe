"""
å¢å¼ºçš„æ¨ç†æœåŠ¡ - ä¿®å¤ç‰ˆæœ¬
è§£å†³thinkingæ¨¡å¼æ–‡æœ¬é‡å å’Œæµå¼è¾“å‡ºé—®é¢˜
"""
import json
import asyncio
from typing import Dict, List, AsyncGenerator, Optional
from database.models import TradingPlan, PredictionData
from database.db import get_db
from utils.logger import setup_logger
from services.enhanced_conversation_service import enhanced_conversation_service, ConversationType
from services.enhanced_agent_stream_service import enhanced_agent_stream_service
from services.kline_event_service import kline_event_service

logger = setup_logger(__name__, "enhanced_inference_fixed.log")


class EnhancedInferenceService:
    """å¢å¼ºçš„æ¨ç†æœåŠ¡ - ä¿®å¤ç‰ˆæœ¬"""

    @classmethod
    async def execute_manual_inference(cls, plan_id: int) -> AsyncGenerator[List[Dict], None]:
        """
        æ‰§è¡Œæ‰‹åŠ¨æ¨ç† - æ­£ç¡®çš„æµå¼è¾“å‡ºï¼Œé¿å…æ–‡æœ¬é‡å 

        Args:
            plan_id: è®¡åˆ’ID

        Yields:
            Chatbotæ¶ˆæ¯åˆ—è¡¨ - å¢é‡æ›´æ–°ï¼Œåˆ†ç¦»thinkingå’Œæ­£æ–‡
        """
        try:
            # 1. åˆå§‹åŒ–å¯¹è¯ï¼ˆé‡ç½®ä¸Šä¸‹æ–‡ï¼‰
            conversation_id = await enhanced_agent_stream_service.initialize_conversation(
                plan_id=plan_id,
                conversation_type=ConversationType.AUTO_INFERENCE,
                reset_context=True
            )

            # 2. æ·»åŠ é¢„æµ‹æ•°æ®æ¶ˆæ¯
            prediction_success = await enhanced_agent_stream_service.add_prediction_data_message(
                conversation_id=conversation_id,
                plan_id=plan_id,
                trigger_event="manual_inference"
            )

            if not prediction_success:
                yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ"}]
                return

            # 3. è·å–å½“å‰å¯¹è¯çŠ¶æ€ç”¨äºæ˜¾ç¤ºï¼ˆå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
            current_messages = enhanced_conversation_service.get_conversation_messages(conversation_id)
            formatted_messages = enhanced_conversation_service.format_for_chatbot(current_messages)

            # ç«‹å³è¿”å›å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬ç³»ç»Ÿæç¤ºè¯å’Œé¢„æµ‹æ•°æ®ï¼‰
            yield formatted_messages

            # 4. å¼€å§‹AIåˆ†æå¯¹è¯ - é‡æ–°è®¾è®¡ä¸ºå¢é‡æµå¼è¾“å‡º
            thinking_buffer = ""      # thinkingå†…å®¹ç¼“å†²åŒº
            analysis_buffer = ""      # åˆ†æå†…å®¹ç¼“å†²åŒº
            last_sent_thinking = ""   # ä¸Šæ¬¡å‘é€çš„thinkingå†…å®¹
            last_sent_analysis = ""   # ä¸Šæ¬¡å‘é€çš„åˆ†æå†…å®¹
            thinking_complete = False # æ ‡è®°thinkingæ˜¯å¦å®Œæˆ

            async for chunk_str in enhanced_agent_stream_service.chat_with_tools_stream(
                conversation_id=conversation_id,
                user_message="",  # ç©ºæ¶ˆæ¯ï¼Œè®©AIåŸºäºé¢„æµ‹æ•°æ®è¿›è¡Œåˆ†æ
                use_thinking_mode=True
            ):
                try:
                    chunk_data = json.loads(chunk_str)
                    chunk_type = chunk_data.get("type", "")

                    should_update = False

                    if chunk_type == "thinking":
                        # ç´¯ç§¯thinkingå†…å®¹
                        new_thinking = chunk_data.get("content", "")
                        thinking_buffer += new_thinking
                        should_update = True

                    elif chunk_type == "content":
                        # ç´¯ç§¯åˆ†æå†…å®¹
                        new_content = chunk_data.get("content", "")
                        analysis_buffer += new_content
                        should_update = True
                        thinking_complete = True  # å¼€å§‹æ­£æ–‡æ„å‘³ç€thinkingå®Œæˆ

                    elif chunk_type == "tool_call":
                        tool_name = chunk_data.get("tool_name", "")
                        arguments = chunk_data.get("arguments", {})
                        args_str = json.dumps(arguments, indent=2, ensure_ascii=False)
                        tool_section = f"\n\nğŸ› ï¸ **å·¥å…·è°ƒç”¨**: `{tool_name}`\n\nğŸ“‹ **å‚æ•°**:\n```json\n{args_str}\n```\n\nâ³ æ­£åœ¨æ‰§è¡Œ..."
                        analysis_buffer += tool_section
                        should_update = True

                    elif chunk_type == "tool_result":
                        tool_name = chunk_data.get("tool_name", "")
                        result = chunk_data.get("result", {})
                        success = result.get("success", False)
                        status_emoji = "âœ…" if success else "âŒ"

                        result_str = json.dumps(result, indent=2, ensure_ascii=False)
                        tool_section = f"\n\nğŸ› ï¸ **å·¥å…·æ‰§è¡Œç»“æœ**: `{tool_name}` {status_emoji}\n\n```json\n{result_str}\n```\n\nğŸ”„ ç»§ç»­åˆ†æ..."
                        analysis_buffer += tool_section
                        should_update = True

                    elif chunk_type == "error":
                        error_msg = chunk_data.get("content", "æœªçŸ¥é”™è¯¯")
                        error_section = f"\n\nâŒ **æ¨ç†é”™è¯¯**: {error_msg}"
                        analysis_buffer += error_section
                        should_update = True

                    # åªæœ‰å†…å®¹æ›´æ–°ä¸”å†…å®¹ç¡®å®å‘ç”Ÿå˜åŒ–æ—¶æ‰ç”Ÿæˆæ–°æ¶ˆæ¯
                    if should_update:
                        thinking_changed = thinking_buffer != last_sent_thinking
                        analysis_changed = analysis_buffer != last_sent_analysis

                        if thinking_changed or analysis_changed:
                            # æ„å»ºå¢é‡æ¶ˆæ¯å†…å®¹ - åˆ†ç¦»thinkingå’Œæ­£æ–‡
                            content_parts = []

                            # æ·»åŠ thinkingéƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
                            if thinking_buffer:
                                content_parts.append(f"<details>\n<summary>ğŸ§  AIæ€è€ƒè¿‡ç¨‹</summary>\n\n{thinking_buffer}\n</details>")

                            # æ·»åŠ åˆ†æéƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
                            if analysis_buffer:
                                if content_parts:  # å¦‚æœå·²æœ‰thinkingï¼Œæ·»åŠ åˆ†éš”ç¬¦
                                    content_parts.append("\n\n---\n\n")
                                content_parts.append(analysis_buffer)

                            if content_parts:
                                content_update = "".join(content_parts)

                                # åˆ›å»ºæ–°çš„assistantæ¶ˆæ¯
                                new_assistant_message = {
                                    "role": "assistant",
                                    "content": content_update,
                                    "metadata": {
                                        "streaming": True,
                                        "has_thinking": bool(thinking_buffer),
                                        "thinking_completed": thinking_complete,
                                        "incremental": True,  # æ ‡è®°ä¸ºå¢é‡æ›´æ–°
                                        "chunk_type": chunk_type
                                    }
                                }

                                # è¿”å›å†å²æ¶ˆæ¯ + æ–°çš„å¢é‡æ¶ˆæ¯
                                response_messages = formatted_messages + [new_assistant_message]
                                yield response_messages

                                # æ›´æ–°æœ€åå‘é€çš„å†…å®¹è®°å½•
                                last_sent_thinking = thinking_buffer
                                last_sent_analysis = analysis_buffer

                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†æ¨ç†å—å¤±è´¥: {e}")
                    continue

            # 5. æ¨ç†å®Œæˆ - å‘é€æœ€ç»ˆå®Œæˆæ¶ˆæ¯
            final_content_parts = []

            if thinking_buffer:
                final_content_parts.append(f"<details>\n<summary>ğŸ§  AIæ€è€ƒè¿‡ç¨‹</summary>\n\n{thinking_buffer}\n\nâœ… æ€è€ƒå®Œæˆ\n</details>")

            if analysis_buffer:
                if final_content_parts:
                    final_content_parts.append("\n\n---\n\n")
                final_content_parts.append(analysis_buffer + "\n\nâœ… **æ¨ç†å®Œæˆ**")

            if final_content_parts:
                final_content = "".join(final_content_parts)
                final_message = {
                    "role": "assistant",
                    "content": final_content,
                    "metadata": {
                        "completed": True,
                        "final": True,
                        "has_thinking": bool(thinking_buffer),
                        "thinking_completed": True,
                        "incremental": False  # æœ€ç»ˆæ¶ˆæ¯ä¸æ˜¯å¢é‡æ›´æ–°
                    }
                }

                final_response = formatted_messages + [final_message]
                yield final_response

        except Exception as e:
            logger.error(f"æ‰§è¡Œæ‰‹åŠ¨æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            yield [{"role": "assistant", "content": f"âŒ æ¨ç†è¿‡ç¨‹å‡ºé”™: {str(e)}"}]

    @classmethod
    async def continue_conversation(
        cls,
        plan_id: int,
        user_message: str,
        conversation_type: ConversationType = ConversationType.MANUAL_CHAT
    ) -> AsyncGenerator[List[Dict], None]:
        """
        ç»§ç»­å¯¹è¯ - ä¿®å¤ç‰ˆæœ¬
        """
        try:
            # è·å–æˆ–åˆ›å»ºå¯¹è¯ä¼šè¯
            conversation_id = await enhanced_agent_stream_service.initialize_conversation(
                plan_id=plan_id,
                conversation_type=conversation_type,
                reset_context=False
            )

            # è·å–å¯¹è¯å†å²
            current_messages = enhanced_conversation_service.get_conversation_messages(conversation_id)
            formatted_messages = enhanced_conversation_service.format_for_chatbot(current_messages)

            # ç«‹å³è¿”å›å†å²æ¶ˆæ¯
            yield formatted_messages

            # å¼€å§‹æµå¼å¯¹è¯
            thinking_buffer = ""
            analysis_buffer = ""
            last_sent_thinking = ""
            last_sent_analysis = ""
            thinking_complete = False

            async for chunk_str in enhanced_agent_stream_service.chat_with_tools_stream(
                conversation_id=conversation_id,
                user_message=user_message,
                use_thinking_mode=True
            ):
                try:
                    chunk_data = json.loads(chunk_str)
                    chunk_type = chunk_data.get("type", "")

                    should_update = False

                    if chunk_type == "thinking":
                        new_thinking = chunk_data.get("content", "")
                        thinking_buffer += new_thinking
                        should_update = True

                    elif chunk_type == "content":
                        new_content = chunk_data.get("content", "")
                        analysis_buffer += new_content
                        should_update = True
                        thinking_complete = True

                    elif chunk_type in ["tool_call", "tool_result", "error"]:
                        # å¤„ç†å·¥å…·ç›¸å…³å’Œé”™è¯¯æ¶ˆæ¯
                        if chunk_type == "tool_call":
                            tool_name = chunk_data.get("tool_name", "")
                            arguments = chunk_data.get("arguments", {})
                            args_str = json.dumps(arguments, indent=2, ensure_ascii=False)
                            tool_section = f"\n\nğŸ› ï¸ **å·¥å…·è°ƒç”¨**: `{tool_name}`\n\nğŸ“‹ **å‚æ•°**:\n```json\n{args_str}\n```\n\nâ³ æ­£åœ¨æ‰§è¡Œ..."
                        elif chunk_type == "tool_result":
                            tool_name = chunk_data.get("tool_name", "")
                            result = chunk_data.get("result", {})
                            success = result.get("success", False)
                            status_emoji = "âœ…" if success else "âŒ"
                            result_str = json.dumps(result, indent=2, ensure_ascii=False)
                            tool_section = f"\n\nğŸ› ï¸ **å·¥å…·æ‰§è¡Œç»“æœ**: `{tool_name}` {status_emoji}\n\n```json\n{result_str}\n```\n\nğŸ”„ ç»§ç»­åˆ†æ..."
                        else:  # error
                            error_msg = chunk_data.get("content", "æœªçŸ¥é”™è¯¯")
                            tool_section = f"\n\nâŒ **æ¨ç†é”™è¯¯**: {error_msg}"

                        analysis_buffer += tool_section
                        should_update = True

                    if should_update:
                        thinking_changed = thinking_buffer != last_sent_thinking
                        analysis_changed = analysis_buffer != last_sent_analysis

                        if thinking_changed or analysis_changed:
                            content_parts = []

                            if thinking_buffer:
                                content_parts.append(f"<details>\n<summary>ğŸ§  AIæ€è€ƒè¿‡ç¨‹</summary>\n\n{thinking_buffer}\n</details>")

                            if analysis_buffer:
                                if content_parts:
                                    content_parts.append("\n\n---\n\n")
                                content_parts.append(analysis_buffer)

                            if content_parts:
                                content_update = "".join(content_parts)

                                new_assistant_message = {
                                    "role": "assistant",
                                    "content": content_update,
                                    "metadata": {
                                        "streaming": True,
                                        "has_thinking": bool(thinking_buffer),
                                        "thinking_completed": thinking_complete,
                                        "incremental": True,
                                        "chunk_type": chunk_type
                                    }
                                }

                                response_messages = formatted_messages + [new_assistant_message]
                                yield response_messages

                                last_sent_thinking = thinking_buffer
                                last_sent_analysis = analysis_buffer

                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†å¯¹è¯å—å¤±è´¥: {e}")
                    continue

            # å¯¹è¯å®Œæˆ
            final_content_parts = []

            if thinking_buffer:
                final_content_parts.append(f"<details>\n<summary>ğŸ§  AIæ€è€ƒè¿‡ç¨‹</summary>\n\n{thinking_buffer}\n\nâœ… æ€è€ƒå®Œæˆ\n</details>")

            if analysis_buffer:
                if final_content_parts:
                    final_content_parts.append("\n\n---\n\n")
                final_content_parts.append(analysis_buffer + "\n\nâœ… **å¯¹è¯å®Œæˆ**")

            if final_content_parts:
                final_content = "".join(final_content_parts)
                final_message = {
                    "role": "assistant",
                    "content": final_content,
                    "metadata": {
                        "completed": True,
                        "final": True,
                        "has_thinking": bool(thinking_buffer),
                        "thinking_completed": True,
                        "incremental": False
                    }
                }

                final_response = formatted_messages + [final_message]
                yield final_response

        except Exception as e:
            logger.error(f"ç»§ç»­å¯¹è¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            yield [{"role": "assistant", "content": f"âŒ å¯¹è¯è¿‡ç¨‹å‡ºé”™: {str(e)}"}]

    @classmethod
    async def handle_kline_event_trigger(cls, plan_id: int, inst_id: str, kline_data: dict):
        """
        å¤„ç†Kçº¿äº‹ä»¶è§¦å‘
        """
        try:
            # è·å–æˆ–åˆ›å»ºKçº¿äº‹ä»¶å¯¹è¯
            conversation_id = await enhanced_agent_stream_service.initialize_conversation(
                plan_id=plan_id,
                conversation_type=ConversationType.KLINE_EVENT,
                reset_context=False  # ä¸é‡ç½®ä¸Šä¸‹æ–‡ï¼Œç»§ç»­ä¹‹å‰çš„å¯¹è¯
            )

            # æ„å»ºäº‹ä»¶æ¶ˆæ¯
            event_message = f"""ğŸ”” **æ–°Kçº¿æ•°æ®äº‹ä»¶**

**äº¤æ˜“å¯¹**: {inst_id}
**æ›´æ–°æ—¶é—´**: {kline_data.get('timestamp', 'N/A')}
**æ”¶ç›˜ä»·**: {kline_data.get('close', 0)}
**æˆäº¤é‡**: {kline_data.get('volume', 0)}

è¯·åŸºäºæœ€æ–°å¸‚åœºæ•°æ®æ›´æ–°åˆ†æå¹¶è€ƒè™‘æ˜¯å¦éœ€è¦è°ƒæ•´äº¤æ˜“ç­–ç•¥ã€‚"""

            # è‡ªåŠ¨ç»§ç»­å¯¹è¯ï¼ˆåŸºäºäº‹ä»¶æ•°æ®ï¼‰
            await enhanced_agent_stream_service.chat_with_tools_stream(
                conversation_id=conversation_id,
                user_message=event_message,
                use_thinking_mode=True
            )

            logger.info(f"Kçº¿äº‹ä»¶è§¦å‘å¯¹è¯å®Œæˆ: plan_id={plan_id}, conversation_id={conversation_id}")

        except Exception as e:
            logger.error(f"å¤„ç†Kçº¿äº‹ä»¶è§¦å‘å¤±è´¥: {e}")

    @classmethod
    def get_latest_prediction_data(cls, plan_id: int) -> Optional[PredictionData]:
        """è·å–æœ€æ–°çš„é¢„æµ‹æ•°æ®"""
        try:
            with get_db() as db:
                return db.query(PredictionData).filter(
                    PredictionData.plan_id == plan_id,
                    PredictionData.status == "success"
                ).order_by(PredictionData.created_at.desc()).first()

        except Exception as e:
            logger.error(f"è·å–æœ€æ–°é¢„æµ‹æ•°æ®å¤±è´¥: {e}")
            return None


# åˆ›å»ºå…¨å±€å®ä¾‹
enhanced_inference_service = EnhancedInferenceService()