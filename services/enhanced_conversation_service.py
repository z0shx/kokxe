"""
å¢å¼ºçš„AI Agentå¯¹è¯ç®¡ç†æœåŠ¡
é‡æ„ç‰ˆï¼šæ”¯æŒå®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†ã€é…ç½®åŒ–ç³»ç»Ÿæç¤ºè¯ã€æŒä¹…åŒ–å¯¹è¯è®°å½•
"""
import json
import pandas as pd
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple, AsyncGenerator, Any
from enum import Enum
from sqlalchemy import and_, desc, or_, text as sa_text
from database.db import get_db
from database.models import (
    AgentConversation, AgentMessage, TradingPlan, TrainingRecord,
    PredictionData, AgentPromptTemplate, LLMConfig, now_beijing
)
from utils.logger import setup_logger

logger = setup_logger(__name__, "enhanced_conversation.log")


class ConversationType(Enum):
    """å¯¹è¯ç±»å‹"""
    MANUAL_CHAT = "manual_chat"          # æ‰‹åŠ¨å¯¹è¯
    AUTO_INFERENCE = "auto_inference"    # è‡ªåŠ¨æ¨ç†
    KLINE_EVENT = "kline_event"          # Kçº¿äº‹ä»¶è§¦å‘
    SYSTEM_INIT = "system_init"          # ç³»ç»Ÿåˆå§‹åŒ–


class MessageRole(Enum):
    """æ¶ˆæ¯è§’è‰²"""
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    TOOL = "tool"


class MessageSubType(Enum):
    """æ¶ˆæ¯å­ç±»å‹"""
    TEXT = "text"
    THINKING = "thinking"
    TOOL_CALL = "tool_call"
    TOOL_RESULT = "tool_result"
    SYSTEM_PROMPT = "system_prompt"
    KLINE_DATA = "kline_data"
    EVENT_NOTIFICATION = "event_notification"


class EnhancedConversationService:
    """å¢å¼ºçš„å¯¹è¯æœåŠ¡ç±»"""

    @staticmethod
    def create_or_get_conversation(
        plan_id: int,
        conversation_type: ConversationType,
        reset_context: bool = False,
        session_name: Optional[str] = None
    ) -> AgentConversation:
        """
        åˆ›å»ºæˆ–è·å–å¯¹è¯ä¼šè¯

        Args:
            plan_id: è®¡åˆ’ID
            conversation_type: å¯¹è¯ç±»å‹
            reset_context: æ˜¯å¦é‡ç½®ä¸Šä¸‹æ–‡ï¼ˆåˆ›å»ºæ–°ä¼šè¯ï¼‰
            session_name: ä¼šè¯åç§°

        Returns:
            å¯¹è¯ä¼šè¯å¯¹è±¡
        """
        try:
            with get_db() as db:
                if not reset_context:
                    # å°è¯•è·å–ç°æœ‰å¯¹è¯
                    existing_conversation = db.query(AgentConversation).filter(
                        and_(
                            AgentConversation.plan_id == plan_id,
                            AgentConversation.conversation_type == conversation_type.value,
                            AgentConversation.status == 'active'
                        )
                    ).order_by(desc(AgentConversation.last_message_at)).first()

                    if existing_conversation:
                        logger.info(f"å¤ç”¨ç°æœ‰å¯¹è¯: conversation_id={existing_conversation.id}, type={conversation_type.value}")
                        return existing_conversation

                # åˆ›å»ºæ–°å¯¹è¯
                conversation = AgentConversation(
                    plan_id=plan_id,
                    conversation_type=conversation_type.value,
                    session_name=session_name or f"{conversation_type.value}_{now_beijing().strftime('%Y%m%d_%H%M%S')}",
                    status='active',
                    started_at=now_beijing(),
                    last_message_at=now_beijing()
                )

                db.add(conversation)
                db.commit()
                db.refresh(conversation)

                logger.info(f"åˆ›å»ºæ–°å¯¹è¯: conversation_id={conversation.id}, type={conversation_type.value}")
                return conversation

        except Exception as e:
            logger.error(f"åˆ›å»ºå¯¹è¯ä¼šè¯å¤±è´¥: {e}")
            raise

    @staticmethod
    def get_system_prompt_content(plan: TradingPlan) -> str:
        """
        è·å–ç³»ç»Ÿæç¤ºè¯å†…å®¹ï¼ˆä¼˜å…ˆä½¿ç”¨agent_promptå­—æ®µï¼‰

        Args:
            plan: äº¤æ˜“è®¡åˆ’å¯¹è±¡

        Returns:
            ç³»ç»Ÿæç¤ºè¯å†…å®¹
        """
        try:
            # ä¼˜å…ˆä½¿ç”¨è®¡åˆ’çš„agent_promptå­—æ®µ
            agent_prompt = getattr(plan, 'agent_prompt', None)
            if agent_prompt and agent_prompt.strip():
                logger.info(f"ä½¿ç”¨è®¡åˆ’é…ç½®çš„agent_prompt")
                return agent_prompt.strip()

            # å¦‚æœæ²¡æœ‰agent_promptï¼Œæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰prompt_template_idå­—æ®µ
            with get_db() as db:
                # æ£€æŸ¥trading_plansè¡¨æ˜¯å¦æœ‰prompt_template_idå­—æ®µ
                result = db.execute(sa_text("""
                    SELECT column_name
                    FROM information_schema.columns
                    WHERE table_name = 'trading_plans' AND column_name = 'prompt_template_id'
                """))
                has_field = result.fetchone() is not None

                if has_field:
                    prompt_template_id = getattr(plan, 'prompt_template_id', None)
                    if prompt_template_id:
                        template = db.query(AgentPromptTemplate).filter(
                            AgentPromptTemplate.id == prompt_template_id,
                            AgentPromptTemplate.is_active == True
                        ).first()

                        if template:
                            logger.info(f"ä½¿ç”¨è®¡åˆ’é…ç½®çš„æç¤ºè¯æ¨¡æ¿: {template.name}")
                            return template.content

                # å¦åˆ™ä½¿ç”¨é»˜è®¤æ¨¡æ¿
                default_template = db.query(AgentPromptTemplate).filter(
                    AgentPromptTemplate.is_default == True,
                    AgentPromptTemplate.is_active == True
                ).first()

                if default_template:
                    logger.info(f"ä½¿ç”¨é»˜è®¤æç¤ºè¯æ¨¡æ¿: {default_template.name}")
                    return default_template.content

                # æœ€åä½¿ç”¨ç¡¬ç¼–ç çš„åŸºç¡€æç¤ºè¯
                logger.warning("æœªæ‰¾åˆ°é…ç½®çš„æç¤ºè¯ï¼Œä½¿ç”¨åŸºç¡€æç¤ºè¯")
                return EnhancedConversationService._get_default_system_prompt(plan)

        except Exception as e:
            logger.error(f"è·å–ç³»ç»Ÿæç¤ºè¯å¤±è´¥: {e}")
            return EnhancedConversationService._get_default_system_prompt(plan)

    @staticmethod
    def _get_default_system_prompt(plan: TradingPlan) -> str:
        """è·å–é»˜è®¤ç³»ç»Ÿæç¤ºè¯ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰"""
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“AIåŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æå¸‚åœºæ•°æ®å¹¶åšå‡ºäº¤æ˜“å†³ç­–ã€‚

**äº¤æ˜“è®¡åˆ’ä¿¡æ¯**:
- äº¤æ˜“å¯¹: {plan.inst_id}
- æ—¶é—´å‘¨æœŸ: {plan.interval}
- ç¯å¢ƒ: {'ğŸ§ª æ¨¡æ‹Ÿç›˜' if plan.is_demo else 'ğŸ’° å®ç›˜'}
- è®¡åˆ’çŠ¶æ€: {plan.status}

**å·¥ä½œåŸåˆ™**:
1. åŸºäºæ•°æ®é©±åŠ¨çš„å†³ç­–
2. ä¸¥æ ¼æ‰§è¡Œé£é™©ç®¡ç†
3. ä¿æŒå®¢è§‚å’Œç†æ€§
4. ä½¿ç”¨ReActæ¨¡å¼è¿›è¡Œæ€è€ƒ
5. è¯¦ç»†è®°å½•å†³ç­–è¿‡ç¨‹

è¯·æ ¹æ®æä¾›çš„é¢„æµ‹æ•°æ®å’Œå¸‚åœºä¿¡æ¯ï¼Œè¿›è¡Œä¸“ä¸šçš„åˆ†æå’Œæ¨ç†ã€‚"""

    @staticmethod
    def add_system_prompt_message(
        conversation_id: int,
        content: str,
        template_id: Optional[int] = None
    ) -> AgentMessage:
        """
        æ·»åŠ ç³»ç»Ÿæç¤ºè¯æ¶ˆæ¯

        Args:
            conversation_id: å¯¹è¯ID
            content: æç¤ºè¯å†…å®¹
            template_id: æ¨¡æ¿ID

        Returns:
            æ¶ˆæ¯å¯¹è±¡
        """
        try:
            with get_db() as db:
                message = AgentMessage(
                    conversation_id=conversation_id,
                    role=MessageRole.SYSTEM.value,
                    message_type=MessageSubType.SYSTEM_PROMPT.value,
                    content=content,
                    metadata=json.dumps({
                        "template_id": template_id,
                        "timestamp": now_beijing().isoformat()
                    }),
                    created_at=now_beijing()
                )

                db.add(message)

                # æ›´æ–°å¯¹è¯çš„æœ€åæ¶ˆæ¯æ—¶é—´
                db.query(AgentConversation).filter(
                    AgentConversation.id == conversation_id
                ).update({
                    'last_message_at': now_beijing()
                })

                db.commit()
                db.refresh(message)

                logger.debug(f"æ·»åŠ ç³»ç»Ÿæç¤ºè¯æ¶ˆæ¯: conversation_id={conversation_id}")
                return message

        except Exception as e:
            logger.error(f"æ·»åŠ ç³»ç»Ÿæç¤ºè¯æ¶ˆæ¯å¤±è´¥: {e}")
            raise

    @staticmethod
    def add_kline_data_message(
        conversation_id: int,
        prediction_data: List[PredictionData],
        trigger_event: str = "manual_inference"
    ) -> AgentMessage:
        """
        æ·»åŠ Kçº¿æ•°æ®æ¶ˆæ¯ï¼ˆCSVæ ¼å¼ï¼‰

        Args:
            conversation_id: å¯¹è¯ID
            prediction_data: é¢„æµ‹æ•°æ®åˆ—è¡¨
            trigger_event: è§¦å‘äº‹ä»¶ç±»å‹

        Returns:
            æ¶ˆæ¯å¯¹è±¡
        """
        try:
            # è½¬æ¢ä¸ºCSVæ ¼å¼
            if not prediction_data:
                csv_content = "æš‚æ— é¢„æµ‹æ•°æ®"
            else:
                # æ„å»ºDataFrameå¹¶è½¬æ¢ä¸ºCSV
                df_data = []
                for data in prediction_data:
                    df_data.append({
                        'timestamp': data.timestamp.strftime('%Y-%m-%d %H:%M:%S UTC'),
                        'close': data.close,
                        'close_min': data.close_min,
                        'close_max': data.close_max,
                        'upward_probability': data.upward_probability,
                        'volatility_amplification_probability': data.volatility_amplification_probability
                    })

                df = pd.DataFrame(df_data)
                csv_content = df.to_csv(index=False)

            content = f"""**æœ€æ–°é¢„æµ‹æ•°æ®** (CSVæ ¼å¼):

{csv_content}

**æ•°æ®æ¥æº**: {trigger_event}
**è®°å½•æ•°é‡**: {len(prediction_data)}
**ç”Ÿæˆæ—¶é—´**: {now_beijing().strftime('%Y-%m-%d %H:%M:%S UTC+8')}"""

            with get_db() as db:
                message = AgentMessage(
                    conversation_id=conversation_id,
                    role=MessageRole.USER.value,
                    message_type=MessageSubType.KLINE_DATA.value,
                    content=content,
                    metadata=json.dumps({
                        "trigger_event": trigger_event,
                        "record_count": len(prediction_data),
                        "data_timestamps": [d.timestamp.isoformat() for d in prediction_data[:5]]  # åªä¿ç•™å‰5ä¸ªæ—¶é—´æˆ³
                    }),
                    created_at=now_beijing()
                )

                db.add(message)

                # æ›´æ–°å¯¹è¯çš„æœ€åæ¶ˆæ¯æ—¶é—´
                db.query(AgentConversation).filter(
                    AgentConversation.id == conversation_id
                ).update({
                    'last_message_at': now_beijing()
                })

                db.commit()
                db.refresh(message)

                logger.info(f"æ·»åŠ Kçº¿æ•°æ®æ¶ˆæ¯: conversation_id={conversation_id}, records={len(prediction_data)}")
                return message

        except Exception as e:
            logger.error(f"æ·»åŠ Kçº¿æ•°æ®æ¶ˆæ¯å¤±è´¥: {e}")
            raise

    @staticmethod
    async def add_assistant_message_stream(
        conversation_id: int,
        content_stream: AsyncGenerator[Dict[str, Any], None]
    ) -> AsyncGenerator[Tuple[AgentMessage, Dict[str, Any]], None]:
        """
        æµå¼æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯

        Args:
            conversation_id: å¯¹è¯ID
            content_stream: å†…å®¹æµç”Ÿæˆå™¨

        Yields:
            (æ¶ˆæ¯å¯¹è±¡, æµå¼æ•°æ®) å…ƒç»„
        """
        message_id = None
        accumulated_content = ""

        try:
            with get_db() as db:
                # åˆ›å»ºåˆå§‹æ¶ˆæ¯
                message = AgentMessage(
                    conversation_id=conversation_id,
                    role=MessageRole.ASSISTANT.value,
                    message_type=MessageSubType.TEXT.value,
                    content="",
                    metadata=json.dumps({
                        "streaming": True,
                        "started_at": now_beijing().isoformat()
                    }),
                    created_at=now_beijing()
                )

                db.add(message)
                db.commit()
                db.refresh(message)
                message_id = message.id

                logger.info(f"å¼€å§‹æµå¼åŠ©æ‰‹æ¶ˆæ¯: conversation_id={conversation_id}, message_id={message_id}")

            # å¤„ç†æµå¼å†…å®¹
            async for chunk_data in content_stream:
                chunk_content = chunk_data.get('content', '')
                chunk_type = chunk_data.get('type', 'content')

                if chunk_type in ['content', 'thinking', 'tool_call', 'tool_result']:
                    accumulated_content += chunk_content

                    # æ›´æ–°æ¶ˆæ¯å†…å®¹
                    with get_db() as db:
                        db.query(AgentMessage).filter(
                            AgentMessage.id == message_id
                        ).update({
                            'content': accumulated_content,
                            'metadata': json.dumps({
                                "streaming": True,
                                "last_update": now_beijing().isoformat(),
                                "chunk_count": chunk_data.get('chunk_count', 0)
                            })
                        })
                        db.commit()

                yield (message, chunk_data)

            # æ ‡è®°æµå¼å®Œæˆ
            with get_db() as db:
                db.query(AgentMessage).filter(
                    AgentMessage.id == message_id
                ).update({
                    'metadata': json.dumps({
                        "streaming": False,
                        "completed_at": now_beijing().isoformat(),
                        "final_length": len(accumulated_content)
                    })
                })
                db.commit()

            logger.info(f"å®Œæˆæµå¼åŠ©æ‰‹æ¶ˆæ¯: conversation_id={conversation_id}, message_id={message_id}")

        except Exception as e:
            logger.error(f"æµå¼åŠ©æ‰‹æ¶ˆæ¯å¤±è´¥: {e}")

            # æ ‡è®°é”™è¯¯çŠ¶æ€
            if message_id:
                try:
                    with get_db() as db:
                        db.query(AgentMessage).filter(
                            AgentMessage.id == message_id
                        ).update({
                            'metadata': json.dumps({
                                "streaming": False,
                                "error": str(e),
                                "failed_at": now_beijing().isoformat()
                            })
                        })
                        db.commit()
                except Exception as update_error:
                    logger.error(f"æ›´æ–°é”™è¯¯çŠ¶æ€å¤±è´¥: {update_error}")

            raise

    @staticmethod
    def get_conversation_messages(
        conversation_id: int,
        include_metadata: bool = False
    ) -> List[Dict[str, Any]]:
        """
        è·å–å¯¹è¯æ¶ˆæ¯ï¼ˆè½¬æ¢ä¸ºChatbotæ ¼å¼ï¼‰

        Args:
            conversation_id: å¯¹è¯ID
            include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•°æ®

        Returns:
            æ¶ˆæ¯åˆ—è¡¨
        """
        try:
            with get_db() as db:
                messages = db.query(AgentMessage).filter(
                    AgentMessage.conversation_id == conversation_id
                ).order_by(AgentMessage.created_at.asc()).all()

                chatbot_messages = []

                for msg in messages:
                    # ç³»ç»Ÿæç¤ºè¯è½¬æ¢ä¸ºassistantè§’è‰²ä»¥ä¾¿åœ¨chatbotä¸­æ­£ç¡®æ˜¾ç¤º
                    if msg.message_type == MessageSubType.SYSTEM_PROMPT.value:
                        chatbot_msg = {
                            "role": "assistant",  # ç³»ç»Ÿæç¤ºè¯ä½¿ç”¨assistantè§’è‰²æ˜¾ç¤º
                            "content": f"ğŸ¤– **ç³»ç»Ÿæç¤ºè¯**\n\n{msg.content}",
                            "timestamp": msg.created_at.isoformat(),
                            "metadata": {"collapsible": True, "default_collapsed": False, "type": "system"}
                        }
                    elif msg.message_type == MessageSubType.KLINE_DATA.value:
                        chatbot_msg = {
                            "role": "user",  # é¢„æµ‹æ•°æ®ä½œä¸ºç”¨æˆ·è¾“å…¥æ˜¾ç¤º
                            "content": f"ğŸ“Š **é¢„æµ‹æ•°æ®**\n\n{msg.content}",
                            "timestamp": msg.created_at.isoformat(),
                            "metadata": {"collapsible": True, "default_collapsed": False, "type": "data"}
                        }
                    else:
                        chatbot_msg = {
                            "role": msg.role,
                            "content": msg.content,
                            "timestamp": msg.created_at.isoformat()
                        }

                        # æ·»åŠ ç‰¹æ®Šæ ¼å¼åŒ–å’Œå…ƒæ•°æ®
                        if msg.message_type == MessageSubType.THINKING.value:
                            chatbot_msg["content"] = f"ğŸ§  **AIæ€è€ƒè¿‡ç¨‹**\n\n{msg.content}"
                            chatbot_msg["metadata"] = {"collapsible": True, "default_collapsed": True, "type": "thinking"}
                        elif msg.message_type == MessageSubType.TOOL_CALL.value:
                            chatbot_msg["metadata"] = {"collapsible": True, "default_collapsed": False, "type": "tool_call"}
                        elif msg.message_type == MessageSubType.TOOL_RESULT.value:
                            chatbot_msg["metadata"] = {"collapsible": True, "default_collapsed": False, "type": "tool_result"}

                    # åŒ…å«åŸå§‹å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    if include_metadata and msg.metadata:
                        try:
                            original_metadata = json.loads(msg.metadata)
                            if "metadata" in chatbot_msg:
                                chatbot_msg["metadata"].update(original_metadata)
                            else:
                                chatbot_msg["metadata"] = original_metadata
                        except json.JSONDecodeError:
                            pass

                    chatbot_messages.append(chatbot_msg)

                return chatbot_messages

        except Exception as e:
            logger.error(f"è·å–å¯¹è¯æ¶ˆæ¯å¤±è´¥: {e}")
            return []

    @staticmethod
    def get_latest_conversation_by_type(
        plan_id: int,
        conversation_type: ConversationType
    ) -> Optional[AgentConversation]:
        """è·å–æŒ‡å®šç±»å‹çš„æœ€æ–°å¯¹è¯"""
        try:
            with get_db() as db:
                return db.query(AgentConversation).filter(
                    and_(
                        AgentConversation.plan_id == plan_id,
                        AgentConversation.conversation_type == conversation_type.value,
                        AgentConversation.status == 'active'
                    )
                ).order_by(desc(AgentConversation.last_message_at)).first()

        except Exception as e:
            logger.error(f"è·å–æœ€æ–°å¯¹è¯å¤±è´¥: {e}")
            return None

    @staticmethod
    def format_for_chatbot(messages: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """
        æ ¼å¼åŒ–æ¶ˆæ¯ä¸ºChatbotæ ¼å¼

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        formatted_messages = []

        for msg in messages:
            formatted_msg = {
                "role": msg.get("role", "user"),
                "content": msg.get("content", "")
            }

            # æ·»åŠ ç‰¹æ®Šæ ·å¼
            if msg.get("metadata", {}).get("collapsible"):
                formatted_msg["metadata"] = msg["metadata"]

            formatted_messages.append(formatted_msg)

        return formatted_messages


# å…¨å±€å®ä¾‹
enhanced_conversation_service = EnhancedConversationService()