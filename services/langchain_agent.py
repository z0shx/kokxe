"""
LangChain Agent æœåŠ¡
æ ¸å¿ƒåŠŸèƒ½ï¼š
- ä½¿ç”¨ LangChain Agent + Tools
- åˆæˆæç¤ºè¯
- æµå¼è¾“å‡ºåˆ° Gradio Chatbot
- æ”¯æŒ Qwen think æ¨¡å¼
- æ˜¾ç¤ºå·¥å…·è°ƒç”¨äº¤äº’
- æ”¯æŒæŒç»­å¯¹è¯
"""
import json
import asyncio
import traceback
import pytz
from typing import Dict, List, AsyncGenerator, Optional, Any
from datetime import datetime
from sqlalchemy import and_, desc

from database.models import (
    TradingPlan, AgentConversation, AgentMessage,
    LLMConfig, TrainingRecord, PredictionData, now_beijing
)
from database.db import get_db
from utils.logger import setup_logger
from services.trading_tools import OKXTradingTools

# LangChain imports
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

logger = setup_logger(__name__, "langchain_agent.log")


class LangChainAgentService:
    """LangChain Agent æœåŠ¡"""

    def __init__(self):
        self._trading_tools = None
        self._llm_clients = {}

    @staticmethod
    def _parse_extra_params(extra_params):
        """è§£æé¢å¤–å‚æ•°"""
        if not extra_params:
            return {}
        try:
            return extra_params if isinstance(extra_params, dict) else json.loads(extra_params)
        except:
            return {}

    @staticmethod
    def _get_llm_base_params(llm_config):
        """è·å–LLMåŸºç¡€å‚æ•°"""
        return {
            "model": llm_config.model_name,
            "temperature": llm_config.temperature or 0.7,
            "max_tokens": llm_config.max_tokens or 2000
        }

    @staticmethod
    def _format_tool_response(success: bool, data=None, error=None, **kwargs):
        """ç»Ÿä¸€çš„å·¥å…·å“åº”æ ¼å¼"""
        response = {"success": success}
        if success:
            response.update(data or {})
            response["timestamp"] = now_beijing().isoformat()
        else:
            response["error"] = error
        return json.dumps(response, ensure_ascii=False)

    @property
    def trading_tools(self):
        """æ‡’åŠ è½½äº¤æ˜“å·¥å…·"""
        if self._trading_tools is None:
            from config import Config
            self._trading_tools = OKXTradingTools(
                api_key=Config.OKX_API_KEY,
                secret_key=Config.OKX_SECRET_KEY,
                passphrase=Config.OKX_PASSPHRASE
            )
        return self._trading_tools

    def get_plan_trading_tools(self, plan_id: int):
        """è·å–è®¡åˆ’ç‰¹å®šçš„äº¤æ˜“å·¥å…·"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    logger.error(f"è®¡åˆ’ä¸å­˜åœ¨: plan_id={plan_id}")
                    return None

                # ä½¿ç”¨è®¡åˆ’ç‰¹å®šçš„APIå¯†é’¥
                return OKXTradingTools(
                    api_key=plan.okx_api_key,
                    secret_key=plan.okx_secret_key,
                    passphrase=plan.okx_passphrase,
                    is_demo=plan.is_demo,
                    trading_limits=plan.trading_limits,
                    plan_id=plan_id  # ä¼ é€’è®¡åˆ’IDç”¨äºè®¢å•å­˜å‚¨
                )

        except Exception as e:
            logger.error(f"è·å–è®¡åˆ’ç‰¹å®šäº¤æ˜“å·¥å…·å¤±è´¥: {e}")
            return None

    def _get_llm_client(self, llm_config: LLMConfig):
        """è·å– LLM å®¢æˆ·ç«¯"""
        client_key = f"{llm_config.provider}_{llm_config.model_name}"

        if client_key not in self._llm_clients:
            base_params = self._get_llm_base_params(llm_config)

            if llm_config.provider == "openai":
                self._llm_clients[client_key] = ChatOpenAI(
                    **base_params,
                    openai_api_key=llm_config.api_key
                )
            elif llm_config.provider == "anthropic":
                self._llm_clients[client_key] = ChatAnthropic(
                    **base_params,
                    anthropic_api_key=llm_config.api_key
                )
            elif llm_config.provider == "qwen":
                # Qwen ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
                base_url = llm_config.api_base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1"
                extra_params = self._parse_extra_params(getattr(llm_config, 'extra_params', None))

                model_kwargs = {}
                if extra_params.get('enable_thinking', False):
                    model_kwargs = {"enable_thinking": True}

                self._llm_clients[client_key] = ChatOpenAI(
                    **base_params,
                    openai_api_key=llm_config.api_key,
                    openai_api_base=base_url,
                    model_kwargs=model_kwargs
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ LLM æä¾›å•†: {llm_config.provider}")

        return self._llm_clients[client_key]

    def _create_langchain_tools(self, tools_config: Dict[str, bool], plan_id: int) -> List[Any]:
        """åˆ›å»º LangChain å·¥å…·"""
        available_tools = {}
        enabled_tools = [name for name, enabled in tools_config.items() if enabled]

        # è·å–è®¡åˆ’ç‰¹å®šçš„äº¤æ˜“å·¥å…·
        plan_trading_tools = self.get_plan_trading_tools(plan_id)
        if not plan_trading_tools:
            logger.error(f"æ— æ³•è·å–è®¡åˆ’ {plan_id} çš„äº¤æ˜“å·¥å…·")
            return list(available_tools.values())

        # è·å–è®¡åˆ’ä¿¡æ¯
        with get_db() as db:
            plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()

        # 1. è·å–å½“å‰ä»·æ ¼å·¥å…·
        if "get_current_price" in enabled_tools:
            @tool
            def get_current_price(inst_id: str = None) -> str:
                """è·å–äº¤æ˜“å¯¹å½“å‰ä»·æ ¼"""
                try:
                    inst_id = inst_id or plan.inst_id
                    price = plan_trading_tools.get_current_price(inst_id)
                    return json.dumps({
                        "success": True,
                        "inst_id": inst_id,
                        "current_price": price,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"è·å–ä»·æ ¼å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["get_current_price"] = get_current_price

        # 2. è·å–å½“å‰åŒ—äº¬æ—¶é—´ (UTC+8)
        if "get_current_utc_time" in enabled_tools:
            @tool
            def get_current_utc_time() -> str:
                """è·å–å½“å‰åŒ—äº¬æ—¶é—´ (UTC+8)"""
                # è·å–åŒ—äº¬æ—¶é—´
                beijing_tz = pytz.timezone('Asia/Shanghai')
                beijing_time = datetime.now(beijing_tz)
                return json.dumps({
                    "success": True,
                    "current_time": beijing_time.strftime('%Y-%m-%d %H:%M:%S'),
                    "timezone": "UTC+8"
                }, ensure_ascii=False)

            available_tools["get_current_utc_time"] = get_current_utc_time

        # 3. æŸ¥è¯¢æŒä»“
        if "get_positions" in enabled_tools:
            @tool
            def get_positions() -> str:
                """æŸ¥è¯¢å½“å‰æŒä»“"""
                try:
                    positions = plan_trading_tools.get_positions()
                    return json.dumps({
                        "success": True,
                        "positions": positions,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"æŸ¥è¯¢æŒä»“å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["get_positions"] = get_positions

        # 4. ä¸‹å•å·¥å…·
        if "place_order" in enabled_tools:
            @tool
            def place_order(inst_id: str, side: str, order_type: str, size: str, price: str = None) -> str:
                """ä¸‹å•äº¤æ˜“

                Args:
                    inst_id: äº¤æ˜“å¯¹ï¼Œå¦‚ ETH-USDT
                    side: ä¹°å–æ–¹å‘ï¼Œbuy æˆ– sell
                    order_type: è®¢å•ç±»å‹ï¼Œmarket æˆ– limit
                    size: ä¸‹å•æ•°é‡
                    price: ä¸‹å•ä»·æ ¼ï¼ˆé™ä»·å•éœ€è¦ï¼‰
                """
                # å‚æ•°éªŒè¯
                if not inst_id:
                    return json.dumps({"success": False, "error": "äº¤æ˜“å¯¹ä¸èƒ½ä¸ºç©º"}, ensure_ascii=False)
                if side not in ["buy", "sell"]:
                    return json.dumps({"success": False, "error": "ä¹°å–æ–¹å‘å¿…é¡»æ˜¯ buy æˆ– sell"}, ensure_ascii=False)
                if order_type not in ["market", "limit"]:
                    return json.dumps({"success": False, "error": "è®¢å•ç±»å‹å¿…é¡»æ˜¯ market æˆ– limit"}, ensure_ascii=False)
                if not size or float(size) <= 0:
                    return json.dumps({"success": False, "error": "ä¸‹å•æ•°é‡å¿…é¡»å¤§äº0"}, ensure_ascii=False)
                if order_type == "limit" and (not price or float(price) <= 0):
                    return json.dumps({"success": False, "error": "é™ä»·å•å¿…é¡»æŒ‡å®šæœ‰æ•ˆä»·æ ¼"}, ensure_ascii=False)
                try:
                    result = plan_trading_tools.place_order(
                        inst_id=inst_id, side=side,
                        order_type=order_type, size=size, price=price
                    )
                    return json.dumps({
                        "success": True,
                        "result": result,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"ä¸‹å•å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["place_order"] = place_order

        # 5. å–æ¶ˆè®¢å•å·¥å…·
        if "cancel_order" in enabled_tools:
            @tool
            def cancel_order(inst_id: str, order_id: str) -> str:
                """å–æ¶ˆè®¢å•

                Args:
                    inst_id: äº¤æ˜“å¯¹
                    order_id: è®¢å•ID
                """
                try:
                    result = plan_trading_tools.cancel_order(inst_id, order_id)
                    return json.dumps({
                        "success": True,
                        "result": result,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"å–æ¶ˆè®¢å•å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["cancel_order"] = cancel_order

        # 6. æŸ¥è¯¢äº¤æ˜“é™åˆ¶
        if "get_trading_limits" in enabled_tools:
            @tool
            def get_trading_limits() -> str:
                """æŸ¥è¯¢äº¤æ˜“é™åˆ¶"""
                try:
                    limits = plan_trading_tools.get_trading_limits()
                    return json.dumps({
                        "success": True,
                        "limits": limits,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"æŸ¥è¯¢äº¤æ˜“é™åˆ¶å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["get_trading_limits"] = get_trading_limits

        # 7. æŸ¥è¯¢è´¦æˆ·ä½™é¢
        if "get_account_balance" in enabled_tools:
            @tool
            def get_account_balance(ccy: str = None) -> str:
                """æŸ¥è¯¢è´¦æˆ·ä½™é¢"""
                try:
                    balance = plan_trading_tools.get_account_balance(ccy)
                    return json.dumps({
                        "success": True,
                        "balance": balance,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"æŸ¥è¯¢è´¦æˆ·ä½™é¢å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["get_account_balance"] = get_account_balance

        # 8. æŸ¥è¯¢å¾…æˆäº¤è®¢å•
        if "get_pending_orders" in enabled_tools:
            @tool
            def get_pending_orders(inst_id: str = None, state: str = "live") -> str:
                """æŸ¥è¯¢å¾…æˆäº¤è®¢å•"""
                try:
                    orders = plan_trading_tools.get_pending_orders(inst_id, state)
                    return json.dumps({
                        "success": True,
                        "orders": orders,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"æŸ¥è¯¢å¾…æˆäº¤è®¢å•å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["get_pending_orders"] = get_pending_orders

        # 9. ä¿®æ”¹è®¢å•
        if "amend_order" in enabled_tools:
            @tool
            def amend_order(inst_id: str, order_id: str, new_size: str = None, new_price: str = None) -> str:
                """ä¿®æ”¹è®¢å•"""
                try:
                    result = plan_trading_tools.amend_order_with_db_save(
                        inst_id=inst_id,
                        order_id=order_id,
                        new_size=new_size,
                        new_price=new_price
                    )
                    return json.dumps({
                        "success": True,
                        "result": result,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"ä¿®æ”¹è®¢å•å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["amend_order"] = amend_order

        # 10. æŸ¥è¯¢å†å²Kçº¿æ•°æ®
        if "query_historical_kline_data" in enabled_tools:
            @tool
            def query_historical_kline_data(
                inst_id: str,
                interval: str = '1H',
                start_time: str = None,
                end_time: str = None,
                limit: int = 100
            ) -> str:
                """æŸ¥è¯¢å†å²Kçº¿æ•°æ®

                Args:
                    inst_id: äº¤æ˜“å¯¹æ ‡è¯†ç¬¦ï¼Œå¦‚ 'ETH-USDT'
                    interval: Kçº¿å‘¨æœŸï¼Œæ”¯æŒ '1m', '5m', '15m', '30m', '1H', '2H', '4H', '6H', '12H', '1D', '1W', '1M', '3M', '6M', '1Y'
                    start_time: å¼€å§‹æ—¶é—´ï¼ŒISOæ ¼å¼å­—ç¬¦ä¸²ï¼Œå¦‚ '2024-01-01T00:00:00Z'
                    end_time: ç»“æŸæ—¶é—´ï¼ŒISOæ ¼å¼å­—ç¬¦ä¸²ï¼Œå¦‚ '2024-12-31T23:59:59Z'
                    limit: è¿”å›æ•°æ®æ¡æ•°ï¼Œé»˜è®¤100ï¼Œæœ€å¤§1000
                """
                try:
                    # å‚æ•°éªŒè¯
                    if not inst_id or not isinstance(inst_id, str):
                        return json.dumps({"success": False, "error": "inst_idå¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²"}, ensure_ascii=False)

                    valid_intervals = ['1m', '5m', '15m', '30m', '1H', '2H', '4H', '6H', '12H', '1D', '1W', '1M', '3M', '6M', '1Y']
                    if interval not in valid_intervals:
                        return json.dumps({"success": False, "error": f"intervalå¿…é¡»æ˜¯ä»¥ä¸‹å€¼ä¹‹ä¸€: {valid_intervals}"}, ensure_ascii=False)

                    if limit and (not isinstance(limit, int) or limit <= 0 or limit > 1000):
                        return json.dumps({"success": False, "error": "limitå¿…é¡»æ˜¯1-1000ä¹‹é—´çš„æ•´æ•°"}, ensure_ascii=False)

                    from services.trading_tools import OKXTradingTools
                    kline_data = plan_trading_tools.query_historical_kline_data(
                        inst_id=inst_id,
                        interval=interval,
                        start_time=start_time,
                        end_time=end_time,
                        limit=limit
                    )
                    return json.dumps({
                        "success": True,
                        "data": kline_data,
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"æŸ¥è¯¢å†å²Kçº¿æ•°æ®å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["query_historical_kline_data"] = query_historical_kline_data

        # 11. æ‰§è¡Œæ¨¡å‹æ¨ç†
        if "run_latest_model_inference" in enabled_tools:
            @tool
            def run_latest_model_inference() -> str:
                """æ‰§è¡Œæœ€æ–°çš„AIæ¨¡å‹æ¨ç†"""
                try:
                    from services.inference_service import InferenceService
                    inference_service = InferenceService()
                    # ä½¿ç”¨åŒæ­¥æ–¹æ³•é¿å…å¼‚æ­¥è°ƒç”¨é—®é¢˜
                    result = inference_service.run_inference_async(plan_id)
                    import asyncio
                    # å¦‚æœè¿”å›çš„æ˜¯åç¨‹ï¼Œéœ€è¦ç­‰å¾…
                    if asyncio.iscoroutine(result):
                        result = asyncio.run(result)
                    return json.dumps({
                        "success": True,
                        "message": "æ¨¡å‹æ¨ç†å·²å¯åŠ¨",
                        "result": str(result),
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"æ‰§è¡Œæ¨¡å‹æ¨ç†å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["run_latest_model_inference"] = run_latest_model_inference

        # 12. æŸ¥è¯¢é¢„æµ‹æ•°æ®
        if "query_prediction_data" in enabled_tools:
            @tool
            def query_prediction_data(limit: int = 50) -> str:
                """æŸ¥è¯¢AIæ¨¡å‹é¢„æµ‹æ•°æ®"""
                try:
                    # å‚æ•°éªŒè¯
                    if not isinstance(limit, int) or limit <= 0 or limit > 500:
                        return json.dumps({"success": False, "error": "limitå¿…é¡»æ˜¯1-500ä¹‹é—´çš„æ•´æ•°"}, ensure_ascii=False)

                    from database.models import PredictionData
                    with get_db() as db:
                        predictions = db.query(PredictionData).filter(
                            PredictionData.plan_id == plan_id
                        ).order_by(PredictionData.timestamp.desc()).limit(limit).all()

                        data = []
                        for pred in predictions:
                            data.append({
                                "timestamp": pred.timestamp.isoformat(),
                                "close": pred.close,
                                "close_min": pred.close_min,
                                "close_max": pred.close_max,
                                "upward_probability": pred.upward_probability
                            })

                    return json.dumps({
                        "success": True,
                        "data": data,
                        "count": len(data),
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"æŸ¥è¯¢é¢„æµ‹æ•°æ®å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["query_prediction_data"] = query_prediction_data

        # 13. è·å–é¢„æµ‹å†å²
        if "get_prediction_history" in enabled_tools:
            @tool
            def get_prediction_history(limit: int = 20) -> str:
                """è·å–å†å²é¢„æµ‹è®°å½•"""
                try:
                    # å‚æ•°éªŒè¯
                    if not isinstance(limit, int) or limit <= 0 or limit > 100:
                        return json.dumps({"success": False, "error": "limitå¿…é¡»æ˜¯1-100ä¹‹é—´çš„æ•´æ•°"}, ensure_ascii=False)

                    from database.models import TrainingRecord, PredictionData
                    with get_db() as db:
                        records = db.query(TrainingRecord).filter(
                            TrainingRecord.plan_id == plan_id,
                            TrainingRecord.status == 'completed'
                        ).order_by(TrainingRecord.created_at.desc()).limit(limit).all()

                        data = []
                        for record in records:
                            # è·å–è¯¥è®­ç»ƒè®°å½•çš„é¢„æµ‹æ•°æ®æ•°é‡
                            pred_count = db.query(PredictionData).filter(
                                PredictionData.training_record_id == record.id
                            ).count()

                            data.append({
                                "training_id": record.id,
                                "model_version": record.version,
                                "created_at": record.created_at.isoformat(),
                                "prediction_count": pred_count,
                                "status": record.status
                            })

                    return json.dumps({
                        "success": True,
                        "data": data,
                        "count": len(data),
                        "timestamp": now_beijing().isoformat()
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"è·å–é¢„æµ‹å†å²å¤±è´¥: {e}")
                    return json.dumps({"success": False, "error": str(e)}, ensure_ascii=False)

            available_tools["get_prediction_history"] = get_prediction_history

        return list(available_tools.values())

    def _detect_qwen_thinking(self, content: str, llm_config: LLMConfig = None) -> bool:
        """æ£€æµ‹ Qwen æ€è€ƒæ¨¡å¼çš„åŒé‡ç­–ç•¥"""
        if not content or not content.strip():
            return False

        # ç­–ç•¥1: å†…å®¹æ£€æµ‹
        thinking_indicators = [
            "æ€è€ƒ:", "è®©æˆ‘åˆ†æ", "é¦–å…ˆ", "æ¥ä¸‹æ¥", "ç»¼åˆè€ƒè™‘",
            "åˆ†æç»“æœ", "åˆ¤æ–­", "å†³ç­–", "å»ºè®®", "æ ¹æ®",
            "æ€è€ƒï¼š", "è€ƒè™‘åˆ°", "ä»å¸‚åœºè§’åº¦çœ‹", "æŠ€æœ¯åˆ†æ"
        ]

        if any(indicator in content for indicator in thinking_indicators):
            return True

        # ç­–ç•¥2: Agentå±‚çº§é…ç½®æ£€æµ‹
        if llm_config and llm_config.provider == "qwen":
            if hasattr(llm_config, 'extra_params') and llm_config.extra_params:
                try:
                    extra_params = llm_config.extra_params if isinstance(llm_config.extra_params, dict) else json.loads(llm_config.extra_params)
                    if extra_params.get('enable_thinking', False):
                        return True
                except:
                    pass

        return False

    def _build_system_prompt(self, plan: TradingPlan, tools_config: Dict[str, bool]) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯ - ä¸‰éƒ¨åˆ†ç»“æ„"""
        # ç¬¬ä¸€éƒ¨åˆ†ï¼šåŠ¨æ€ç”¨æˆ·æç¤ºè¯
        dynamic_prompt = plan.agent_prompt or "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“AIåŠ©æ‰‹ã€‚"

        # ç¬¬äºŒéƒ¨åˆ†ï¼šå¯ç”¨å·¥å…·æè¿°
        tools_desc = []
        enabled_tools = [name for name, enabled in tools_config.items() if enabled]

        tool_descriptions = {
            "get_current_price": "è·å–äº¤æ˜“å¯¹çš„å½“å‰ä»·æ ¼",
            "get_current_utc_time": "è·å–å½“å‰åŒ—äº¬æ—¶é—´ (UTC+8)",
            "get_positions": "æŸ¥è¯¢å½“å‰æŒä»“ä¿¡æ¯",
            "place_order": "ä¸‹å•äº¤æ˜“ï¼ˆä¹°å…¥æˆ–å–å‡ºï¼‰",
            "cancel_order": "å–æ¶ˆè®¢å•",
            "get_trading_limits": "æŸ¥è¯¢äº¤æ˜“é™åˆ¶",
            "amend_order": "ä¿®æ”¹è®¢å•ï¼ˆè°ƒæ•´ä»·æ ¼æˆ–æ•°é‡ï¼‰",
            "query_historical_kline_data": "æŸ¥è¯¢å†å²Kçº¿æ•°æ®ï¼ˆæ”¯æŒå¤šç§æ—¶é—´å‘¨æœŸå’Œè‡ªå®šä¹‰æ—¶é—´èŒƒå›´ï¼‰",
            "get_pending_orders": "æŸ¥è¯¢å¾…æˆäº¤è®¢å•åˆ—è¡¨",
            "get_account_balance": "æŸ¥è¯¢è´¦æˆ·ä½™é¢ä¿¡æ¯",
            "query_prediction_data": "æŸ¥è¯¢AIæ¨¡å‹é¢„æµ‹æ•°æ®",
            "get_prediction_history": "è·å–å†å²é¢„æµ‹è®°å½•",
            "run_latest_model_inference": "æ‰§è¡Œæœ€æ–°çš„AIæ¨¡å‹æ¨ç†",
            "query_historical_kline_data": "æŸ¥è¯¢å†å²Kçº¿æ•°æ®"
        }

        for tool_name in enabled_tools:
            if tool_name in tool_descriptions:
                tools_desc.append(f"- {tool_name}: {tool_descriptions[tool_name]}")

        # ç¬¬ä¸‰éƒ¨åˆ†ï¼šäº¤æ˜“é™åˆ¶å’Œè®¡åˆ’ä¿¡æ¯
        limits_desc = ""
        if plan.trading_limits:
            try:
                limits = plan.trading_limits if isinstance(plan.trading_limits, dict) else json.loads(plan.trading_limits)
                if limits:
                    # ç”Ÿæˆå‹å¥½çš„äº¤æ˜“é™åˆ¶æç¤ºè¯æ–‡æœ¬
                    limits_text = self._build_trading_limits_prompt(limits)
                    limits_desc = f"\n\näº¤æ˜“é™åˆ¶é…ç½®ï¼š\n{limits_text}"
            except:
                pass

        # æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""{dynamic_prompt}

å¯ç”¨å·¥å…·ï¼š
{chr(10).join(tools_desc) if tools_desc else "æ— å¯ç”¨å·¥å…·"}

äº¤æ˜“è®¡åˆ’ä¿¡æ¯ï¼š
- äº¤æ˜“å¯¹: {plan.inst_id}
- æ—¶é—´å‘¨æœŸ: {plan.interval}
- åˆå§‹æœ¬é‡‘: {plan.initial_capital} USDT
{limits_desc}

è¯·æ ¹æ®ä»¥ä¸Šè¦æ±‚ï¼Œå¹¶ä½¿ç”¨ç›¸åº”çš„å·¥å…·æ¥å®Œæˆäº¤æ˜“å†³ç­–æ“ä½œã€‚"""

        return system_prompt

    def _build_trading_limits_prompt(self, limits: Dict) -> str:
        """æ„å»ºäº¤æ˜“é™åˆ¶çš„æç¤ºè¯æ–‡æœ¬"""
        limits_parts = []

        # å¯ç”¨èµ„é‡‘ (USDT)
        available_usdt = limits.get('available_usdt_amount', 0)
        if available_usdt > 0:
            limits_parts.append(f"- å¯ç”¨èµ„é‡‘: {available_usdt} USDT (ä¸‹å•ä¹°å…¥æ—¶ä½¿ç”¨)")

        # èµ„é‡‘æ¯”ä¾‹ (%)
        usdt_percentage = limits.get('available_usdt_percentage', 0)
        if usdt_percentage > 0:
            limits_parts.append(f"- èµ„é‡‘æ¯”ä¾‹: {usdt_percentage}% (å¦‚æœå¯ç”¨èµ„é‡‘ä¸è¶³ï¼Œåˆ™ä½¿ç”¨è´¦æˆ·å¯ç”¨èµ„é‡‘ç™¾åˆ†æ¯”è®¡ç®—)")

        # å¹³æ‘Šå•é‡
        avg_orders = limits.get('avg_order_count', 1)
        if avg_orders > 0:
            limits_parts.append(f"- å¹³æ‘Šå•é‡: {avg_orders} ç¬” (æŒ‚å•é™åˆ¶ï¼Œæœ€å¤šæœªæˆäº¤è®¢å•æ•°)")

        # æ­¢æŸæ¯”ä¾‹ (%)
        stop_loss = limits.get('stop_loss_percentage', 0)
        if stop_loss > 0:
            limits_parts.append(f"- æ­¢æŸæ¯”ä¾‹: {stop_loss}% (å¦‚æœä¹°å…¥åä»·æ ¼ä½äºé¢„æœŸï¼Œè§¦å‘æŒ‚å•è°ƒä»·)")

        if not limits_parts:
            return "- æœªè®¾ç½®ç‰¹æ®Šäº¤æ˜“é™åˆ¶"

        return "\n".join(limits_parts)

    async def stream_conversation(
        self,
        plan_id: int,
        user_message: str,
        conversation_type: str = "manual_chat"
    ) -> AsyncGenerator[List[Dict[str, str]], None]:
        """æµå¼å¯¹è¯"""
        # è·å–è®¡åˆ’å’Œé…ç½®
        with get_db() as db:
            plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
            if not plan:
                yield [{"role": "assistant", "content": "âŒ è®¡åˆ’ä¸å­˜åœ¨"}]
                return

            llm_config = db.query(LLMConfig).filter(LLMConfig.id == plan.llm_config_id).first()
            if not llm_config:
                yield [{"role": "assistant", "content": "âŒ LLMé…ç½®ä¸å­˜åœ¨"}]
                return

            # åˆ›å»ºæˆ–è·å–å¯¹è¯
            # å¯¹äºä¸åŒç±»å‹é‡‡ç”¨ä¸åŒç­–ç•¥
            if conversation_type == 'auto_inference':
                # è‡ªåŠ¨æ¨ç†æ€»æ˜¯åˆ›å»ºæ–°å¯¹è¯ï¼Œä¸å¤ç”¨
                conversation = None
            elif conversation_type == "inference_session":
                # æ¨ç†ä¼šè¯æ¯æ¬¡éƒ½åˆ›å»ºæ–°ä¼šè¯ï¼ˆé‡ç½®ä¸Šä¸‹æ–‡ï¼‰
                conversation = None
            else:
                # å…¶ä»–ç±»å‹å°è¯•å¤ç”¨ç°æœ‰å¯¹è¯
                conversation = db.query(AgentConversation).filter(
                    AgentConversation.plan_id == plan_id,
                    AgentConversation.status == 'active',
                    AgentConversation.conversation_type == conversation_type
                ).first()

            # å¦‚æœæ²¡æœ‰ç°æœ‰å¯¹è¯ï¼Œåˆ›å»ºæ–°å¯¹è¯
            if not conversation:
                conversation = AgentConversation(
                    plan_id=plan_id,
                    conversation_type=conversation_type,
                    status='active',
                    started_at=now_beijing(),
                    last_message_at=now_beijing()
                )
                db.add(conversation)
                db.commit()
                db.refresh(conversation)

        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°åˆ›å»ºçš„å¯¹è¯
        is_new_conversation = (conversation.created_at == conversation.last_message_at)

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        tools_config = plan.agent_tools_config or {}
        system_prompt = self._build_system_prompt(plan, tools_config)

        # å¦‚æœæ˜¯æ–°å¯¹è¯ï¼Œè¾“å‡ºç³»ç»Ÿæç¤ºè¯
        if is_new_conversation:
            # è¾“å‡ºç³»ç»Ÿæ¶ˆæ¯ - ä½¿ç”¨ç”¨æˆ·è¦æ±‚çš„ "System:" æ ¼å¼
            yield [{"role": "system", "content": system_prompt}]

            # ä¿å­˜ç³»ç»Ÿæ¶ˆæ¯åˆ°æ•°æ®åº“
            try:
                with get_db() as db:
                    await self._save_message(
                        db, conversation.id, "system", system_prompt, "text"
                    )
            except Exception as e:
                logger.error(f"ä¿å­˜ç³»ç»Ÿæ¶ˆæ¯å¤±è´¥: {e}")
        else:
            # åŠ è½½å†å²æ¶ˆæ¯
            yield await self._load_conversation_history(conversation.id)

        # è¾“å‡ºç”¨æˆ·æ¶ˆæ¯
        yield [{"role": "user", "content": user_message}]
        try:
            with get_db() as db:
                await self._save_message(
                    db, conversation.id, "user", user_message, "text"
                )
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}")

        try:
            # è·å– LLM å’Œå·¥å…·
            llm = self._get_llm_client(llm_config)
            tools = self._create_langchain_tools(tools_config, plan_id)

            # æ„å»ºæ¶ˆæ¯å†å²
            with get_db() as db:
                # è·å–å†å²æ¶ˆæ¯
                history = db.query(AgentMessage).filter(
                    AgentMessage.conversation_id == conversation.id
                ).order_by(AgentMessage.created_at).all()

                messages = [SystemMessage(content=system_prompt)]

                # æ·»åŠ å†å²å¯¹è¯ï¼ˆæ’é™¤åˆšåˆšä¿å­˜çš„ç³»ç»Ÿå’Œç”¨æˆ·æ¶ˆæ¯ï¼‰
                for msg in history[:-2]:
                    if msg.role == "user":
                        messages.append(HumanMessage(content=msg.content))
                    elif msg.role == "assistant":
                        messages.append(AIMessage(content=msg.content))
                    elif msg.role == "tool":
                        messages.append(ToolMessage(content=msg.content, tool_call_id=msg.tool_call_id or ""))

                # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
                messages.append(HumanMessage(content=user_message))

            # åˆ›å»º Agent
            if tools:
                prompt = ChatPromptTemplate.from_messages([
                    ("system", system_prompt),
                    MessagesPlaceholder("chat_history", optional=True),
                    ("human", "{input}"),
                    MessagesPlaceholder("agent_scratchpad")
                ])

                agent = create_openai_tools_agent(llm, tools, prompt)
                agent_executor = AgentExecutor(
                    agent=agent,
                    tools=tools,
                    verbose=False,
                    handle_parsing_errors=True,
                    return_intermediate_steps=True
                )

                # æµå¼æ‰§è¡Œ Agent
                response = ""
                logger.info(f"PLAN {plan_id} - å¼€å§‹Agentæµå¼æ‰§è¡Œï¼ŒLLM: {llm_config.model_name}")
                logger.debug(f"PLAN {plan_id} - è¾“å…¥æ¶ˆæ¯é•¿åº¦: {len(user_message)} å­—ç¬¦")

                chunk_count = 0
                async for chunk in agent_executor.astream({"input": user_message, "chat_history": messages[1:-1]}):
                    chunk_count += 1
                    logger.debug(f"PLAN {plan_id} - Agent chunk #{chunk_count}: {type(chunk)} - {list(chunk.keys()) if isinstance(chunk, dict) else str(chunk)[:100]}")
                    # å¤„ç†å·¥å…·è°ƒç”¨
                    if "actions" in chunk:
                        for action in chunk["actions"]:
                            tool_name = getattr(action, 'tool', 'unknown')
                            tool_input = getattr(action, 'tool_input', {})

                            # ç”Ÿæˆå·¥å…·è°ƒç”¨IDå¹¶è®°å½•å¼€å§‹æ—¶é—´
                            import uuid
                            import time
                            tool_call_id = str(uuid.uuid4())[:8]
                            tool_start_time = time.time()

                            # ä¸ºäº¤æ˜“å·¥å…·è®¾ç½®ä¸Šä¸‹æ–‡ä¿¡æ¯
                            plan_trading_tools = self.get_plan_trading_tools(plan_id)
                            if plan_trading_tools:
                                plan_trading_tools.set_tool_context(
                                    conversation_id=conversation.id,
                                    tool_call_id=tool_call_id
                                )

                            # è¾“å‡ºå·¥å…·è°ƒç”¨ - ä½¿ç”¨æ–°çš„ role:tool_call
                            tool_call_data = {
                                "tool_name": tool_name,
                                "arguments": tool_input,
                                "status": "calling",
                                "tool_call_id": tool_call_id
                            }
                            tool_call_content = json.dumps(tool_call_data, ensure_ascii=False)
                            logger.info(f"PLAN {plan_id} - å·¥å…·è°ƒç”¨: {tool_name}, ID: {tool_call_id}")
                            logger.debug(f"PLAN {plan_id} - å·¥å…·è°ƒç”¨å‚æ•°: {tool_input}")
                            yield [{"role": "tool_call", "content": tool_call_content}]

                            # ä¿å­˜å·¥å…·è°ƒç”¨åˆ°æ•°æ®åº“
                            with get_db() as db:
                                await self._save_message(
                                    db, conversation.id, "tool",
                                    f"è°ƒç”¨å·¥å…· {tool_name}", "tool_call",
                                    tool_name=tool_name,
                                    tool_args=tool_input,
                                    tool_call_id=tool_call_id,
                                    tool_execution_time=None  # è°ƒç”¨æ—¶æš‚ä¸è®°å½•æ—¶é—´
                                )

                    # å¤„ç†å·¥å…·ç»“æœ
                    if "steps" in chunk:
                        for step in chunk["steps"]:
                            if hasattr(step, 'observation') and step.observation:
                                obs = step.observation
                                tool_name = getattr(step.action, 'tool', 'unknown') if hasattr(step, 'action') else 'unknown'

                                # è®¡ç®—å·¥å…·æ‰§è¡Œæ—¶é—´
                                tool_execution_time = time.time() - tool_start_time

                                # æ ¼å¼åŒ–å·¥å…·ç»“æœ - ä½¿ç”¨æ–°çš„ role:tool_result
                                try:
                                    tool_params = getattr(step.action, 'tool_input', {})

                                    # å°è¯•è§£æç»“æœ
                                    if isinstance(obs, str) and obs.startswith('{'):
                                        try:
                                            result_data = json.loads(obs)
                                            result = result_data
                                        except:
                                            result = {"raw_result": obs}
                                    else:
                                        result = {"raw_result": obs}

                                    # åˆ›å»ºå·¥å…·ç»“æœæ•°æ®
                                    tool_result_data = {
                                        "tool_name": tool_name,
                                        "arguments": tool_params,
                                        "result": result,
                                        "status": "success" if not obs.startswith("ERROR") else "error"
                                    }

                                    tool_result_content = json.dumps(tool_result_data, ensure_ascii=False)
                                    logger.info(f"PLAN {plan_id} - å·¥å…·ç»“æœ: {tool_name}, çŠ¶æ€: {tool_result_data['status']}")
                                    logger.debug(f"PLAN {plan_id} - å·¥å…·ç»“æœé•¿åº¦: {len(tool_result_content)} å­—ç¬¦")
                                    yield [{"role": "tool_result", "content": tool_result_content}]

                                except Exception as e:
                                    # é”™è¯¯æƒ…å†µä¸‹ä¹Ÿè¿”å›ç»“æ„åŒ–æ•°æ®
                                    error_data = {
                                        "tool_name": tool_name,
                                        "arguments": getattr(step.action, 'tool_input', {}),
                                        "result": {"error": str(e)},
                                        "status": "error"
                                    }
                                    tool_error_content = json.dumps(error_data, ensure_ascii=False)
                                    yield [{"role": "tool_result", "content": tool_error_content}]

                                # ä¿å­˜å·¥å…·ç»“æœåˆ°æ•°æ®åº“
                                related_order_id = None
                                if tool_name in ['place_order', 'amend_order', 'cancel_order']:
                                    # å°è¯•ä»å·¥å…·ç»“æœä¸­æå–è®¢å•ID
                                    try:
                                        if isinstance(obs, str) and obs.startswith('{'):
                                            result_data = json.loads(obs)
                                            if result_data.get('success') and result_data.get('order_id'):
                                                related_order_id = result_data['order_id']
                                    except:
                                        pass

                                with get_db() as db:
                                    await self._save_message(
                                        db, conversation.id, "tool",
                                        f"å·¥å…· {tool_name} æ‰§è¡Œå®Œæˆ", "tool_result",
                                        tool_name=tool_name,
                                    tool_args=getattr(step.action, 'tool_input', {}),
                                    tool_result=obs,
                                        tool_call_id=tool_call_id,
                                        tool_execution_time=tool_execution_time,
                                        related_order_id=related_order_id
                                    )

                    # å¤„ç†æœ€ç»ˆè¾“å‡º
                    if "output" in chunk:
                        output = chunk["output"]
                        if output and output.strip():
                            response = output
                            # æ£€æŸ¥æ˜¯å¦æ˜¯æ€è€ƒè¿‡ç¨‹ï¼ˆæŸäº›æ¨¡å‹å¦‚Qwenä¼šè¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼‰
                            if output.startswith("<think>") or output.startswith("æ€è€ƒ:"):
                                formatted_output = f"ğŸ§  **æ€è€ƒè¿‡ç¨‹**:\n\n{output}"
                            else:
                                formatted_output = f"ğŸ¤– **AIåŠ©æ‰‹å›å¤**:\n\n{output}"
                            # å®ç°æµå¼è¾“å‡º
                            chunk_size = 15
                            for i in range(0, len(output), chunk_size):
                                chunk_text = output[i:i+chunk_size]
                                if i == 0:
                                    if output.startswith("æ€è€ƒ:") or "æ€è€ƒè¿‡ç¨‹" in output:
                                        prefix = "ğŸ§  **æ€è€ƒè¿‡ç¨‹**:\n\n"
                                    else:
                                        prefix = "ğŸ¤– **AIåŠ©æ‰‹å›å¤**:\n\n"
                                    formatted_chunk = prefix + chunk_text
                                else:
                                    formatted_chunk = chunk_text

                                yield [{"role": "assistant", "content": formatted_chunk}]
                                import asyncio
                                await asyncio.sleep(0.03)

                            # ä¿å­˜åŠ©æ‰‹å›å¤åˆ°æ•°æ®åº“
                            with get_db() as db:
                                await self._save_message(
                                    db, conversation.id, "assistant", output, "text"
                                )

            else:
                # æ²¡æœ‰å·¥å…·ï¼Œç›´æ¥ä½¿ç”¨ LLM
                response = ""
                async for chunk in llm.astream(messages):
                    content = self._extract_content_from_chunk(chunk)
                    if content and content.strip():
                        response += content
                        yield [{"role": "assistant", "content": content}]

                # ä¿å­˜å®Œæ•´å›å¤åˆ°æ•°æ®åº“
                if response:
                    with get_db() as db:
                        await self._save_message(
                            db, conversation.id, "assistant", response, "text"
                        )

            # æ›´æ–°å¯¹è¯çŠ¶æ€
            with get_db() as db:
                conversation = db.query(AgentConversation).filter(
                    AgentConversation.id == conversation.id
                ).first()
                if conversation:
                    conversation.last_message_at = now_beijing()
                    db.commit()

        except Exception as e:
            logger.error(f"Agent æ‰§è¡Œå¤±è´¥: {e}")
            logger.debug(f"Agent æ‰§è¡Œå¤±è´¥è¯¦æƒ…: {traceback.format_exc()}")
            yield [{"role": "assistant", "content": f"âŒ Agent æ‰§è¡Œå¤±è´¥: {str(e)}"}]

            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            with get_db() as db:
                await self._save_message(
                    db, conversation.id, "assistant",
                    f"Agent æ‰§è¡Œå¤±è´¥: {str(e)}", "text"
                )

    def _extract_content_from_chunk(self, chunk) -> Optional[str]:
        """ä» chunk ä¸­æå–å†…å®¹ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
        if not chunk:
            return None

        # æ–¹æ³•1: æ ‡å‡† content å±æ€§
        if hasattr(chunk, 'content'):
            content = chunk.content
            if content and isinstance(content, str) and content.strip():
                return content

        # æ–¹æ³•2: text å±æ€§
        if hasattr(chunk, 'text'):
            text = chunk.text
            if text and isinstance(text, str) and text.strip():
                return text

        # æ–¹æ³•3: å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œæ’é™¤å¯¹è±¡è¡¨ç¤º
        try:
            chunk_str = str(chunk)
            if (len(chunk_str) > 0 and
                not chunk_str.startswith('<') and
                not chunk_str.startswith('AIMessage') and
                not chunk_str.startswith('ChatMessage') and
                not 'content=' in chunk_str and
                not 'additional_kwargs=' in chunk_str and
                not 'response_metadata=' in chunk_str and
                chunk_str.strip()):
                return chunk_str
        except:
            pass

        return None

    async def _save_message(
        self,
        db,
        conversation_id: int,
        role: str,
        content: str,
        message_type: str,
        tool_name: str = None,
        tool_args: dict = None,
        tool_result: str = None,
        tool_call_id: str = None,
        tool_execution_time: float = None,
        related_order_id: str = None
    ):
        """ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“"""
        try:
            message = AgentMessage(
                conversation_id=conversation_id,
                role=role,
                content=content,
                message_type=message_type,
                tool_name=tool_name,
                tool_arguments=json.dumps(tool_args) if tool_args else None,
                tool_result=json.dumps(tool_result) if tool_result else None,
                tool_call_id=tool_call_id,
                tool_execution_time=tool_execution_time,
                related_order_id=related_order_id,
                created_at=now_beijing()
            )
            db.add(message)

            # æ›´æ–°å¯¹è¯çš„æœ€åæ¶ˆæ¯æ—¶é—´
            conversation = db.query(AgentConversation).filter(AgentConversation.id == conversation_id).first()
            if conversation:
                conversation.last_message_at = now_beijing()

            db.commit()
            logger.debug(f"æˆåŠŸä¿å­˜æ¶ˆæ¯: role={role}, conversation_id={conversation_id}")
        except Exception as e:
            logger.error(f"ä¿å­˜æ¶ˆæ¯å¤±è´¥: conversation_id={conversation_id}, role={role}, error={e}")
            # ä¸é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…ä¸­æ–­agentæ‰§è¡Œ

    async def _load_conversation_history(self, conversation_id: int) -> List[Dict[str, str]]:
        """åŠ è½½å¯¹è¯å†å²æ¶ˆæ¯"""
        try:
            from database.models import AgentMessage
            with get_db() as db:
                messages = db.query(AgentMessage).filter(
                    AgentMessage.conversation_id == conversation_id
                ).order_by(AgentMessage.created_at.asc()).all()

                # è½¬æ¢ä¸ºæµå¼æ¶ˆæ¯æ ¼å¼
                history_messages = []
                for message in messages:
                    role = message.role
                    content = message.content

                    # æ ¹æ®æ¶ˆæ¯ç±»å‹è½¬æ¢æ ¼å¼
                    if message.message_type == "thinking":
                        formatted_content = f"ğŸ’­ **æ€è€ƒè¿‡ç¨‹**:\\n{content}"
                        history_messages.append({"role": "assistant", "content": formatted_content})
                    elif message.message_type in ["tool_call", "tool_result"]:
                        # å·¥å…·æ¶ˆæ¯ - æ„é€ JSONæ ¼å¼
                        tool_data = {
                            "tool_name": message.tool_name or "",
                            "arguments": message.tool_arguments or {},
                            "result": message.tool_result or {},
                            "status": "success" if message.message_type == "tool_result" else "calling",
                            "tool_call_id": message.tool_call_id or ""
                        }
                        tool_content = json.dumps(tool_data, ensure_ascii=False)

                        if message.message_type == "tool_call":
                            formatted_content = f"ğŸ”§ **å·¥å…·è°ƒç”¨**: `{tool_data['tool_name']}`\\n\\nå‚æ•°: {json.dumps(tool_data.get('arguments', {}), indent=2, ensure_ascii=False)}"
                        else:
                            formatted_content = f"âœ… **å·¥å…·å®Œæˆ**: `{tool_data['tool_name']}`\\n\\nç»“æœ: {json.dumps(tool_data.get('result', {}), indent=2, ensure_ascii=False)}"

                        history_messages.append({"role": "assistant", "content": formatted_content})
                    elif message.message_type == "play_result":
                        # æŠ•èµ„ç»“æœ
                        history_messages.append({"role": "assistant", "content": content})
                    else:
                        # æ™®é€šæ¶ˆæ¯
                        history_messages.append({"role": role, "content": content})

                return history_messages

        except Exception as e:
            logger.error(f"åŠ è½½å¯¹è¯å†å²å¤±è´¥: {e}")
            return []

    async def test_connection(self, plan_id: int) -> bool:
        """æµ‹è¯•è¿æ¥"""
        try:
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    return False

                llm_config = db.query(LLMConfig).filter(LLMConfig.id == plan.llm_config_id).first()
                if not llm_config:
                    return False

            llm = self._get_llm_client(llm_config)
            messages = [
                SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹"),
                HumanMessage(content="ç®€å•å›å¤ï¼šæµ‹è¯•æˆåŠŸ")
            ]

            result = await llm.ainvoke(messages)
            return hasattr(result, 'content') and result.content is not None

        except Exception as e:
            logger.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False


    def extract_order_ids_from_tool_results(self, tool_results: List[Dict]) -> List[str]:
        """
        ä»å·¥å…·ç»“æœä¸­æå–æ‰€æœ‰è®¢å•ID

        Args:
            tool_results: å·¥å…·æ‰§è¡Œç»“æœåˆ—è¡¨

        Returns:
            List[str]: æå–åˆ°çš„è®¢å•IDåˆ—è¡¨ï¼ˆå»é‡ï¼‰
        """
        order_ids = []

        for result in tool_results:
            if not isinstance(result, dict):
                continue

            # æ£€æŸ¥ä¸åŒå·¥å…·çš„è®¢å•IDä½ç½®
            if result.get('success'):
                result_data = result.get('result', result)

                # place_order, cancel_order, amend_order çš„è®¢å•ID
                if 'order_id' in result_data:
                    order_ids.append(str(result_data['order_id']))

                # æ‰¹é‡æ“ä½œçš„å¤šä¸ªè®¢å•ID
                if 'order_ids' in result_data:
                    order_ids.extend([str(oid) for oid in result_data['order_ids']])

                # OKX API å“åº”æ ¼å¼
                if 'data' in result_data and isinstance(result_data['data'], list):
                    for item in result_data['data']:
                        if 'ordId' in item:
                            order_ids.append(str(item['ordId']))
                        if 'order_id' in item:
                            order_ids.append(str(item['order_id']))

        return list(set(order_ids))  # å»é‡

    async def auto_decision(
        self,
        plan_id: int,
        training_id: int = None,
        prediction_data: List[Dict] = None
    ) -> AsyncGenerator[List[Dict[str, str]], None]:
        """
        åŸºäºé¢„æµ‹æ•°æ®çš„è‡ªåŠ¨å†³ç­–ï¼ˆåå°æ¨ç†ï¼Œä¸å±•ç¤ºåˆ°chatbotï¼‰

        Args:
            plan_id: è®¡åˆ’ID
            training_id: è®­ç»ƒè®°å½•IDï¼ˆå¯é€‰ï¼‰
            prediction_data: é¢„æµ‹æ•°æ®ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä»æ•°æ®åº“è·å–ï¼‰

        Yields:
            æµå¼æ¶ˆæ¯åˆ—è¡¨
        """
        try:
            logger.info(f"å¼€å§‹è‡ªåŠ¨å†³ç­–: plan_id={plan_id}, training_id={training_id}")

            # è·å–è®¡åˆ’å’Œé…ç½®
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    yield [{"role": "assistant", "content": "âŒ è®¡åˆ’ä¸å­˜åœ¨"}]
                    return

                llm_config = db.query(LLMConfig).filter(LLMConfig.id == plan.llm_config_id).first()
                if not llm_config:
                    yield [{"role": "assistant", "content": "âŒ LLMé…ç½®ä¸å­˜åœ¨"}]
                    return

            # è·å–é¢„æµ‹æ•°æ®
            if not prediction_data:
                predictions = self._get_latest_predictions(plan_id, training_id)
            else:
                # å°†å­—å…¸æ ¼å¼è½¬æ¢ä¸ºPredictionDataå¯¹è±¡ï¼ˆæ¨¡æ‹Ÿï¼‰
                predictions = prediction_data

            if not predictions:
                yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®"}]
                return

            logger.info(f"è·å–åˆ° {len(predictions)} æ¡é¢„æµ‹æ•°æ®")

            # æ„å»ºå†³ç­–æç¤ºè¯
            decision_prompt = self._build_decision_prompt(plan, predictions)

            logger.info("å¼€å§‹æµå¼è‡ªåŠ¨å†³ç­–...")

            # ä½¿ç”¨ç»Ÿä¸€çš„æµå¼å¯¹è¯æ¥å£è¿›è¡Œè‡ªåŠ¨æ¨ç†
            async for chunk in self.stream_conversation(
                plan_id=plan_id,
                user_message=decision_prompt,
                conversation_type="auto_inference"
            ):
                yield chunk

            logger.info("è‡ªåŠ¨å†³ç­–å®Œæˆ")

        except Exception as e:
            logger.error(f"è‡ªåŠ¨å†³ç­–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield [{"role": "assistant", "content": f"âŒ è‡ªåŠ¨å†³ç­–å¤±è´¥: {str(e)}"}]

    async def manual_inference(self, plan_id: int) -> AsyncGenerator[List[Dict[str, str]], None]:
        """
        ç»Ÿä¸€çš„æ‰‹åŠ¨æ¨ç†å…¥å£ï¼ˆæµå¼ï¼‰

        Args:
            plan_id: è®¡åˆ’ID

        Yields:
            æµå¼æ¶ˆæ¯åˆ—è¡¨
        """
        try:
            logger.info(f"å¼€å§‹æ‰‹åŠ¨æ¨ç†: plan_id={plan_id}")

            # è·å–è®¡åˆ’å’Œé…ç½®
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    yield [{"role": "assistant", "content": "âŒ è®¡åˆ’ä¸å­˜åœ¨"}]
                    return

                llm_config = db.query(LLMConfig).filter(LLMConfig.id == plan.llm_config_id).first()
                if not llm_config:
                    yield [{"role": "assistant", "content": "âŒ LLMé…ç½®ä¸å­˜åœ¨"}]
                    return

            # è·å–æœ€æ–°çš„è®­ç»ƒè®°å½•
            with get_db() as db:
                latest_training = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status == 'completed',
                        TrainingRecord.is_active == True
                    )
                ).order_by(desc(TrainingRecord.created_at)).first()

                if not latest_training:
                    yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒè®°å½•ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ"}]
                    return

            # ä½¿ç”¨è‡ªåŠ¨å†³ç­–åŠŸèƒ½ï¼Œä½†æŒ‡å®šä¸ºæ‰‹åŠ¨æ¨ç†ç±»å‹
            async for chunk in self.auto_decision(plan_id, latest_training.id):
                yield chunk

        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield [{"role": "assistant", "content": f"âŒ æ‰‹åŠ¨æ¨ç†å¤±è´¥: {str(e)}"}]

    async def scheduled_decision(self, plan_id: int, training_id: int) -> AsyncGenerator[List[Dict[str, str]], None]:
        """
        å®šæ—¶ä»»åŠ¡å†³ç­–å…¥å£

        Args:
            plan_id: è®¡åˆ’ID
            training_id: è®­ç»ƒè®°å½•ID

        Yields:
            æµå¼æ¶ˆæ¯åˆ—è¡¨
        """
        try:
            logger.info(f"å¼€å§‹å®šæ—¶å†³ç­–: plan_id={plan_id}, training_id={training_id}")

            # ä½¿ç”¨è‡ªåŠ¨å†³ç­–åŠŸèƒ½ï¼Œä½†æŒ‡å®šä¸ºå®šæ—¶å†³ç­–ç±»å‹
            async for chunk in self.stream_conversation(
                plan_id=plan_id,
                user_message=f"è¯·åŸºäºè®­ç»ƒè®°å½• v{training_id} çš„é¢„æµ‹æ•°æ®è¿›è¡Œå®šæ—¶äº¤æ˜“å†³ç­–åˆ†æ",
                conversation_type="scheduled_decision"
            ):
                yield chunk

        except Exception as e:
            logger.error(f"å®šæ—¶å†³ç­–å¤±è´¥: {e}")
            yield [{"role": "assistant", "content": f"âŒ å®šæ—¶å†³ç­–å¤±è´¥: {str(e)}"}]

    def _get_latest_predictions(self, plan_id: int, training_id: int = None) -> List[PredictionData]:
        """è·å–æœ€æ–°çš„é¢„æµ‹æ•°æ®ï¼ˆä»agent_decision_serviceè¿ç§»é€»è¾‘ï¼‰"""
        try:
            with get_db() as db:
                if training_id:
                    # ä½¿ç”¨æŒ‡å®šçš„è®­ç»ƒè®°å½•
                    predictions = db.query(PredictionData).filter(
                        PredictionData.training_record_id == training_id
                    ).order_by(PredictionData.timestamp).all()
                    logger.info(f"ä½¿ç”¨æŒ‡å®šè®­ç»ƒè®°å½• {training_id}ï¼Œè·å–åˆ° {len(predictions)} æ¡é¢„æµ‹æ•°æ®")
                else:
                    # è·å–æœ€æ–°çš„é¢„æµ‹æ•°æ®
                    latest_training = db.query(TrainingRecord).filter(
                        TrainingRecord.plan_id == plan_id,
                        TrainingRecord.status == 'completed'
                    ).order_by(TrainingRecord.completed_at.desc()).first()

                    if latest_training:
                        predictions = db.query(PredictionData).filter(
                            PredictionData.training_record_id == latest_training.id
                        ).order_by(PredictionData.timestamp).all()
                        logger.info(f"ä½¿ç”¨æœ€æ–°è®­ç»ƒè®°å½• {latest_training.id}ï¼Œè·å–åˆ° {len(predictions)} æ¡é¢„æµ‹æ•°æ®")
                    else:
                        predictions = []
                        logger.warning(f"è®¡åˆ’ {plan_id} æ²¡æœ‰æ‰¾åˆ°å®Œæˆçš„è®­ç»ƒè®°å½•")

                return predictions

        except Exception as e:
            logger.error(f"è·å–é¢„æµ‹æ•°æ®å¤±è´¥: {e}")
            return []

    def _build_decision_prompt(self, plan: TradingPlan, predictions: List[PredictionData]) -> str:
        """æ„å»ºå†³ç­–æç¤ºè¯"""
        try:
            # æ ¼å¼åŒ–é¢„æµ‹æ•°æ®
            pred_text = []
            for pred in predictions[:20]:  # é™åˆ¶æ˜¾ç¤ºæœ€æ–°çš„20æ¡é¢„æµ‹æ•°æ®
                pred_text.append(
                    f"æ—¶é—´: {pred.timestamp.strftime('%Y-%m-%d %H:%M')}, "
                    f"é¢„æµ‹ä»·æ ¼: {pred.predicted_price:.6f}, "
                    f"ç½®ä¿¡åº¦: {pred.confidence:.2f}, "
                    f"ä¸Šæ¶¨æ¦‚ç‡: {pred.upward_prob:.2%}, "
                    f"æ³¢åŠ¨ç‡: {pred.volatility:.2%}"
                )

            # è·å–å½“å‰ä»·æ ¼ä¿¡æ¯
            current_price_info = ""
            try:
                trading_tools = self.get_plan_trading_tools(plan.id)
                if trading_tools:
                    current_price = trading_tools.get_current_price(plan.inst_id)
                    current_price_info = f"\nå½“å‰ä»·æ ¼: {current_price}"
            except Exception as e:
                logger.warning(f"è·å–å½“å‰ä»·æ ¼å¤±è´¥: {e}")
                current_price_info = "\nå½“å‰ä»·æ ¼: æ— æ³•è·å–"

            # æ„å»ºå†³ç­–æç¤ºè¯
            prompt = f"""åŸºäºä»¥ä¸‹é¢„æµ‹æ•°æ®è¿›è¡Œäº¤æ˜“å†³ç­–åˆ†æï¼š

äº¤æ˜“è®¡åˆ’ï¼š{plan.inst_id} ({plan.interval})
å½“å‰æ—¶é—´ï¼š{now_beijing().strftime('%Y-%m-%d %H:%M:%S')}{current_price_info}

é¢„æµ‹æ•°æ®ï¼š
{chr(10).join(pred_text)}

è¯·åˆ†æè¿™äº›é¢„æµ‹æ•°æ®ï¼Œç»™å‡ºå…·ä½“çš„äº¤æ˜“å»ºè®®ï¼š
1. å½“å‰å¸‚åœºè¶‹åŠ¿åˆ†æ
2. å»ºè®®çš„äº¤æ˜“æ“ä½œï¼ˆä¹°å…¥/å–å‡º/æŒæœ‰ï¼‰
3. å…·ä½“çš„ä¸‹å•ç­–ç•¥ï¼ˆä»·æ ¼ã€æ•°é‡ç­‰ï¼‰
4. é£é™©æ§åˆ¶å»ºè®®

å¦‚æœå†³å®šæ‰§è¡Œäº¤æ˜“ï¼Œè¯·ä½¿ç”¨ç›¸åº”çš„å·¥å…·è¿›è¡Œæ“ä½œã€‚è¯·åŸºäºé‡åŒ–åˆ†æç»“æœåšå‡ºå†³ç­–ï¼Œè€Œä¸æ˜¯ä¸»è§‚çŒœæµ‹ã€‚"""

            return prompt

        except Exception as e:
            logger.error(f"æ„å»ºå†³ç­–æç¤ºè¯å¤±è´¥: {e}")
            return "è¯·åŸºäºå¯ç”¨çš„é¢„æµ‹æ•°æ®è¿›è¡Œäº¤æ˜“å†³ç­–åˆ†æã€‚"

    def get_unified_decisions(self, plan_id: int, limit: int = 50):
        """
        ç»Ÿä¸€çš„å†³ç­–æŸ¥è¯¢æ¥å£ï¼Œå…¼å®¹å†å²æ•°æ®

        Args:
            plan_id: è®¡åˆ’ID
            limit: è¿”å›è®°å½•æ•°é™åˆ¶

        Returns:
            List[Dict]: ç»Ÿä¸€æ ¼å¼çš„å†³ç­–è®°å½•åˆ—è¡¨
        """
        decisions = []

        try:
            with get_db() as db:
                # 1. ä¼˜å…ˆä»AgentMessageè·å–æ–°æ•°æ®
                auto_messages = db.query(AgentMessage).join(AgentConversation).filter(
                    AgentConversation.plan_id == plan_id,
                    AgentConversation.conversation_type.in_(['auto_inference', 'scheduled_decision']),
                    AgentMessage.role == 'assistant'
                ).order_by(AgentMessage.created_at.desc()).limit(limit).all()

                for msg in auto_messages:
                    decisions.append({
                        'id': msg.id,
                        'created_at': msg.created_at,
                        'content': msg.content,
                        'source': 'agent_message',
                        'conversation_id': msg.conversation_id,
                        'conversation_type': db.query(AgentConversation).filter(
                            AgentConversation.id == msg.conversation_id
                        ).first().conversation_type if msg.conversation_id else 'unknown'
                    })

                # 2. ä»æ—§çš„AgentDecisionè·å–å†å²æ•°æ®ï¼ˆåªè¯»ï¼Œå…¼å®¹æ€§ï¼‰
                try:
                    from database.models import AgentDecision
                    old_decisions = db.query(AgentDecision).filter(
                        AgentDecision.plan_id == plan_id
                    ).order_by(AgentDecision.decision_time.desc()).limit(limit).all()

                    for decision in old_decisions:
                        decisions.append({
                            'id': decision.id,
                            'created_at': decision.decision_time,
                            'content': f"å†³ç­–ç±»å‹: {decision.decision_type}\næ¨ç†: {decision.reasoning}\nçŠ¶æ€: {decision.status}",
                            'source': 'agent_decision',
                            'training_id': decision.training_record_id,
                            'llm_model': decision.llm_model
                        })
                except ImportError:
                    # AgentDecisionæ¨¡å‹å¯èƒ½å·²è¢«åˆ é™¤ï¼Œè·³è¿‡
                    pass

            # æŒ‰æ—¶é—´æ’åº
            decisions.sort(key=lambda x: x['created_at'], reverse=True)
            return decisions[:limit]

        except Exception as e:
            logger.error(f"è·å–ç»Ÿä¸€å†³ç­–è®°å½•å¤±è´¥: {e}")
            return []


# å…¨å±€å®ä¾‹
agent_service = LangChainAgentService()