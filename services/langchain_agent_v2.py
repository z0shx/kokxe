"""
ç»Ÿä¸€çš„LangChain AgentæœåŠ¡ v2 - ä½¿ç”¨ç°ä»£API
æ•´åˆäº†æ¨ç†ã€å¯¹è¯ã€æµå¼è¾“å‡ºåŠŸèƒ½ï¼Œé€‚é…Gradio Chatbotæ¥å£
"""
import json
import asyncio
from typing import Dict, List, AsyncGenerator, Optional, Any, Tuple
from datetime import datetime
from enum import Enum
import re

from sqlalchemy import func

from database.models import (
    TradingPlan, PredictionData, AgentConversation,
    AgentMessage, LLMConfig, TrainingRecord
)
from database.db import get_db
from utils.logger import setup_logger
from services.trading_tools import OKXTradingTools
from database.models import now_beijing

# Modern LangChain imports
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
# ä½¿ç”¨æ›´ç°ä»£çš„Agent APIï¼Œé¿å…ä¾èµ–å†²çª
try:
    from langchain.agents import AgentExecutor, create_openai_tools_agent
    AGENT_AVAILABLE = True
except ImportError:
    AGENT_AVAILABLE = False
    print("è­¦å‘Š: LangChain Agents APIä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ‰‹åŠ¨å·¥å…·è°ƒç”¨")

logger = setup_logger(__name__, "langchain_agent_v2.log")


class ConversationType(Enum):
    """å¯¹è¯ç±»å‹æšä¸¾"""
    MANUAL_CHAT = "manual_chat"
    AUTO_INFERENCE = "auto_inference"


class MessageRole(Enum):
    """æ¶ˆæ¯è§’è‰²æšä¸¾"""
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    TOOL = "tool"
    PLAY = "play"


class MessageType(Enum):
    """æ¶ˆæ¯ç±»å‹æšä¸¾"""
    TEXT = "text"
    THINKING = "thinking"
    TOOL_CALL = "tool_call"
    TOOL_RESULT = "tool_result"
    PLAY_RESULT = "play_result"


class LangChainAgentV2Service:
    """ç»Ÿä¸€çš„LangChain AgentæœåŠ¡ v2ï¼Œä½¿ç”¨ç°ä»£APIé€‚é…Gradio Chatbotæ¥å£"""

    def __init__(self):
        self._trading_tools = None
        self._llm_clients = {}

    @property
    def trading_tools(self):
        """æ‡’åŠ è½½trading tools"""
        if self._trading_tools is None:
            from config import Config
            self._trading_tools = OKXTradingTools(
                api_key=Config.OKX_API_KEY,
                secret_key=Config.OKX_SECRET_KEY,
                passphrase=Config.OKX_PASSPHRASE
            )
        return self._trading_tools

    def _get_llm_client(self, llm_config: LLMConfig):
        """è·å–LLMå®¢æˆ·ç«¯"""
        client_key = f"{llm_config.provider}_{llm_config.model_name}"

        if client_key not in self._llm_clients:
            if llm_config.provider == "openai":
                self._llm_clients[client_key] = ChatOpenAI(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    openai_api_key=llm_config.api_key
                )
            elif llm_config.provider == "anthropic":
                self._llm_clients[client_key] = ChatAnthropic(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    anthropic_api_key=llm_config.api_key
                )
            elif llm_config.provider == "qwen":
                # ä½¿ç”¨OpenAIæ¥å£å…¼å®¹æ–¹å¼æ”¯æŒQwen
                base_url = llm_config.api_base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1"

                # è·å–é¢å¤–å‚æ•°
                extra_params = {}
                if hasattr(llm_config, 'extra_params') and llm_config.extra_params:
                    try:
                        extra_params = llm_config.extra_params if isinstance(llm_config.extra_params, dict) else json.loads(llm_config.extra_params)
                    except:
                        extra_params = {}

                # é…ç½®æ€è€ƒæ¨¡å¼
                model_kwargs = {}
                if extra_params.get('enable_thinking', False):
                    model_kwargs = {"enable_thinking": True}

                self._llm_clients[client_key] = ChatOpenAI(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    openai_api_key=llm_config.api_key,
                    openai_api_base=base_url,
                    model_kwargs=model_kwargs
                )
            else:
                raise ValueError(f"Unsupported LLM provider: {llm_config.provider}")

        return self._llm_clients[client_key]

    def _create_langchain_tools(self, tools_config: Dict[str, bool], plan_id: int = None):
        """åˆ›å»ºLangChainå·¥å…· - é‡æ„ç‰ˆæœ¬ï¼Œä¸“æ³¨äº10ä¸ªæ ¸å¿ƒå·¥å…·"""
        from database.db import get_db
        from database.models import TradingPlan, PredictionData

        available_tools = {}

        # åªå¯ç”¨é…ç½®ä¸­å¯ç”¨çš„å·¥å…·
        enabled_tools = [name for name, enabled in tools_config.items() if enabled]

        # è·å–è®¡åˆ’ä¿¡æ¯ç”¨äºå·¥å…·è°ƒç”¨
        plan_info = None
        if plan_id:
            with get_db() as db:
                plan_info = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()

        # 1. æŸ¥è¯¢é¢„æµ‹æ•°æ®å·¥å…·
        if "query_prediction_data" in enabled_tools:
            @tool
            def query_prediction_data(
                plan_id: int,
                start_time: str = None,
                end_time: str = None,
                inference_batch_id: str = None,
                limit: int = 50
            ) -> Dict[str, Any]:
                """æŸ¥è¯¢æ•°æ®åº“ä¸­çš„é¢„æµ‹æ•°æ®,æŒ‰æ—¶é—´èŒƒå›´ã€æ‰¹æ¬¡IDç­‰æ¡ä»¶æŸ¥è¯¢

                Args:
                    plan_id: è®¡åˆ’ID
                    start_time: å¼€å§‹æ—¶é—´(UTC+8), æ ¼å¼: '2025-01-01 00:00:00'
                    end_time: ç»“æŸæ—¶é—´(UTC+8), æ ¼å¼: '2025-01-01 23:59:59'
                    inference_batch_id: æ‰¹æ¬¡ID
                    limit: è¿”å›æ•°é‡é™åˆ¶ï¼Œé»˜è®¤50
                """
                try:
                    with get_db() as db:
                        query = db.query(PredictionData).filter(PredictionData.plan_id == plan_id)

                        # æ—¶é—´èŒƒå›´æŸ¥è¯¢
                        if start_time:
                            from datetime import datetime
                            start_dt = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')
                            query = query.filter(PredictionData.timestamp >= start_dt)
                        if end_time:
                            from datetime import datetime
                            end_dt = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')
                            query = query.filter(PredictionData.timestamp <= end_dt)

                        # æ‰¹æ¬¡IDæŸ¥è¯¢
                        if inference_batch_id:
                            query = query.filter(PredictionData.inference_batch_id == inference_batch_id)

                        # é™åˆ¶æ•°é‡å¹¶æŒ‰æ—¶é—´å€’åº
                        predictions = query.order_by(PredictionData.timestamp.desc()).limit(limit).all()

                        return {
                            "success": True,
                            "count": len(predictions),
                            "data": [
                                {
                                    "timestamp": pred.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                                    "inference_batch_id": pred.inference_batch_id,
                                    "open": pred.open,
                                    "high": pred.high,
                                    "low": pred.low,
                                    "close": pred.close,
                                    "close_min": pred.close_min,
                                    "close_max": pred.close_max,
                                    "upward_probability": pred.upward_probability,
                                    "volatility_amplification_probability": pred.volatility_amplification_probability
                                } for pred in predictions
                            ]
                        }
                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["query_prediction_data"] = query_prediction_data

        # 2. æŸ¥è¯¢å†å²é¢„æµ‹æ‰¹æ¬¡å·¥å…·
        if "get_prediction_history" in enabled_tools:
            @tool
            def get_prediction_history(plan_id: int, limit: int = 30) -> Dict[str, Any]:
                """æŸ¥è¯¢å†å²é¢„æµ‹æ•°æ®,è¿”å›æ¨ç†æ‰¹æ¬¡åˆ—è¡¨

                Args:
                    plan_id: è®¡åˆ’ID
                    limit: è¿”å›æ‰¹æ¬¡æ•°é‡ï¼Œæœ€å¤š30ä¸ª
                """
                try:
                    with get_db() as db:
                        # è·å–ä¸åŒçš„inference_batch_id
                        batches = db.query(PredictionData.inference_batch_id).filter(
                            PredictionData.plan_id == plan_id
                        ).distinct().order_by(PredictionData.inference_batch_id.desc()).limit(limit).all()

                        batch_ids = [batch[0] for batch in batches if batch[0]]

                        # è·å–æ¯ä¸ªæ‰¹æ¬¡çš„è¯¦ç»†ä¿¡æ¯
                        batch_info = []
                        for batch_id in batch_ids:
                            first_pred = db.query(PredictionData).filter(
                                PredictionData.plan_id == plan_id,
                                PredictionData.inference_batch_id == batch_id
                            ).first()

                            if first_pred:
                                batch_info.append({
                                    "inference_batch_id": batch_id,
                                    "created_at": first_pred.created_at.strftime('%Y-%m-%d %H:%M:%S'),
                                    "prediction_count": db.query(PredictionData).filter(
                                        PredictionData.plan_id == plan_id,
                                        PredictionData.inference_batch_id == batch_id
                                    ).count()
                                })

                        return {
                            "success": True,
                            "total_batches": len(batch_info),
                            "data": batch_info
                        }
                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["get_prediction_history"] = get_prediction_history

        # 3. æŸ¥è¯¢å†å²Kçº¿æ•°æ®å·¥å…·
        if "query_historical_kline_data" in enabled_tools:
            @tool
            def query_historical_kline_data(
                inst_id: str,
                interval: str = "1H",
                start_time: str = None,
                end_time: str = None,
                limit: int = 100
            ) -> Dict[str, Any]:
                """æŸ¥è¯¢å†å²Kçº¿å®é™…äº¤æ˜“æ•°æ®,ä½¿ç”¨UTC+8æ—¶é—´æˆ³ä½œä¸ºæŸ¥è¯¢æ¡ä»¶

                Args:
                    inst_id: äº¤æ˜“å¯¹ï¼Œå¦‚ 'ETH-USDT'
                    interval: æ—¶é—´é—´éš”ï¼Œé»˜è®¤ '1H'
                    start_time: å¼€å§‹æ—¶é—´(UTC+8), æ ¼å¼: '2025-01-01 00:00:00'
                    end_time: ç»“æŸæ—¶é—´(UTC+8), æ ¼å¼: '2025-01-01 23:59:59'
                    limit: è¿”å›æ•°é‡ï¼Œé»˜è®¤100
                """
                try:
                    with get_db() as db:
                        from database.models import KlineData

                        query = db.query(KlineData).filter(
                            KlineData.inst_id == inst_id,
                            KlineData.interval == interval
                        )

                        # æ—¶é—´èŒƒå›´æŸ¥è¯¢
                        if start_time:
                            from datetime import datetime
                            start_dt = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')
                            query = query.filter(KlineData.timestamp >= start_dt)
                        if end_time:
                            from datetime import datetime
                            end_dt = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')
                            query = query.filter(KlineData.timestamp <= end_dt)

                        # é™åˆ¶æ•°é‡å¹¶æŒ‰æ—¶é—´å€’åº
                        klines = query.order_by(KlineData.timestamp.desc()).limit(limit).all()

                        return {
                            "success": True,
                            "count": len(klines),
                            "data": [
                                {
                                    "timestamp": kline.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                                    "open": kline.open,
                                    "high": kline.high,
                                    "low": kline.low,
                                    "close": kline.close,
                                    "volume": kline.volume,
                                    "amount": kline.amount
                                } for kline in klines
                            ]
                        }
                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["query_historical_kline_data"] = query_historical_kline_data

        # 4. è·å–å½“å‰UTC+8æ—¶é—´å·¥å…·
        if "get_current_utc_time" in enabled_tools:
            @tool
            def get_current_utc_time() -> Dict[str, Any]:
                """è¯»å–å½“å‰æ—¥æœŸä¸æ—¶é—´(UTC+8),ç”¨äºæ—¶é—´ç›¸å…³æ“ä½œ"""
                from datetime import datetime
                import pytz

                # è·å–åŒ—äº¬æ—¶åŒºå½“å‰æ—¶é—´
                beijing_tz = pytz.timezone('Asia/Shanghai')
                current_time = datetime.now(beijing_tz)

                return {
                    "success": True,
                    "data": {
                        "current_time": current_time.strftime('%Y-%m-%d %H:%M:%S'),
                        "timestamp": current_time.timestamp(),
                        "timezone": "UTC+8"
                    }
                }

            available_tools["get_current_utc_time"] = get_current_utc_time

        # 5. æ‰§è¡Œæ¨¡å‹æ¨ç†å·¥å…·
        if "run_latest_model_inference" in enabled_tools:
            @tool
            def run_latest_model_inference(plan_id: int) -> Dict[str, Any]:
                """æ‰§è¡Œæœ€æ–°å¾®è°ƒç‰ˆæœ¬æ¨¡å‹çš„é¢„æµ‹æ¨ç†"""
                try:
                    # å¯¼å…¥æ¨ç†æœåŠ¡
                    from services.inference_service import inference_service

                    # æ£€æŸ¥è‡ªåŠ¨æ¨ç†é…ç½®
                    if plan_info:
                        auto_inference_enabled = plan_info.auto_inference_enabled
                        auto_inference_interval = plan_info.auto_inference_interval_hours or 4

                        if not auto_inference_enabled:
                            return {
                                "success": False,
                                "error": "æ­¤è®¡åˆ’æœªå¯ç”¨è‡ªåŠ¨æ¨ç†ï¼Œè¯·åœ¨è®¡åˆ’é…ç½®ä¸­å¯ç”¨"
                            }

                        # æ£€æŸ¥è·ç¦»ä¸Šæ¬¡æ¨ç†çš„æ—¶é—´é—´éš”
                        if plan_info.last_finetune_time:
                            from datetime import datetime, timedelta
                            time_diff = datetime.now() - plan_info.last_finetune_time
                            hours_diff = time_diff.total_seconds() / 3600

                            if hours_diff < auto_inference_interval:
                                return {
                                    "success": False,
                                    "error": f"è·ç¦»ä¸Šæ¬¡æ¨ç†ä¸è¶³{auto_inference_interval}å°æ—¶ï¼Œè¯·ç¨åå†è¯•"
                                }

                    # æ‰§è¡Œæ¨ç†
                    result = inference_service.run_inference(plan_id)

                    return {
                        "success": True,
                        "message": "é¢„æµ‹æ¨ç†å·²å¯åŠ¨ï¼ˆæ­£åœ¨åå°æ‰§è¡Œï¼‰",
                        "inference_params": result.get("inference_params", {})
                    }

                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["run_latest_model_inference"] = run_latest_model_inference

        # 6. æŸ¥è¯¢è´¦æˆ·ä½™é¢å·¥å…·
        if "get_account_balance" in enabled_tools:
            @tool
            def get_account_balance(ccy: str = "USDT") -> Dict[str, Any]:
                """æŸ¥è¯¢è´¦æˆ·ä½™é¢,è¿”å›å¯ç”¨ä½™é¢ã€å†»ç»“ä½™é¢ç­‰ä¿¡æ¯

                Args:
                    ccy: å¸ç§ï¼Œé»˜è®¤æŸ¥è¯¢USDT
                """
                try:
                    if not plan_info or not all([plan_info.okx_api_key, plan_info.okx_secret_key, plan_info.okx_passphrase]):
                        return {"success": False, "error": "è®¡åˆ’æœªé…ç½®OKX APIå¯†é’¥"}

                    # åˆ›å»ºOKXäº¤æ˜“å·¥å…·å®ä¾‹
                    trading_tools = OKXTradingTools(
                        api_key=plan_info.okx_api_key,
                        secret_key=plan_info.okx_secret_key,
                        passphrase=plan_info.okx_passphrase,
                        is_demo=plan_info.is_demo
                    )

                    # è°ƒç”¨OKX API
                    result = trading_tools.get_account_balance(ccy=ccy)

                    return result

                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["get_account_balance"] = get_account_balance

        # 7. æŸ¥è¯¢æœªæˆäº¤è®¢å•å·¥å…·
        if "get_pending_orders" in enabled_tools:
            @tool
            def get_pending_orders(
                inst_id: str,
                state: str = "live",
                limit: int = 300
            ) -> Dict[str, Any]:
                """æŸ¥è¯¢å½“å‰æ‰€æœ‰OKXæœªæˆäº¤è®¢å•(æŒ‚å•)ä¿¡æ¯

                Args:
                    inst_id: äº¤æ˜“å¯¹IDï¼Œå¦‚ 'ETH-USDT'
                    state: è®¢å•çŠ¶æ€ï¼Œ'live': ç­‰å¾…æˆäº¤, 'partially_filled': éƒ¨åˆ†æˆäº¤
                    limit: è¿”å›æ•°é‡é™åˆ¶ï¼Œé»˜è®¤300
                """
                try:
                    if not plan_info or not all([plan_info.okx_api_key, plan_info.okx_secret_key, plan_info.okx_passphrase]):
                        return {"success": False, "error": "è®¡åˆ’æœªé…ç½®OKX APIå¯†é’¥"}

                    # åˆ›å»ºOKXäº¤æ˜“å·¥å…·å®ä¾‹
                    trading_tools = OKXTradingTools(
                        api_key=plan_info.okx_api_key,
                        secret_key=plan_info.okx_secret_key,
                        passphrase=plan_info.okx_passphrase,
                        is_demo=plan_info.is_demo
                    )

                    # è°ƒç”¨OKX API
                    result = trading_tools.get_pending_orders(
                        inst_id=inst_id,
                        state=state,
                        limit=limit
                    )

                    return result

                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["get_pending_orders"] = get_pending_orders

        # 8. ä¸‹é™ä»·å•å·¥å…·
        if "place_order" in enabled_tools:
            @tool
            def place_order(
                inst_id: str,
                side: str,
                sz: str,
                px: str,
                cl_ord_id: str = None
            ) -> Dict[str, Any]:
                """ä¸‹é™ä»·å•,ä»¥æŒ‡å®šä»·æ ¼ä¹°å…¥æˆ–å–å‡º

                Args:
                    inst_id: äº¤æ˜“å¯¹IDï¼Œå¦‚ 'ETH-USDT'
                    side: è®¢å•æ–¹å‘ï¼Œ'buy': ä¹°, 'sell': å–
                    sz: å§”æ‰˜æ•°é‡
                    px: å§”æ‰˜ä»·æ ¼
                    cl_ord_id: å®¢æˆ·ç«¯è®¢å•IDï¼Œå¦‚ä¸æä¾›å°†è‡ªåŠ¨ç”Ÿæˆ
                """
                try:
                    if not plan_info or not all([plan_info.okx_api_key, plan_info.okx_secret_key, plan_info.okx_passphrase]):
                        return {"success": False, "error": "è®¡åˆ’æœªé…ç½®OKX APIå¯†é’¥"}

                    # åˆ›å»ºOKXäº¤æ˜“å·¥å…·å®ä¾‹
                    trading_tools = OKXTradingTools(
                        api_key=plan_info.okx_api_key,
                        secret_key=plan_info.okx_secret_key,
                        passphrase=plan_info.okx_passphrase,
                        is_demo=plan_info.is_demo
                    )

                    # è°ƒç”¨OKX API
                    result = trading_tools.place_order(
                        inst_id=inst_id,
                        side=side,
                        td_mode="isolated",
                        ord_type="limit",
                        sz=sz,
                        px=px,
                        cl_ord_id=cl_ord_id,
                        tag="kokexAgent"
                    )

                    return result

                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["place_order"] = place_order

        # 9. æ’¤é”€è®¢å•å·¥å…·
        if "cancel_order" in enabled_tools:
            @tool
            def cancel_order(inst_id: str, cl_ord_id: str) -> Dict[str, Any]:
                """æ’¤é”€æœªæˆäº¤çš„è®¢å•,å†»ç»“èµ„é‡‘å°†ç«‹å³é‡Šæ”¾

                Args:
                    inst_id: äº¤æ˜“å¯¹IDï¼Œå¦‚ 'ETH-USDT'
                    cl_ord_id: å®¢æˆ·ç«¯è®¢å•ID
                """
                try:
                    if not plan_info or not all([plan_info.okx_api_key, plan_info.okx_secret_key, plan_info.okx_passphrase]):
                        return {"success": False, "error": "è®¡åˆ’æœªé…ç½®OKX APIå¯†é’¥"}

                    # åˆ›å»ºOKXäº¤æ˜“å·¥å…·å®ä¾‹
                    trading_tools = OKXTradingTools(
                        api_key=plan_info.okx_api_key,
                        secret_key=plan_info.okx_secret_key,
                        passphrase=plan_info.okx_passphrase,
                        is_demo=plan_info.is_demo
                    )

                    # è°ƒç”¨OKX API
                    result = trading_tools.cancel_order(
                        inst_id=inst_id,
                        cl_ord_id=cl_ord_id
                    )

                    return result

                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["cancel_order"] = cancel_order

        # 10. ä¿®æ”¹è®¢å•å·¥å…·
        if "amend_order" in enabled_tools:
            @tool
            def amend_order(
                inst_id: str,
                cl_ord_id: str,
                new_sz: str = None,
                new_px: str = None,
                req_id: str = None
            ) -> Dict[str, Any]:
                """ä¿®æ”¹æœªæˆäº¤è®¢å•çš„ä»·æ ¼æˆ–æ•°é‡

                Args:
                    inst_id: äº¤æ˜“å¯¹IDï¼Œå¦‚ 'ETH-USDT'
                    cl_ord_id: å®¢æˆ·ç«¯è®¢å•ID
                    new_sz: ä¿®æ”¹çš„æ–°æ•°é‡ï¼Œå¿…é¡»å¤§äº0
                    new_px: ä¿®æ”¹åçš„æ–°ä»·æ ¼
                    req_id: ç”¨æˆ·è‡ªå®šä¹‰ä¿®æ”¹äº‹ä»¶ID
                """
                try:
                    if not plan_info or not all([plan_info.okx_api_key, plan_info.okx_secret_key, plan_info.okx_passphrase]):
                        return {"success": False, "error": "è®¡åˆ’æœªé…ç½®OKX APIå¯†é’¥"}

                    # åˆ›å»ºOKXäº¤æ˜“å·¥å…·å®ä¾‹
                    trading_tools = OKXTradingTools(
                        api_key=plan_info.okx_api_key,
                        secret_key=plan_info.okx_secret_key,
                        passphrase=plan_info.okx_passphrase,
                        is_demo=plan_info.is_demo
                    )

                    # è°ƒç”¨OKX API
                    result = trading_tools.amend_order(
                        inst_id=inst_id,
                        cl_ord_id=cl_ord_id,
                        new_sz=new_sz,
                        new_px=new_px,
                        req_id=req_id
                    )

                    return result

                except Exception as e:
                    return {"success": False, "error": str(e)}

            available_tools["amend_order"] = amend_order

        return available_tools

    async def _save_message(self, conversation_id: int, role: str, content: str,
                           message_type: str = "text", tool_name: str = None,
                           tool_arguments: Dict = None, tool_result: Dict = None):
        """ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“"""
        try:
            with get_db() as db:
                message = AgentMessage(
                    conversation_id=conversation_id,
                    role=role,
                    content=content,
                    message_type=message_type,
                    tool_name=tool_name,
                    tool_arguments=tool_arguments,
                    tool_result=tool_result,
                    timestamp=now_beijing()
                )
                db.add(message)

                # æ›´æ–°ä¼šè¯ç»Ÿè®¡
                conversation = db.query(AgentConversation).filter(
                    AgentConversation.id == conversation_id
                ).first()
                if conversation:
                    conversation.total_messages += 1
                    if message_type in ["tool_call", "tool_result"]:
                        conversation.total_tool_calls += 1
                    conversation.last_message_at = now_beijing()

                db.commit()
        except Exception as e:
            logger.error(f"ä¿å­˜æ¶ˆæ¯å¤±è´¥: {e}")

    async def stream_agent_response_real(
        self,
        plan_id: int,
        user_message: str = None,
        conversation_type: str = "manual_chat"
    ):
        """çœŸæ­£çš„Agentå“åº”æµï¼Œæ”¯æŒæ–°çš„æ¶ˆæ¯æ ¼å¼ï¼ˆthinkæ¨¡å¼ã€toolè°ƒç”¨ã€playç»“æœï¼‰"""
        try:
            # è·å–è®¡åˆ’é…ç½®
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    yield [{"role": "assistant", "content": "âŒ æœªæ‰¾åˆ°æŒ‡å®šè®¡åˆ’"}]
                    return

                llm_config = db.query(LLMConfig).filter(LLMConfig.id == plan.llm_config_id).first()
                if not llm_config:
                    yield [{"role": "assistant", "content": "âŒ æœªæ‰¾åˆ°LLMé…ç½®"}]
                    return

            # åˆ›å»ºæˆ–è·å–å¯¹è¯
            with get_db() as db:
                conversation = db.query(AgentConversation).filter(
                    AgentConversation.plan_id == plan_id,
                    AgentConversation.status == 'active',
                    AgentConversation.conversation_type == conversation_type
                ).first()

                if not conversation:
                    conversation = AgentConversation(
                        plan_id=plan_id,
                        conversation_type=conversation_type,
                        status='active',
                        started_at=now_beijing(),
                        last_message_at=now_beijing()
                    )
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)

            # è·å–LLMå®¢æˆ·ç«¯å’Œå·¥å…·
            llm = self._get_llm_client(llm_config)
            tools_config = plan.agent_tools_config if isinstance(plan.agent_tools_config, dict) else json.loads(plan.agent_tools_config) if plan.agent_tools_config else {}
            tools = self._create_langchain_tools(tools_config, plan_id)

            # ç»‘å®šå·¥å…·åˆ°LLM
            tools_list = list(tools.values())
            if tools_list:
                llm_with_tools = llm.bind_tools(tools_list)
            else:
                llm_with_tools = llm

            # æ„å»ºå®Œæ•´æç¤ºè¯ï¼ˆåŠ¨æ€éƒ¨åˆ† + å·¥å…·éƒ¨åˆ† + äº¤æ˜“é™åˆ¶ï¼‰
            system_prompt = self._build_system_prompt(plan, tools_config, plan_id)

            # è¾“å‡ºç³»ç»Ÿæ¶ˆæ¯
            yield [{"role": "system", "content": system_prompt}]
            await self._save_message(conversation.id, MessageRole.SYSTEM.value, system_prompt, MessageType.TEXT.value)

            # è·å–ç”¨æˆ·è¾“å…¥æ¶ˆæ¯
            if conversation_type == "auto_inference":
                # è‡ªåŠ¨æ¨ç†æ¨¡å¼ï¼šè·å–æœ€æ–°é¢„æµ‹æ•°æ®
                prediction_data = self._get_prediction_data_for_context(plan_id)
                input_message = prediction_data
            else:
                # æ‰‹åŠ¨èŠå¤©æ¨¡å¼ï¼šä½¿ç”¨ç”¨æˆ·æ¶ˆæ¯
                input_message = user_message

            # è¾“å‡ºç”¨æˆ·æ¶ˆæ¯
            yield [{"role": "user", "content": input_message}]
            await self._save_message(conversation.id, MessageRole.USER.value, input_message, MessageType.TEXT.value)

            # æ„å»ºLangChainæ¶ˆæ¯åºåˆ—
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=input_message)
            ]

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨Qwen thinkæ¨¡å¼
            enable_thinking = False
            if llm_config.provider == "qwen":
                # æ£€æŸ¥ extra_params ä¸­æ˜¯å¦æœ‰ enable_thinking é…ç½®
                if hasattr(llm_config, 'extra_params') and llm_config.extra_params:
                    try:
                        extra_params = llm_config.extra_params if isinstance(llm_config.extra_params, dict) else json.loads(llm_config.extra_params)
                        enable_thinking = extra_params.get('enable_thinking', False)
                    except:
                        pass

            # æµå¼è°ƒç”¨LLM
            current_content = ""
            thinking_content = ""
            in_thinking_mode = False
            tool_calls_count = 0
            play_results = []

            async for chunk in llm_with_tools.astream(messages):
                # å¤„ç†æ€è€ƒæ¨¡å¼ï¼ˆQwenï¼‰
                if enable_thinking and hasattr(chunk, 'content'):
                    content = chunk.content or ""

                    # æ£€æµ‹æ€è€ƒæ ‡ç­¾
                    if "<think>" in content and not in_thinking_mode:
                        in_thinking_mode = True
                        thinking_content = content.split("<think>", 1)[1]
                        continue
                    elif "</think>" in content and in_thinking_mode:
                        # ç»“æŸæ€è€ƒæ¨¡å¼
                        remaining_thinking = thinking_content + content.split("</think>", 1)[0]
                        if remaining_thinking.strip():
                            # è¾“å‡ºå®Œæ•´æ€è€ƒå†…å®¹
                            yield [{"role": "assistant", "content": f"ğŸ’­ **æ€è€ƒè¿‡ç¨‹**:\n{remaining_thinking}"}]
                            await self._save_message(conversation.id, MessageRole.ASSISTANT.value,
                                                   remaining_thinking, MessageType.THINKING.value)
                        thinking_content = ""
                        in_thinking_mode = False
                        # å¤„ç†æ€è€ƒåçš„å†…å®¹
                        after_think = content.split("</think>", 1)[1]
                        if after_think.strip():
                            yield [{"role": "assistant", "content": after_think}]
                            await self._save_message(conversation.id, MessageRole.ASSISTANT.value, after_think)
                        continue
                    elif in_thinking_mode:
                        # åœ¨æ€è€ƒæ¨¡å¼ä¸­ï¼Œç´¯ç§¯å†…å®¹
                        thinking_content += content
                        continue

                # å¤„ç†å·¥å…·è°ƒç”¨
                if hasattr(chunk, 'tool_calls') and chunk.tool_calls:
                    for tool_call in chunk.tool_calls:
                        tool_calls_count += 1
                        tool_name = tool_call.get("name", "unknown")
                        tool_args = tool_call.get("args", {})

                        # è¾“å‡ºå·¥å…·è°ƒç”¨ï¼ˆç‹¬ç«‹æ¶ˆæ¯æ°”æ³¡ï¼‰
                        tool_call_data = {
                            "tool_name": tool_name,
                            "arguments": tool_args,
                            "status": "calling"
                        }
                        yield [{"role": "tool", "content": json.dumps(tool_call_data, ensure_ascii=False)}]
                        await self._save_message(conversation.id, MessageRole.TOOL.value,
                                               f"è°ƒç”¨å·¥å…· {tool_name}", MessageType.TOOL_CALL.value,
                                               tool_name, tool_args)

                        # æ‰§è¡Œå·¥å…·
                        try:
                            tool_func = next((t for t in tools_list if t.name == tool_name), None)
                            if tool_func:
                                result = tool_func.invoke(tool_args)

                                tool_result_data = {
                                    "tool_name": tool_name,
                                    "arguments": tool_args,
                                    "result": result,
                                    "status": "success" if not (isinstance(result, dict) and "error" in result) else "error"
                                }

                                # è¾“å‡ºå·¥å…·ç»“æœï¼ˆç‹¬ç«‹æ¶ˆæ¯æ°”æ³¡ï¼‰
                                yield [{"role": "tool", "content": json.dumps(tool_result_data, ensure_ascii=False)}]
                                await self._save_message(conversation.id, MessageRole.TOOL.value,
                                                       f"å·¥å…· {tool_name} æ‰§è¡Œå®Œæˆ", MessageType.TOOL_RESULT.value,
                                                       tool_name, tool_args, result)

                                # æ£€æŸ¥æ˜¯å¦æ˜¯æŠ•èµ„å†³ç­–ç»“æœ
                                if tool_name in ["place_order", "cancel_order", "amend_order"]:
                                    play_results.append({
                                        "action": tool_name,
                                        "parameters": tool_args,
                                        "result": result,
                                        "timestamp": now_beijing().isoformat()
                                    })

                                # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                                messages.append(ToolMessage(content=str(result), tool_call_id=tool_call.get("id", "")))

                        except Exception as tool_error:
                            error_data = {
                                "tool_name": tool_name,
                                "arguments": tool_args,
                                "error": str(tool_error),
                                "status": "error"
                            }
                            yield [{"role": "tool", "content": json.dumps(error_data, ensure_ascii=False)}]
                            await self._save_message(conversation.id, MessageRole.TOOL.value,
                                                   f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥", MessageType.TOOL_RESULT.value,
                                                   tool_name, tool_args, {"error": str(tool_error)})

                # å¤„ç†æ™®é€šæ–‡æœ¬å†…å®¹
                if hasattr(chunk, 'content') and chunk.content and not in_thinking_mode:
                    current_content += chunk.content
                    if chunk.content.strip():
                        yield [{"role": "assistant", "content": chunk.content}]
                        await self._save_message(conversation.id, MessageRole.ASSISTANT.value, chunk.content)

            # è¾“å‡ºæŠ•èµ„å†³ç­–ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if play_results:
                play_data = {
                    "investment_decisions": play_results,
                    "total_decisions": len(play_results),
                    "session_id": conversation.id,
                    "timestamp": now_beijing().isoformat()
                }
                yield [{"role": "play", "content": json.dumps(play_data, ensure_ascii=False)}]
                await self._save_message(conversation.id, MessageRole.PLAY.value,
                                       json.dumps(play_data, ensure_ascii=False), MessageType.PLAY_RESULT.value)

            # å®Œæˆå¯¹è¯
            completion_msg = f"âœ… å¯¹è¯å®Œæˆï¼Œå…±è°ƒç”¨ {tool_calls_count} ä¸ªå·¥å…·"
            yield [{"role": "assistant", "content": completion_msg}]
            await self._save_message(conversation.id, MessageRole.ASSISTANT.value, completion_msg)

            # æ›´æ–°å¯¹è¯çŠ¶æ€
            with get_db() as db:
                conversation = db.query(AgentConversation).filter(AgentConversation.id == conversation.id).first()
                if conversation:
                    conversation.status = 'completed'
                    conversation.completed_at = now_beijing()
                    db.commit()

        except Exception as e:
            logger.error(f"Agentæµå¼å“åº”å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield [{"role": "assistant", "content": f"âŒ Agentæ‰§è¡Œå¤±è´¥: {str(e)}"}]

    def _build_system_prompt(self, plan: TradingPlan, tools_config: Dict[str, bool], plan_id: int) -> str:
        """æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆåŠ¨æ€éƒ¨åˆ† + å·¥å…·éƒ¨åˆ† + äº¤æ˜“é™åˆ¶ï¼‰"""

        # 1. åŠ¨æ€éƒ¨åˆ†ï¼ˆæ¥è‡ª agent é…ç½®ï¼‰
        dynamic_prompt = plan.agent_prompt or "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“AIåŠ©æ‰‹ã€‚"

        # 2. å·¥å…·éƒ¨åˆ†ï¼ˆæ ¹æ®å¯ç”¨å·¥å…·åŠ¨æ€ç”Ÿæˆï¼‰
        enabled_tools = [name for name, enabled in tools_config.items() if enabled]
        tools_description = []

        if "query_prediction_data" in enabled_tools:
            tools_description.append("- **query_prediction_data**: æŸ¥è¯¢é¢„æµ‹æ•°æ®ï¼Œæ”¯æŒæ—¶é—´èŒƒå›´å’Œæ‰¹æ¬¡ç­›é€‰")
        if "get_prediction_history" in enabled_tools:
            tools_description.append("- **get_prediction_history**: æŸ¥è¯¢å†å²é¢„æµ‹æ‰¹æ¬¡ä¿¡æ¯")
        if "query_historical_kline_data" in enabled_tools:
            tools_description.append("- **query_historical_kline_data**: æŸ¥è¯¢å†å²Kçº¿å®é™…æ•°æ®")
        if "get_current_utc_time" in enabled_tools:
            tools_description.append("- **get_current_utc_time**: è·å–å½“å‰UTC+8æ—¶é—´")
        if "run_latest_model_inference" in enabled_tools:
            tools_description.append("- **run_latest_model_inference**: æ‰§è¡Œæœ€æ–°æ¨¡å‹æ¨ç†")
        if "get_account_balance" in enabled_tools:
            tools_description.append("- **get_account_balance**: æŸ¥è¯¢è´¦æˆ·ä½™é¢")
        if "get_pending_orders" in enabled_tools:
            tools_description.append("- **get_pending_orders**: æŸ¥è¯¢æœªæˆäº¤è®¢å•")
        if "place_order" in enabled_tools:
            tools_description.append("- **place_order**: ä¸‹é™ä»·å•ï¼ˆä¹°å…¥/å–å‡ºï¼‰")
        if "cancel_order" in enabled_tools:
            tools_description.append("- **cancel_order**: æ’¤é”€è®¢å•")
        if "amend_order" in enabled_tools:
            tools_description.append("- **amend_order**: ä¿®æ”¹è®¢å•ä»·æ ¼æˆ–æ•°é‡")

        tools_section = f"## å¯ç”¨å·¥å…·\n{chr(10).join(tools_description)}" if tools_description else "## å¯ç”¨å·¥å…·\nå½“å‰æœªå¯ç”¨ä»»ä½•å·¥å…·"

        # 3. äº¤æ˜“é™åˆ¶ï¼ˆä»è®¡åˆ’é…ç½®ä¸­è·å–ï¼‰
        trading_limits = []
        if hasattr(plan, 'trading_limits') and plan.trading_limits:
            try:
                limits = plan.trading_limits if isinstance(plan.trading_limits, dict) else json.loads(plan.trading_limits)
                if limits:
                    trading_limits.append("### äº¤æ˜“é™åˆ¶")
                    if 'max_position_size' in limits:
                        trading_limits.append(f"- æœ€å¤§æŒä»“è§„æ¨¡: {limits['max_position_size']}")
                    if 'max_order_value' in limits:
                        trading_limits.append(f"- æœ€å¤§è®¢å•ä»·å€¼: {limits['max_order_value']}")
                    if 'max_daily_trades' in limits:
                        trading_limits.append(f"- æ¯æ—¥æœ€å¤§äº¤æ˜“æ¬¡æ•°: {limits['max_daily_trades']}")
                    if 'risk_percentage' in limits:
                        trading_limits.append(f"- é£é™©æ§åˆ¶æ¯”ä¾‹: {limits['risk_percentage']}%")
            except:
                pass

        trading_limits_section = chr(10).join(trading_limits) if trading_limits else ""

        # æ„å»ºå®Œæ•´æç¤ºè¯
        full_prompt = f"""{dynamic_prompt}

## è®¡åˆ’ä¿¡æ¯
- å½“å‰è®¡åˆ’ID: {plan_id}
- äº¤æ˜“å¯¹: {plan.inst_id}
- æ—¶é—´é¢—ç²’åº¦: {plan.time_granularity}
- ç¯å¢ƒ: {'æ¨¡æ‹Ÿç›˜' if plan.is_demo else 'å®ç›˜'}

{tools_section}

{trading_limits_section}

## é‡è¦æç¤º
- æ‰€æœ‰æ—¶é—´éƒ½ä½¿ç”¨UTC+8æ—¶åŒºï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
- ä½¿ç”¨éœ€è¦plan_idå‚æ•°çš„å·¥å…·æ—¶ï¼Œè¯·ä½¿ç”¨: {plan_id}
- ä¸¥æ ¼éµå®ˆäº¤æ˜“é™åˆ¶å’Œé£é™©æ§åˆ¶è¦æ±‚
- æ¯æ¬¡å†³ç­–å‰è¯·å…ˆåˆ†æå½“å‰å¸‚åœºçŠ¶å†µ
- äº¤æ˜“å‰è¯·ç¡®è®¤è´¦æˆ·ä½™é¢å’Œé£é™©æ‰¿å—èƒ½åŠ›

## å†³ç­–æµç¨‹
1. åˆ†æå½“å‰å¸‚åœºçŠ¶å†µå’Œæœ€æ–°æ•°æ®
2. è·å–å¿…è¦çš„å†å²æ•°æ®å’Œé¢„æµ‹ä¿¡æ¯
3. è¯„ä¼°é£é™©å’Œäº¤æ˜“æœºä¼š
4. å¦‚éœ€äº¤æ˜“ï¼Œè°ƒç”¨ç›¸åº”çš„äº¤æ˜“å·¥å…·
5. è®°å½•å†³ç­–ç†ç”±å’Œç»“æœ

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯æä¾›ä¸“ä¸šçš„äº¤æ˜“åˆ†æå’Œå»ºè®®ã€‚"""

        return full_prompt

    def _get_prediction_data_for_context(self, plan_id: int, limit: int = 20) -> str:
        """è·å–é¢„æµ‹æ•°æ®ä½œä¸ºä¸Šä¸‹æ–‡"""
        try:
            with get_db() as db:
                predictions = db.query(PredictionData).filter(
                    PredictionData.plan_id == plan_id
                ).order_by(PredictionData.timestamp.desc()).limit(limit).all()

                if not predictions:
                    return "æš‚æ— é¢„æµ‹æ•°æ®"

                # æ ¼å¼åŒ–ä¸ºCSVå­—ç¬¦ä¸²
                csv_lines = ["timestamp,open,high,low,close,upward_probability,volatility_amplification_probability"]
                for pred in predictions:
                    csv_lines.append(
                        f"{pred.timestamp.strftime('%Y-%m-%d %H:%M:%S')},"
                        f"{pred.open},{pred.high},{pred.low},{pred.close},"
                        f"{pred.upward_probability or 0},{pred.volatility_amplification_probability or 0}"
                    )

                return "\\n".join(csv_lines)

        except Exception as e:
            logger.error(f"è·å–é¢„æµ‹æ•°æ®å¤±è´¥: {e}")
            return f"è·å–é¢„æµ‹æ•°æ®å¤±è´¥: {str(e)}"

    async def stream_conversation(self, plan_id: int, user_message: str):
        """æµå¼å¯¹è¯æ¥å£"""
        async for message_batch in self.stream_agent_response_real(
            plan_id=plan_id,
            user_message=user_message,
            conversation_type=ConversationType.MANUAL_CHAT.value
        ):
            yield message_batch

    async def stream_auto_inference(self, plan_id: int):
        """è‡ªåŠ¨æ¨ç†æµå¼æ¥å£"""
        async for message_batch in self.stream_agent_response_real(
            plan_id=plan_id,
            user_message=None,
            conversation_type=ConversationType.AUTO_INFERENCE.value
        ):
            yield message_batch


# å…¨å±€å®ä¾‹
langchain_agent_v2_service = LangChainAgentV2Service()
