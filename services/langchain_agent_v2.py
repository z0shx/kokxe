"""
ç»Ÿä¸€çš„LangChain AgentæœåŠ¡ v2 - ä½¿ç”¨ç°ä»£API
æ•´åˆäº†æ¨ç†ã€å¯¹è¯ã€æµå¼è¾“å‡ºåŠŸèƒ½ï¼Œé€‚é…Gradio Chatbotæ¥å£
"""
import json
import asyncio
from typing import Dict, List, AsyncGenerator, Optional, Any, Tuple
from datetime import datetime
from enum import Enum

from sqlalchemy import func

from database.models import (
    TradingPlan, PredictionData, AgentConversation,
    AgentMessage, LLMConfig, TrainingRecord
)
from database.db import get_db
from utils.logger import setup_logger
from services.trading_tools import OKXTradingTools

# Modern LangChain imports
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

logger = setup_logger(__name__, "langchain_agent_v2.log")


class ConversationType(Enum):
    """å¯¹è¯ç±»å‹æšä¸¾"""
    MANUAL_CHAT = "manual_chat"
    AUTO_INFERENCE = "auto_inference"


class LangChainAgentV2Service:
    """ç»Ÿä¸€çš„LangChain AgentæœåŠ¡ v2ï¼Œä½¿ç”¨ç°ä»£APIé€‚é…Gradio Chatbotæ¥å£"""

    def __init__(self):
        self._trading_tools = None
        self._llm_clients = {}

    @property
    def trading_tools(self):
        """æ‡’åŠ è½½trading tools"""
        if self._trading_tools is None:
            from config import Config
            self._trading_tools = OKXTradingTools(
                api_key=Config.OKX_API_KEY or "demo_key",
                secret_key="demo_secret",
                passphrase="demo_passphrase"
            )
        return self._trading_tools

    def _get_llm_client(self, llm_config: LLMConfig):
        """è·å–LLMå®¢æˆ·ç«¯"""
        client_key = f"{llm_config.provider}_{llm_config.model_name}"

        if client_key not in self._llm_clients:
            if llm_config.provider == "openai":
                self._llm_clients[client_key] = ChatOpenAI(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    openai_api_key=llm_config.api_key
                )
            elif llm_config.provider == "anthropic":
                self._llm_clients[client_key] = ChatAnthropic(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    anthropic_api_key=llm_config.api_key
                )
            elif llm_config.provider == "qwen":
                # ä½¿ç”¨OpenAIæ¥å£å…¼å®¹æ–¹å¼æ”¯æŒQwen
                base_url = llm_config.api_base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1"
                self._llm_clients[client_key] = ChatOpenAI(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    openai_api_key=llm_config.api_key,
                    openai_api_base=base_url
                )
            else:
                raise ValueError(f"Unsupported LLM provider: {llm_config.provider}")

        return self._llm_clients[client_key]

    def _create_langchain_tools(self, tools_config: Dict[str, bool]):
        """åˆ›å»ºLangChainå·¥å…·"""
        available_tools = {}

        # åªå¯ç”¨é…ç½®ä¸­å¯ç”¨çš„å·¥å…·
        enabled_tools = [name for name, enabled in tools_config.items() if enabled]

        if "get_current_price" in enabled_tools:
            @tool
            def get_current_price(inst_id: str) -> Dict[str, Any]:
                """è·å–å½“å‰å¸‚åœºä»·æ ¼"""
                return self.trading_tools.get_current_price(inst_id=inst_id)
            available_tools["get_current_price"] = get_current_price

        if "query_historical_kline_data" in enabled_tools:
            @tool
            def query_historical_kline_data(
                inst_id: str,
                interval: str = "1H",
                start_time: str = None,
                end_time: str = None,
                limit: int = 100
            ) -> Dict[str, Any]:
                """æŸ¥è¯¢å†å²Kçº¿æ•°æ®"""
                params = {"inst_id": inst_id, "interval": interval, "limit": limit}
                if start_time:
                    params["start_time"] = start_time
                if end_time:
                    params["end_time"] = end_time
                return self.trading_tools.query_historical_kline_data(**params)
            available_tools["query_historical_kline_data"] = query_historical_kline_data

        if "get_positions" in enabled_tools:
            @tool
            def get_positions(inst_id: str = None) -> Dict[str, Any]:
                """è·å–å½“å‰æŒä»“"""
                return self.trading_tools.get_positions(inst_id=inst_id)
            available_tools["get_positions"] = get_positions

        if "get_trading_limits" in enabled_tools:
            @tool
            def get_trading_limits(inst_id: str) -> Dict[str, Any]:
                """è·å–äº¤æ˜“é™åˆ¶"""
                return self.trading_tools.get_trading_limits(inst_id=inst_id)
            available_tools["get_trading_limits"] = get_trading_limits

        if "place_order" in enabled_tools:
            @tool
            def place_order(
                inst_id: str,
                side: str,
                order_type: str,
                size: float,
                price: Optional[float] = None
            ) -> Dict[str, Any]:
                """ä¸‹å•äº¤æ˜“"""
                return self.trading_tools.place_order(
                    inst_id=inst_id,
                    side=side,
                    order_type=order_type,
                    size=size,
                    price=price
                )
            available_tools["place_order"] = place_order

        if "cancel_order" in enabled_tools:
            @tool
            def cancel_order(inst_id: str, order_id: str) -> Dict[str, Any]:
                """å–æ¶ˆè®¢å•"""
                return self.trading_tools.cancel_order(inst_id=inst_id, order_id=order_id)
            available_tools["cancel_order"] = cancel_order

        if "get_account_balance" in enabled_tools:
            @tool
            def get_account_balance() -> Dict[str, Any]:
                """è·å–è´¦æˆ·ä½™é¢"""
                return self.trading_tools.get_account_balance()
            available_tools["get_account_balance"] = get_account_balance

        if "get_latest_predictions" in enabled_tools:
            @tool
            def get_latest_predictions(plan_id: int, limit: int = 10) -> Dict[str, Any]:
                """è·å–æœ€æ–°é¢„æµ‹æ•°æ®"""
                try:
                    with get_db() as db:
                        predictions = db.query(PredictionData).filter(
                            PredictionData.plan_id == plan_id
                        ).order_by(PredictionData.timestamp.desc()).limit(limit).all()

                        return {
                            "success": True,
                            "data": [
                                {
                                    "timestamp": pred.timestamp.isoformat(),
                                    "open": pred.open,
                                    "high": pred.high,
                                    "low": pred.low,
                                    "close": pred.close,
                                    "close_min": pred.close_min,
                                    "close_max": pred.close_max
                                }
                                for pred in predictions
                            ]
                        }
                except Exception as e:
                    return {"success": False, "error": str(e)}
            available_tools["get_latest_predictions"] = get_latest_predictions

        if "modify_order" in enabled_tools:
            @tool
            def modify_order(
                inst_id: str,
                order_id: str,
                new_size: Optional[float] = None,
                new_price: Optional[float] = None
            ) -> Dict[str, Any]:
                """ä¿®æ”¹è®¢å•"""
                return self.trading_tools.modify_order(
                    inst_id=inst_id,
                    order_id=order_id,
                    new_size=new_size,
                    new_price=new_price
                )
            available_tools["modify_order"] = modify_order

        if "get_pending_orders" in enabled_tools:
            @tool
            def get_pending_orders(inst_id: str = None) -> Dict[str, Any]:
                """è·å–æŒ‚å•"""
                return self.trading_tools.get_pending_orders(inst_id=inst_id)
            available_tools["get_pending_orders"] = get_pending_orders

        if "get_current_utc_time" in enabled_tools:
            @tool
            def get_current_utc_time() -> Dict[str, Any]:
                """è·å–å½“å‰UTCæ—¶é—´"""
                from datetime import datetime, timezone
                return {
                    "success": True,
                    "data": {
                        "utc_time": datetime.now(timezone.utc).isoformat(),
                        "timestamp": int(datetime.now(timezone.utc).timestamp())
                    }
                }
            available_tools["get_current_utc_time"] = get_current_utc_time

        if "place_stop_loss_order" in enabled_tools:
            @tool
            def place_stop_loss_order(
                inst_id: str,
                side: str,
                size: float,
                stop_price: float
            ) -> Dict[str, Any]:
                """è®¾ç½®æ­¢æŸè®¢å•"""
                return self.trading_tools.place_stop_loss_order(
                    inst_id=inst_id,
                    side=side,
                    size=size,
                    stop_price=stop_price
                )
            available_tools["place_stop_loss_order"] = place_stop_loss_order

        if "query_prediction_data" in enabled_tools:
            @tool
            def query_prediction_data(
                plan_id: int,
                batch_id: str = None,
                start_time: str = None,
                end_time: str = None,
                limit: int = 100
            ) -> Dict[str, Any]:
                """æŸ¥è¯¢é¢„æµ‹æ•°æ®"""
                try:
                    with get_db() as db:
                        query = db.query(PredictionData).filter(
                            PredictionData.plan_id == plan_id
                        )

                        if batch_id:
                            query = query.filter(PredictionData.batch_id == batch_id)
                        if start_time:
                            query = query.filter(PredictionData.timestamp >= start_time)
                        if end_time:
                            query = query.filter(PredictionData.timestamp <= end_time)

                        predictions = query.order_by(PredictionData.timestamp.desc()).limit(limit).all()

                        return {
                            "success": True,
                            "data": [
                                {
                                    "batch_id": pred.batch_id,
                                    "timestamp": pred.timestamp.isoformat(),
                                    "open": pred.open,
                                    "high": pred.high,
                                    "low": pred.low,
                                    "close": pred.close,
                                    "close_min": pred.close_min,
                                    "close_max": pred.close_max,
                                    "upward_probability": pred.upward_probability,
                                    "volatility_amplification_probability": pred.volatility_amplification_probability
                                }
                                for pred in predictions
                            ]
                        }
                except Exception as e:
                    return {"success": False, "error": str(e)}
            available_tools["query_prediction_data"] = query_prediction_data

        if "get_prediction_history" in enabled_tools:
            @tool
            def get_prediction_history(plan_id: int, days: int = 7) -> Dict[str, Any]:
                """è·å–é¢„æµ‹å†å²"""
                try:
                    from datetime import datetime, timedelta
                    start_date = datetime.now() - timedelta(days=days)

                    with get_db() as db:
                        # æŒ‰æ‰¹æ¬¡åˆ†ç»„
                        batches = db.query(
                            PredictionData.batch_id,
                            func.min(PredictionData.timestamp).label('start_time'),
                            func.max(PredictionData.timestamp).label('end_time'),
                            func.count(PredictionData.id).label('count')
                        ).filter(
                            PredictionData.plan_id == plan_id,
                            PredictionData.timestamp >= start_date
                        ).group_by(PredictionData.batch_id).order_by(
                            PredictionData.batch_id.desc()
                        ).all()

                        return {
                            "success": True,
                            "data": [
                                {
                                    "batch_id": batch.batch_id,
                                    "start_time": batch.start_time.isoformat(),
                                    "end_time": batch.end_time.isoformat(),
                                    "data_points": batch.count
                                }
                                for batch in batches
                            ]
                        }
                except Exception as e:
                    return {"success": False, "error": str(e)}
            available_tools["get_prediction_history"] = get_prediction_history

        if "run_latest_model_inference" in enabled_tools:
            @tool
            def run_latest_model_inference(plan_id: int) -> Dict[str, Any]:
                """è¿è¡Œæœ€æ–°æ¨¡å‹æ¨ç†"""
                try:
                    from services.schedule_service import ScheduleService
                    result = ScheduleService.trigger_inference(plan_id)
                    return result
                except Exception as e:
                    return {"success": False, "error": str(e)}
            available_tools["run_latest_model_inference"] = run_latest_model_inference

        if "delete_prediction_data_by_batch" in enabled_tools:
            @tool
            def delete_prediction_data_by_batch(batch_id: str) -> Dict[str, Any]:
                """æŒ‰æ‰¹æ¬¡åˆ é™¤é¢„æµ‹æ•°æ®"""
                try:
                    with get_db() as db:
                        deleted_count = db.query(PredictionData).filter(
                            PredictionData.batch_id == batch_id
                        ).delete()
                        db.commit()

                        return {
                            "success": True,
                            "data": {
                                "batch_id": batch_id,
                                "deleted_count": deleted_count
                            }
                        }
                except Exception as e:
                    db.rollback()
                    return {"success": False, "error": str(e)}
            available_tools["delete_prediction_data_by_batch"] = delete_prediction_data_by_batch

        return list(available_tools.values())

    def _build_system_prompt(self, plan: TradingPlan, training_record: TrainingRecord) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        # ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„ç³»ç»Ÿæç¤ºè¯
        if plan.agent_prompt and plan.agent_prompt.strip():
            system_prompt = plan.agent_prompt.strip()
        else:
            # å¦‚æœæ²¡æœ‰é…ç½®æç¤ºè¯ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“åˆ†æå¸ˆï¼ŒåŸºäºAIé¢„æµ‹æ¨¡å‹æä¾›äº¤æ˜“å»ºè®®ã€‚

ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„é¢„æµ‹æ•°æ®è¿›è¡Œå¸‚åœºåˆ†æï¼Œå¹¶åœ¨å¿…è¦æ—¶æ‰§è¡Œäº¤æ˜“æ“ä½œã€‚

**åˆ†æåŸåˆ™ï¼š**
1. ä»”ç»†åˆ†æé¢„æµ‹æ•°æ®çš„è¶‹åŠ¿å’Œç½®ä¿¡åº¦
2. è€ƒè™‘å¸‚åœºé£é™©å’Œèµ„é‡‘ç®¡ç†
3. æä¾›æ¸…æ™°çš„äº¤æ˜“å»ºè®®å’Œç†ç”±
4. ä½¿ç”¨å·¥å…·è·å–å®æ—¶å¸‚åœºæ•°æ®è¾…åŠ©å†³ç­–

**é£é™©ç®¡ç†ï¼š**
- ä¸¥æ ¼éµå®ˆäº¤æ˜“é™é¢
- ä¼˜å…ˆè€ƒè™‘èµ„é‡‘å®‰å…¨
- é¿å…è¿‡åº¦äº¤æ˜“

ç°åœ¨å¼€å§‹åˆ†æ..."""

        # æ·»åŠ äº¤æ˜“å¯¹ä¿¡æ¯
        if plan.inst_id:
            system_prompt += f"\n\n**äº¤æ˜“å¯¹**: {plan.inst_id}"
            system_prompt += f"\n**æ—¶é—´å‘¨æœŸ**: {plan.interval}"

        # æ·»åŠ è®­ç»ƒæ¨¡å‹ä¿¡æ¯
        if training_record:
            system_prompt += f"\n\n**ä½¿ç”¨æ¨¡å‹**: v{training_record.version} (ID: {training_record.id})"
            if training_record.train_end_time:
                system_prompt += f"\n**è®­ç»ƒå®Œæˆæ—¶é—´**: {training_record.train_end_time}"

        return system_prompt

    def _get_prediction_data_for_context(self, plan_id: int) -> str:
        """è·å–é¢„æµ‹æ•°æ®ç”¨äºä¸Šä¸‹æ–‡"""
        try:
            with get_db() as db:
                # è·å–æœ€æ–°çš„é¢„æµ‹æ•°æ®æ‰¹æ¬¡
                latest_batch = db.query(PredictionData.inference_batch_id).filter(
                    PredictionData.plan_id == plan_id
                ).group_by(PredictionData.inference_batch_id).order_by(
                    func.max(PredictionData.created_at).desc()
                ).limit(1).first()

                if not latest_batch:
                    return ""

                batch_id = latest_batch[0]
                predictions = db.query(PredictionData).filter(
                    PredictionData.plan_id == plan_id,
                    PredictionData.inference_batch_id == batch_id
                ).order_by(PredictionData.timestamp).limit(24).all()

                if not predictions:
                    return ""

                # æ ¼å¼åŒ–ä¸ºCSVæ ¼å¼
                csv_lines = ["timestamp,open,high,low,close,close_min,close_max"]
                for pred in predictions:
                    csv_lines.append(
                        f"{pred.timestamp.isoformat()},"
                        f"{pred.open},{pred.high},{pred.low},"
                        f"{pred.close},{pred.close_min or ''},{pred.close_max or ''}"
                    )

                return "\n".join(csv_lines)

        except Exception as e:
            logger.error(f"è·å–é¢„æµ‹æ•°æ®å¤±è´¥: {e}")
            return ""

    async def stream_agent_response(
        self,
        plan_id: int,
        user_message: str = None,
        conversation_type: ConversationType = ConversationType.MANUAL_CHAT,
        append_mode: bool = True
    ) -> AsyncGenerator[List[Dict[str, str]], None]:
        """
        æµå¼Agentå“åº”ï¼Œé€‚é…Gradio Chatbotæ¥å£
        ä½¿ç”¨ç°ä»£LangChain APIå®ç°

        Args:
            plan_id: è®¡åˆ’ID
            user_message: ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
            conversation_type: å¯¹è¯ç±»å‹
            append_mode: æ˜¯å¦è¿½åŠ æ¨¡å¼ï¼ˆTrue=è¿½åŠ æ¶ˆæ¯ï¼ŒFalse=æ›¿æ¢æœ€åä¸€æ¡ï¼‰
        """
        try:
            # è·å–è®¡åˆ’é…ç½®
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    yield [{"role": "assistant", "content": "âŒ è®¡åˆ’ä¸å­˜åœ¨"}]
                    return

                # æ£€æŸ¥LLMé…ç½®
                if not plan.llm_config_id:
                    yield [{"role": "assistant", "content": "âŒ æœªé…ç½®LLM"}]
                    return

                # è·å–æœ€æ–°è®­ç»ƒè®°å½•
                training_record = db.query(TrainingRecord).filter(
                    TrainingRecord.plan_id == plan_id,
                    TrainingRecord.status == 'completed',
                    TrainingRecord.is_active == True
                ).order_by(TrainingRecord.created_at.desc()).first()

                if not training_record:
                    yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒè®°å½•"}]
                    return

                llm_config = db.query(LLMConfig).filter(LLMConfig.id == plan.llm_config_id).first()
                if not llm_config:
                    yield [{"role": "assistant", "content": "âŒ LLMé…ç½®ä¸å­˜åœ¨"}]
                    return

            # åˆ›å»ºå¯¹è¯ä¼šè¯
            conversation = await self._create_conversation(
                plan_id=plan_id,
                conversation_type=conversation_type
            )

            # å‘é€ç³»ç»Ÿæç¤ºï¼ˆä½¿ç”¨assistantè§’è‰²ä»¥ä¾¿åœ¨Gradioä¸­æ˜¾ç¤ºï¼‰
            system_prompt = self._build_system_prompt(plan, training_record)
            yield [{"role": "assistant", "content": f"ğŸ“‹ **ç³»ç»Ÿæç¤º**:\n{system_prompt}"}]

            # æ„å»ºè¾“å…¥æ¶ˆæ¯
            if conversation_type == ConversationType.AUTO_INFERENCE:
                # è‡ªåŠ¨æ¨ç†ï¼šä½¿ç”¨é¢„æµ‹æ•°æ®ä½œä¸ºè¾“å…¥
                prediction_data = self._get_prediction_data_for_context(plan_id)
                if not prediction_data:
                    yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰æ‰¾åˆ°é¢„æµ‹æ•°æ®"}]
                    return

                input_message = f"æœ€æ–°ä¸€æ‰¹é¢„æµ‹æ•°æ®ï¼ˆCSVæ ¼å¼ï¼‰ï¼š\n{prediction_data}"

                # ä¿å­˜ç³»ç»Ÿæ¶ˆæ¯
                await self._save_message(conversation.id, "system",
                    f"å¼€å§‹è‡ªåŠ¨æ¨ç†åˆ†æï¼Œé¢„æµ‹æ•°æ®æ‰¹æ¬¡åŒ…å«æ—¶é—´åºåˆ—åˆ†æ")

                # å‘é€é¢„æµ‹æ•°æ®ä½œä¸ºç”¨æˆ·è¾“å…¥
                yield [{"role": "user", "content": f"ğŸ“ˆ **é¢„æµ‹æ•°æ®è¾“å…¥**:\n```csv\n{prediction_data}\n```"}]

            else:
                # æ‰‹åŠ¨å¯¹è¯ï¼šä½¿ç”¨ç”¨æˆ·æ¶ˆæ¯
                if not user_message:
                    yield [{"role": "assistant", "content": "âŒ è¯·è¾“å…¥æ¶ˆæ¯"}]
                    return

                input_message = user_message

                # å‘é€ç”¨æˆ·æ¶ˆæ¯åˆ°chatbot
                yield [{"role": "user", "content": input_message}]

            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆä½¿ç”¨åŸå§‹çš„input_messageï¼Œä¸åŒ…å«æ ¼å¼åŒ–ï¼‰
            await self._save_message(conversation.id, "user", input_message)

            # è·å–LLMå®¢æˆ·ç«¯å’Œå·¥å…·
            with get_db() as db:
                tools = self._create_langchain_tools(plan.agent_tools_config or {})

            # å‘é€æ€è€ƒå¼€å§‹æ¶ˆæ¯
            yield [{"role": "assistant", "content": "ğŸ¤” **å¼€å§‹æ€è€ƒ**: æ­£åœ¨åˆ†ææ‚¨çš„è¯·æ±‚..."}]

            # ä½¿ç”¨LLMç”Ÿæˆå“åº”
            llm = self._get_llm_client(llm_config)

            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=input_message)
            ]

            # æ£€æŸ¥æ˜¯å¦ä¸ºQwenä¾›åº”å•†
            is_qwen = llm_config.provider == "qwen"

            # å‘é€åˆ†æå¼€å§‹æ¶ˆæ¯
            analysis_start_msg = "ğŸ§  **AIåˆ†æ**: åŸºäºä»¥ä¸Šä¿¡æ¯å¼€å§‹ç”Ÿæˆäº¤æ˜“å»ºè®®..."
            yield [{"role": "assistant", "content": analysis_start_msg}]
            await self._save_message(conversation.id, "assistant", analysis_start_msg)

            # å¦‚æœæ˜¯Qwenä¾›åº”å•†ï¼Œå‘é€åˆ†æå¼€å§‹æ ‡è¯†
            if is_qwen:
                qwen_start_msg = "ğŸ¤– **Qwenåˆ†æç»“æœ**:"
                yield [{"role": "assistant", "content": qwen_start_msg}]
                await self._save_message(conversation.id, "assistant", qwen_start_msg)

            # ä½¿ç”¨è‡ªå®šä¹‰Agentæ‰§è¡Œï¼ˆé¿å…ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼‰
            try:
                # å…ˆå‘é€å¼€å§‹æ€è€ƒçš„æ¶ˆæ¯
                thinking_msg = "ğŸ¤” **Agentæ€è€ƒ**: æ­£åœ¨åˆ†æé¢„æµ‹æ•°æ®å¹¶å‡†å¤‡å·¥å…·è°ƒç”¨..."
                yield [{"role": "assistant", "content": thinking_msg}]
                await self._save_message(conversation.id, "assistant", thinking_msg)
                await asyncio.sleep(0.5)

                logger.info(f"åˆ›å»ºè‡ªå®šä¹‰Agentï¼Œä¾›åº”å•†: {llm_config.provider}, å·¥å…·æ•°é‡: {len(tools)}")

                # æ„å»ºåŒ…å«å·¥å…·ä¿¡æ¯çš„å¢å¼ºæç¤ºè¯
                tools_info = "\n".join([f"- {tool.name}: {tool.description}" for tool in tools])
                enhanced_prompt = f"""{system_prompt}

å¯ç”¨å·¥å…·:
{tools_info}

è¯·æ ¹æ®éœ€è¦è°ƒç”¨è¿™äº›å·¥å…·æ¥è·å–å®æ—¶æ•°æ®å¹¶æ‰§è¡Œäº¤æ˜“æ“ä½œã€‚ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è°ƒç”¨å·¥å…·:

Tool_Name: å‚æ•°1=value1, å‚æ•°2=value2

åˆ†ææ­¥éª¤:
1. åˆ†æé¢„æµ‹æ•°æ®çš„è¶‹åŠ¿å’Œæ¨¡å¼
2. è°ƒç”¨ç›¸å…³å·¥å…·è·å–å®æ—¶å¸‚åœºæ•°æ®
3. åŸºäºæ•°æ®åšå‡ºäº¤æ˜“å†³ç­–
4. æ‰§è¡Œç›¸åº”çš„äº¤æ˜“æ“ä½œ

å½“å‰è¾“å…¥: {input_message}

è¯·å¼€å§‹åˆ†æå¹¶è°ƒç”¨å¿…è¦çš„å·¥å…·:"""

                # ä¿å­˜å¢å¼ºæç¤ºè¯
                prompt_msg = f"ğŸ“‹ **å¢å¼ºç³»ç»Ÿæç¤º**: å·²åŠ è½½ {len(tools)} ä¸ªå¯ç”¨å·¥å…·"
                yield [{"role": "assistant", "content": prompt_msg}]
                await self._save_message(conversation.id, "assistant", prompt_msg)

                # ä½¿ç”¨LLMè¿›è¡ŒAgentå¼æ¨ç†
                messages = [SystemMessage(content=enhanced_prompt)]
                current_content = ""
                tool_call_count = 0
                chunk_count = 0

                logger.info("å¼€å§‹Agentå¼LLMæ¨ç†...")

                async for chunk in llm.astream(messages):
                    if chunk.content:
                        chunk_content = chunk.content
                        current_content += chunk_content
                        chunk_count += 1

                        logger.debug(f"Agent chunk {chunk_count}: {chunk_content[:100]}...")

                        # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
                        lines = chunk_content.split('\n')
                        for line in lines:
                            line = line.strip()
                            if ':' in line and any(tool.name in line for tool in tools):
                                # æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨
                                tool_call_count += 1

                                # è§£æå·¥å…·è°ƒç”¨
                                tool_name = None
                                tool_params = {}

                                for tool in tools:
                                    if tool.name in line:
                                        tool_name = tool.name
                                        if ':' in line:
                                            params_str = line.split(':', 1)[1].strip()
                                            # ç®€å•å‚æ•°è§£æ
                                            if '=' in params_str:
                                                for param in params_str.split(','):
                                                    if '=' in param:
                                                        key, value = param.split('=', 1)
                                                        tool_params[key.strip()] = value.strip()
                                        break

                                if tool_name:
                                    tool_call_msg = f"ğŸ› ï¸ **è°ƒç”¨å·¥å…·** ({tool_call_count}): `{tool_name}`\nğŸ“ **å‚æ•°**: `{tool_params}`"
                                    yield [{"role": "assistant", "content": tool_call_msg}]
                                    await self._save_message(conversation.id, "assistant", tool_call_msg)

                                    # æ‰§è¡Œå·¥å…·
                                    try:
                                        tool_func = next((t for t in tools if t.name == tool_name), None)
                                        if tool_func:
                                            # ç­‰å¾…å·¥å…·æ‰§è¡Œ
                                            await asyncio.sleep(0.5)

                                            # æ‰§è¡Œå·¥å…·ï¼ˆåŒæ­¥è°ƒç”¨ï¼‰
                                            result = tool_func.invoke(tool_params)

                                            # æ ¼å¼åŒ–ç»“æœ
                                            if isinstance(result, dict):
                                                result_str = f"```json\n{result}\n```"
                                            else:
                                                result_str = str(result)
                                                if len(result_str) > 300:
                                                    result_str = result_str[:300] + "..."

                                            tool_result_msg = f"âœ… **{tool_name} æ‰§è¡Œå®Œæˆ**:\n{result_str}"
                                            yield [{"role": "assistant", "content": tool_result_msg}]
                                            await self._save_message(conversation.id, "assistant", tool_result_msg)

                                            # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å½“å‰å†…å®¹ä¸­
                                            current_content += f"\n\nå·¥å…·è°ƒç”¨ç»“æœ: {result_str}"
                                        else:
                                            error_msg = f"âŒ å·¥å…· {tool_name} æœªæ‰¾åˆ°"
                                            yield [{"role": "assistant", "content": error_msg}]
                                            await self._save_message(conversation.id, "assistant", error_msg)
                                    except Exception as tool_error:
                                        error_msg = f"âŒ {tool_name} æ‰§è¡Œå¤±è´¥: {str(tool_error)}"
                                        yield [{"role": "assistant", "content": error_msg}]
                                        await self._save_message(conversation.id, "assistant", error_msg)

                        # æµå¼è¾“å‡ºå½“å‰å†…å®¹
                        if len(chunk_content.strip()) > 0:
                            yield [{"role": "assistant", "content": chunk_content}]

                        # æ§åˆ¶è¾“å‡ºé€Ÿåº¦
                        await asyncio.sleep(0.02)

                logger.info(f"Agentæ¨ç†å®Œæˆï¼Œå·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}, æ€»è¾“å‡ºé•¿åº¦: {len(current_content)}")

                # ä¿å­˜å®Œæˆæ¶ˆæ¯
                completion_msg = f"âœ… **Agentæ‰§è¡Œå®Œæˆ**: å…±è°ƒç”¨ {tool_call_count} æ¬¡å·¥å…·ï¼Œç”Ÿæˆå®Œæ•´äº¤æ˜“å†³ç­–ã€‚"
                yield [{"role": "assistant", "content": completion_msg}]
                await self._save_message(conversation.id, "assistant", completion_msg)

            except Exception as agent_error:
                logger.error(f"Agentæ‰§è¡Œé”™è¯¯: {agent_error}")
                import traceback
                traceback.print_exc()
                error_msg = f"âŒ Agentæ‰§è¡Œå¤±è´¥: {str(agent_error)}"
                yield [{"role": "assistant", "content": error_msg}]
                await self._save_message(conversation.id, "assistant", error_msg)

            # ä¿å­˜å®Œæ•´çš„æœ€ç»ˆå“åº”
            if current_content:
                final_content = current_content if not is_qwen else f"Qwenåˆ†æ: {current_content}"
                await self._save_message(conversation.id, "assistant", final_content)

        except Exception as e:
            logger.error(f"Agentæµå¼å“åº”å¤±è´¥: {e}")
            yield [{"role": "assistant", "content": f"âŒ å¤„ç†å¤±è´¥: {str(e)}"}]

    async def _create_conversation(self, plan_id: int, conversation_type: ConversationType):
        """åˆ›å»ºå¯¹è¯ä¼šè¯"""
        with get_db() as db:
            conversation = AgentConversation(
                plan_id=plan_id,
                conversation_type=conversation_type.value,
                status="active"
            )
            db.add(conversation)
            db.commit()
            db.refresh(conversation)
            return conversation

    async def _save_message(self, conversation_id: int, role: str, content: str):
        """ä¿å­˜æ¶ˆæ¯"""
        try:
            with get_db() as db:
                message = AgentMessage(
                    conversation_id=conversation_id,
                    role=role,
                    content=content
                )
                db.add(message)
                db.commit()
        except Exception as e:
            logger.error(f"ä¿å­˜æ¶ˆæ¯å¤±è´¥: {e}")

    async def get_conversation_history(self, plan_id: int) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²ï¼Œè¿”å›Chatbotæ ¼å¼"""
        try:
            with get_db() as db:
                # è·å–æœ€æ–°çš„å¯¹è¯
                latest_conversation = db.query(AgentConversation).filter(
                    AgentConversation.plan_id == plan_id
                ).order_by(AgentConversation.created_at.desc()).first()

                if not latest_conversation:
                    return []

                messages = db.query(AgentMessage).filter(
                    AgentMessage.conversation_id == latest_conversation.id
                ).order_by(AgentMessage.created_at).all()

                return [
                    {"role": msg.role, "content": msg.content}
                    for msg in messages
                ]

        except Exception as e:
            logger.error(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return []

    # å…¼å®¹æ€§æ–¹æ³• - ä¸ºäº†ä¿æŒå‘åå…¼å®¹
    async def stream_manual_inference(self, plan_id: int):
        """æ‰‹åŠ¨æ¨ç†æµå¼å“åº”ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        async for message_batch in self.stream_agent_response(
            plan_id=plan_id,
            user_message=None,
            conversation_type=ConversationType.AUTO_INFERENCE
        ):
            yield message_batch

    async def stream_conversation(self, plan_id: int, user_message: str):
        """æµå¼å¯¹è¯ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        async for message_batch in self.stream_agent_response(
            plan_id=plan_id,
            user_message=user_message,
            conversation_type=ConversationType.MANUAL_CHAT
        ):
            yield message_batch


# å…¨å±€å®ä¾‹
langchain_agent_v2_service = LangChainAgentV2Service()