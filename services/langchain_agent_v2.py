"""
ç»Ÿä¸€çš„LangChain AgentæœåŠ¡ v2 - ä½¿ç”¨ç°ä»£API
æ•´åˆäº†æ¨ç†ã€å¯¹è¯ã€æµå¼è¾“å‡ºåŠŸèƒ½ï¼Œé€‚é…Gradio Chatbotæ¥å£
"""
import json
import asyncio
from typing import Dict, List, AsyncGenerator, Optional, Any, Tuple
from datetime import datetime
from enum import Enum

from sqlalchemy import func

from database.models import (
    TradingPlan, PredictionData, AgentConversation,
    AgentMessage, LLMConfig, TrainingRecord
)
from database.db import get_db
from utils.logger import setup_logger
from services.trading_tools import OKXTradingTools

# Modern LangChain imports
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

logger = setup_logger(__name__, "langchain_agent_v2.log")


class ConversationType(Enum):
    """å¯¹è¯ç±»å‹æšä¸¾"""
    MANUAL_CHAT = "manual_chat"
    AUTO_INFERENCE = "auto_inference"


class LangChainAgentV2Service:
    """ç»Ÿä¸€çš„LangChain AgentæœåŠ¡ v2ï¼Œä½¿ç”¨ç°ä»£APIé€‚é…Gradio Chatbotæ¥å£"""

    def __init__(self):
        self._trading_tools = None
        self._llm_clients = {}

    @property
    def trading_tools(self):
        """æ‡’åŠ è½½trading tools"""
        if self._trading_tools is None:
            from config import Config
            self._trading_tools = OKXTradingTools(
                api_key=Config.OKX_API_KEY or "demo_key",
                secret_key="demo_secret",
                passphrase="demo_passphrase"
            )
        return self._trading_tools

    def _get_llm_client(self, llm_config: LLMConfig):
        """è·å–LLMå®¢æˆ·ç«¯"""
        client_key = f"{llm_config.provider}_{llm_config.model_name}"

        if client_key not in self._llm_clients:
            if llm_config.provider == "openai":
                self._llm_clients[client_key] = ChatOpenAI(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    openai_api_key=llm_config.api_key
                )
            elif llm_config.provider == "anthropic":
                self._llm_clients[client_key] = ChatAnthropic(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    anthropic_api_key=llm_config.api_key
                )
            elif llm_config.provider == "qwen":
                # ä½¿ç”¨OpenAIæ¥å£å…¼å®¹æ–¹å¼æ”¯æŒQwen
                base_url = llm_config.api_base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1"
                self._llm_clients[client_key] = ChatOpenAI(
                    model=llm_config.model_name,
                    temperature=llm_config.temperature or 0.7,
                    max_tokens=llm_config.max_tokens or 2000,
                    openai_api_key=llm_config.api_key,
                    openai_api_base=base_url
                )
            else:
                raise ValueError(f"Unsupported LLM provider: {llm_config.provider}")

        return self._llm_clients[client_key]

    def _create_langchain_tools(self, tools_config: Dict[str, bool]):
        """åˆ›å»ºLangChainå·¥å…·"""
        available_tools = {}

        # åªå¯ç”¨é…ç½®ä¸­å¯ç”¨çš„å·¥å…·
        enabled_tools = [name for name, enabled in tools_config.items() if enabled]

        if "get_current_price" in enabled_tools:
            @tool
            def get_current_price(inst_id: str) -> Dict[str, Any]:
                """è·å–å½“å‰å¸‚åœºä»·æ ¼"""
                return self.trading_tools.get_current_price(inst_id=inst_id)
            available_tools["get_current_price"] = get_current_price

        if "query_historical_kline_data" in enabled_tools:
            @tool
            def query_historical_kline_data(
                inst_id: str,
                interval: str = "1H",
                start_time: str = None,
                end_time: str = None,
                limit: int = 100
            ) -> Dict[str, Any]:
                """æŸ¥è¯¢å†å²Kçº¿æ•°æ®"""
                params = {"inst_id": inst_id, "interval": interval, "limit": limit}
                if start_time:
                    params["start_time"] = start_time
                if end_time:
                    params["end_time"] = end_time
                return self.trading_tools.query_historical_kline_data(**params)
            available_tools["query_historical_kline_data"] = query_historical_kline_data

        if "get_positions" in enabled_tools:
            @tool
            def get_positions(inst_id: str = None) -> Dict[str, Any]:
                """è·å–å½“å‰æŒä»“"""
                return self.trading_tools.get_positions(inst_id=inst_id)
            available_tools["get_positions"] = get_positions

        if "get_trading_limits" in enabled_tools:
            @tool
            def get_trading_limits(inst_id: str) -> Dict[str, Any]:
                """è·å–äº¤æ˜“é™åˆ¶"""
                return self.trading_tools.get_trading_limits(inst_id=inst_id)
            available_tools["get_trading_limits"] = get_trading_limits

        if "place_order" in enabled_tools:
            @tool
            def place_order(
                inst_id: str,
                side: str,
                order_type: str,
                size: float,
                price: Optional[float] = None
            ) -> Dict[str, Any]:
                """ä¸‹å•äº¤æ˜“"""
                return self.trading_tools.place_order(
                    inst_id=inst_id,
                    side=side,
                    order_type=order_type,
                    size=size,
                    price=price
                )
            available_tools["place_order"] = place_order

        if "cancel_order" in enabled_tools:
            @tool
            def cancel_order(inst_id: str, order_id: str) -> Dict[str, Any]:
                """å–æ¶ˆè®¢å•"""
                return self.trading_tools.cancel_order(inst_id=inst_id, order_id=order_id)
            available_tools["cancel_order"] = cancel_order

        if "get_account_balance" in enabled_tools:
            @tool
            def get_account_balance() -> Dict[str, Any]:
                """è·å–è´¦æˆ·ä½™é¢"""
                return self.trading_tools.get_account_balance()
            available_tools["get_account_balance"] = get_account_balance

        if "get_latest_predictions" in enabled_tools:
            @tool
            def get_latest_predictions(plan_id: int, limit: int = 10) -> Dict[str, Any]:
                """è·å–æœ€æ–°é¢„æµ‹æ•°æ®"""
                try:
                    with get_db() as db:
                        predictions = db.query(PredictionData).filter(
                            PredictionData.plan_id == plan_id
                        ).order_by(PredictionData.timestamp.desc()).limit(limit).all()

                        return {
                            "success": True,
                            "data": [
                                {
                                    "timestamp": pred.timestamp.isoformat(),
                                    "open": pred.open,
                                    "high": pred.high,
                                    "low": pred.low,
                                    "close": pred.close,
                                    "close_min": pred.close_min,
                                    "close_max": pred.close_max
                                }
                                for pred in predictions
                            ]
                        }
                except Exception as e:
                    return {"success": False, "error": str(e)}
            available_tools["get_latest_predictions"] = get_latest_predictions

        return list(available_tools.values())

    def _build_system_prompt(self, plan: TradingPlan, training_record: TrainingRecord) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        base_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“åˆ†æå¸ˆï¼ŒåŸºäºAIé¢„æµ‹æ¨¡å‹æä¾›äº¤æ˜“å»ºè®®ã€‚

ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„é¢„æµ‹æ•°æ®è¿›è¡Œå¸‚åœºåˆ†æï¼Œå¹¶åœ¨å¿…è¦æ—¶æ‰§è¡Œäº¤æ˜“æ“ä½œã€‚

**åˆ†æåŸåˆ™ï¼š**
1. ä»”ç»†åˆ†æé¢„æµ‹æ•°æ®çš„è¶‹åŠ¿å’Œç½®ä¿¡åº¦
2. è€ƒè™‘å¸‚åœºé£é™©å’Œèµ„é‡‘ç®¡ç†
3. æä¾›æ¸…æ™°çš„äº¤æ˜“å»ºè®®å’Œç†ç”±
4. ä½¿ç”¨å·¥å…·è·å–å®æ—¶å¸‚åœºæ•°æ®è¾…åŠ©å†³ç­–

**é£é™©ç®¡ç†ï¼š**
- ä¸¥æ ¼éµå®ˆäº¤æ˜“é™é¢
- ä¼˜å…ˆè€ƒè™‘èµ„é‡‘å®‰å…¨
- é¿å…è¿‡åº¦äº¤æ˜“

ç°åœ¨å¼€å§‹åˆ†æ..."""

        # æ·»åŠ äº¤æ˜“å¯¹ä¿¡æ¯
        if plan.inst_id:
            base_prompt += f"\n\n**äº¤æ˜“å¯¹**: {plan.inst_id}"
            base_prompt += f"\n**æ—¶é—´å‘¨æœŸ**: {plan.interval}"

        # æ·»åŠ è®­ç»ƒæ¨¡å‹ä¿¡æ¯
        if training_record:
            base_prompt += f"\n\n**ä½¿ç”¨æ¨¡å‹**: v{training_record.version} (ID: {training_record.id})"
            if training_record.train_end_time:
                base_prompt += f"\n**è®­ç»ƒå®Œæˆæ—¶é—´**: {training_record.train_end_time}"

        return base_prompt

    def _get_prediction_data_for_context(self, plan_id: int) -> str:
        """è·å–é¢„æµ‹æ•°æ®ç”¨äºä¸Šä¸‹æ–‡"""
        try:
            with get_db() as db:
                # è·å–æœ€æ–°çš„é¢„æµ‹æ•°æ®æ‰¹æ¬¡
                latest_batch = db.query(PredictionData.inference_batch_id).filter(
                    PredictionData.plan_id == plan_id
                ).group_by(PredictionData.inference_batch_id).order_by(
                    func.max(PredictionData.created_at).desc()
                ).limit(1).first()

                if not latest_batch:
                    return ""

                batch_id = latest_batch[0]
                predictions = db.query(PredictionData).filter(
                    PredictionData.plan_id == plan_id,
                    PredictionData.inference_batch_id == batch_id
                ).order_by(PredictionData.timestamp).limit(24).all()

                if not predictions:
                    return ""

                # æ ¼å¼åŒ–ä¸ºCSVæ ¼å¼
                csv_lines = ["timestamp,open,high,low,close,close_min,close_max"]
                for pred in predictions:
                    csv_lines.append(
                        f"{pred.timestamp.isoformat()},"
                        f"{pred.open},{pred.high},{pred.low},"
                        f"{pred.close},{pred.close_min or ''},{pred.close_max or ''}"
                    )

                return "\n".join(csv_lines)

        except Exception as e:
            logger.error(f"è·å–é¢„æµ‹æ•°æ®å¤±è´¥: {e}")
            return ""

    async def stream_agent_response(
        self,
        plan_id: int,
        user_message: str = None,
        conversation_type: ConversationType = ConversationType.MANUAL_CHAT
    ) -> AsyncGenerator[List[Dict[str, str]], None]:
        """
        æµå¼Agentå“åº”ï¼Œé€‚é…Gradio Chatbotæ¥å£
        ä½¿ç”¨ç°ä»£LangChain APIå®ç°
        """
        try:
            # è·å–è®¡åˆ’é…ç½®
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    yield [{"role": "assistant", "content": "âŒ è®¡åˆ’ä¸å­˜åœ¨"}]
                    return

                # æ£€æŸ¥LLMé…ç½®
                if not plan.llm_config_id:
                    yield [{"role": "assistant", "content": "âŒ æœªé…ç½®LLM"}]
                    return

                # è·å–æœ€æ–°è®­ç»ƒè®°å½•
                training_record = db.query(TrainingRecord).filter(
                    TrainingRecord.plan_id == plan_id,
                    TrainingRecord.status == 'completed',
                    TrainingRecord.is_active == True
                ).order_by(TrainingRecord.created_at.desc()).first()

                if not training_record:
                    yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒè®°å½•"}]
                    return

            # åˆ›å»ºå¯¹è¯ä¼šè¯
            conversation = await self._create_conversation(
                plan_id=plan_id,
                conversation_type=conversation_type
            )

            # æ„å»ºè¾“å…¥æ¶ˆæ¯
            if conversation_type == ConversationType.AUTO_INFERENCE:
                # è‡ªåŠ¨æ¨ç†ï¼šä½¿ç”¨é¢„æµ‹æ•°æ®ä½œä¸ºè¾“å…¥
                prediction_data = self._get_prediction_data_for_context(plan_id)
                if not prediction_data:
                    yield [{"role": "assistant", "content": "âŒ æ²¡æœ‰æ‰¾åˆ°é¢„æµ‹æ•°æ®"}]
                    return

                input_message = f"""è¯·åˆ†æä»¥ä¸‹é¢„æµ‹æ•°æ®å¹¶ç»™å‡ºäº¤æ˜“å»ºè®®ï¼š

é¢„æµ‹æ•°æ®ï¼ˆCSVæ ¼å¼ï¼‰ï¼š
{prediction_data}

è¯·åŸºäºè¿™äº›æ•°æ®è¿›è¡Œå¸‚åœºåˆ†æï¼Œå¹¶ç»™å‡ºå…·ä½“çš„äº¤æ˜“å»ºè®®ã€‚"""

                await self._save_message(conversation.id, "system",
                    f"å¼€å§‹è‡ªåŠ¨æ¨ç†åˆ†æï¼Œé¢„æµ‹æ•°æ®æ‰¹æ¬¡åŒ…å«æ—¶é—´åºåˆ—åˆ†æ")

            else:
                # æ‰‹åŠ¨å¯¹è¯ï¼šä½¿ç”¨ç”¨æˆ·æ¶ˆæ¯
                if not user_message:
                    yield [{"role": "assistant", "content": "âŒ è¯·è¾“å…¥æ¶ˆæ¯"}]
                    return

                input_message = user_message

            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            await self._save_message(conversation.id, "user", input_message)

            # è·å–LLMå®¢æˆ·ç«¯å’Œå·¥å…·
            llm_config = db.query(LLMConfig).filter(LLMConfig.id == plan.llm_config_id).first()
            if not llm_config:
                yield [{"role": "assistant", "content": "âŒ LLMé…ç½®ä¸å­˜åœ¨"}]
                return

            with get_db() as db:
                tools = self._create_langchain_tools(plan.agent_tools_config or {})

            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt(plan, training_record)

            # ç®€åŒ–çš„æµå¼å“åº”å®ç°
            yield [{"role": "assistant", "content": "ğŸ¤” **å¼€å§‹æ€è€ƒ**: æ­£åœ¨åˆ†ææ‚¨çš„è¯·æ±‚..."}]

            # ä½¿ç”¨ç®€å•çš„LLMè°ƒç”¨å®ç°æµå¼è¾“å‡º
            llm = self._get_llm_client(llm_config)

            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=input_message)
            ]

            # æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨è¿‡ç¨‹
            if tools:
                yield [{"role": "assistant", "content": "ğŸ› ï¸ **å‡†å¤‡è°ƒç”¨å·¥å…·**: æ£€æŸ¥å¯ç”¨å·¥å…·..."}]

                for tool_func in tools[:3]:  # é™åˆ¶å·¥å…·è°ƒç”¨æ•°é‡
                    tool_name = tool_func.name
                    yield [{"role": "assistant", "content": f"ğŸ”§ **å·¥å…·è°ƒç”¨**: `{tool_name}`"}]
                    await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œæ—¶é—´

            # ç”Ÿæˆæœ€ç»ˆå“åº”
            async for chunk in llm.astream(messages):
                if chunk.content:
                    content = chunk.content
                    await self._save_message(conversation.id, "assistant", content)
                    yield [{"role": "assistant", "content": content}]
                    await asyncio.sleep(0.1)  # æ§åˆ¶æµå¼é€Ÿåº¦

        except Exception as e:
            logger.error(f"Agentæµå¼å“åº”å¤±è´¥: {e}")
            yield [{"role": "assistant", "content": f"âŒ å¤„ç†å¤±è´¥: {str(e)}"}]

    async def _create_conversation(self, plan_id: int, conversation_type: ConversationType):
        """åˆ›å»ºå¯¹è¯ä¼šè¯"""
        with get_db() as db:
            conversation = AgentConversation(
                plan_id=plan_id,
                conversation_type=conversation_type.value,
                status="active"
            )
            db.add(conversation)
            db.commit()
            db.refresh(conversation)
            return conversation

    async def _save_message(self, conversation_id: int, role: str, content: str):
        """ä¿å­˜æ¶ˆæ¯"""
        try:
            with get_db() as db:
                message = AgentMessage(
                    conversation_id=conversation_id,
                    role=role,
                    content=content
                )
                db.add(message)
                db.commit()
        except Exception as e:
            logger.error(f"ä¿å­˜æ¶ˆæ¯å¤±è´¥: {e}")

    async def get_conversation_history(self, plan_id: int) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²ï¼Œè¿”å›Chatbotæ ¼å¼"""
        try:
            with get_db() as db:
                # è·å–æœ€æ–°çš„å¯¹è¯
                latest_conversation = db.query(AgentConversation).filter(
                    AgentConversation.plan_id == plan_id
                ).order_by(AgentConversation.created_at.desc()).first()

                if not latest_conversation:
                    return []

                messages = db.query(AgentMessage).filter(
                    AgentMessage.conversation_id == latest_conversation.id
                ).order_by(AgentMessage.created_at).all()

                return [
                    {"role": msg.role, "content": msg.content}
                    for msg in messages
                ]

        except Exception as e:
            logger.error(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return []

    # å…¼å®¹æ€§æ–¹æ³• - ä¸ºäº†ä¿æŒå‘åå…¼å®¹
    async def stream_manual_inference(self, plan_id: int):
        """æ‰‹åŠ¨æ¨ç†æµå¼å“åº”ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        async for message_batch in self.stream_agent_response(
            plan_id=plan_id,
            user_message=None,
            conversation_type=ConversationType.AUTO_INFERENCE
        ):
            yield message_batch


# å…¨å±€å®ä¾‹
langchain_agent_v2_service = LangChainAgentV2Service()