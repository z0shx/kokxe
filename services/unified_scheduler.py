"""
ç»Ÿä¸€è°ƒåº¦æœåŠ¡
æ•´åˆåŸæœ‰ SchedulerService å’Œ ScheduleService çš„åŠŸèƒ½ï¼Œæ¶ˆé™¤é‡å¤å®ç°

ä¸»è¦åŠŸèƒ½ï¼š
1. è‡ªåŠ¨å¾®è°ƒä»»åŠ¡è°ƒåº¦ (æ•´åˆä¸¤ä¸ªæœåŠ¡çš„å®ç°)
2. è‡ªåŠ¨æ¨ç†ä»»åŠ¡è°ƒåº¦ (æ•´åˆä¸¤ä¸ªæœåŠ¡çš„å®ç°)
3. è‡ªåŠ¨Agentä»»åŠ¡è°ƒåº¦ (ä» SchedulerService ç»§æ‰¿)
4. æ¯æ—¥æ¨¡å‹æ¸…ç†ä»»åŠ¡ (æ•´åˆä¸¤ä¸ªæœåŠ¡çš„å®ç°)
5. ç»Ÿä¸€çš„ä»»åŠ¡æ‰§è¡Œè®°å½•å’ŒçŠ¶æ€ç®¡ç†
"""

import asyncio
import logging
import json
from datetime import datetime, timedelta, time, timezone
from typing import Dict, List, Optional
from sqlalchemy import and_, desc, asc
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.jobstores.memory import MemoryJobStore

from database.db import get_db
from database.models import TradingPlan, TaskExecution, TrainingRecord, now_beijing
from services.training_service import TrainingService
from services.inference_service import InferenceService
from services.task_execution_service import TaskExecutionService
from utils.timezone_helper import format_datetime_full_beijing

logger = logging.getLogger(__name__)


class UnifiedScheduler:
    """ç»Ÿä¸€è°ƒåº¦æœåŠ¡"""

    # å®šä¹‰UTC+8æ—¶åŒº
    BEIJING_TZ = timezone(timedelta(hours=8))

    def __init__(self):
        self.running = False
        self.scheduler = None
        self.scheduler_task = None
        self._init_scheduler()

    def _init_scheduler(self):
        """åˆå§‹åŒ– APScheduler è°ƒåº¦å™¨"""
        if self.scheduler is None:
            jobstores = {
                'default': MemoryJobStore()
            }

            self.scheduler = BackgroundScheduler(
                jobstores=jobstores,
                timezone='Asia/Shanghai'
            )

            logger.info("ç»Ÿä¸€è°ƒåº¦å™¨å·²åˆå§‹åŒ–ï¼Œæ—¶åŒº: Asia/Shanghai")

            # æ·»åŠ æ¯æ—¥æ¨¡å‹æ¸…ç†ä»»åŠ¡ (åŒ—äº¬æ—¶é—´å‡Œæ™¨2ç‚¹æ‰§è¡Œ)
            try:
                cleanup_trigger = CronTrigger(hour=2, minute=0, timezone='Asia/Shanghai')
                self.scheduler.add_job(
                    func=self._daily_model_cleanup_wrapper,
                    trigger=cleanup_trigger,
                    id='daily_model_cleanup',
                    name='Daily Model Cleanup',
                    replace_existing=True,
                    misfire_grace_time=3600  # å…è®¸1å°æ—¶å»¶è¿Ÿ
                )
                logger.info("âœ… å·²æ·»åŠ æ¯æ—¥æ¨¡å‹æ¸…ç†ä»»åŠ¡ (02:00 Beijing)")
            except Exception as e:
                logger.error(f"âŒ æ·»åŠ æ¯æ—¥æ¨¡å‹æ¸…ç†ä»»åŠ¡å¤±è´¥: {e}")

    async def start_scheduler(self):
        """å¯åŠ¨ç»Ÿä¸€è°ƒåº¦å™¨"""
        if self.running:
            logger.warning("ç»Ÿä¸€è°ƒåº¦å™¨å·²ç»åœ¨è¿è¡Œä¸­")
            return

        try:
            # å¯åŠ¨ APScheduler
            if not self.scheduler.running:
                self.scheduler.start()
                logger.info("APScheduler å·²å¯åŠ¨")

            # å¯åŠ¨å¼‚æ­¥è°ƒåº¦å¾ªç¯ï¼ˆç”¨äºé«˜é¢‘æ£€æŸ¥ä»»åŠ¡ï¼‰
            self.running = True
            self.scheduler_task = asyncio.create_task(self._scheduler_loop())
            logger.info("ç»Ÿä¸€è°ƒåº¦å™¨å·²å¯åŠ¨")

            # è¾“å‡ºè°ƒåº¦å™¨çŠ¶æ€
            self._log_scheduler_status()

        except Exception as e:
            logger.error(f"å¯åŠ¨ç»Ÿä¸€è°ƒåº¦å™¨å¤±è´¥: {e}")
            self.running = False

    async def stop_scheduler(self):
        """åœæ­¢ç»Ÿä¸€è°ƒåº¦å™¨"""
        if not self.running:
            return

        self.running = False
        if self.scheduler_task:
            self.scheduler_task.cancel()
            try:
                await self.scheduler_task
            except asyncio.CancelledError:
                pass

        if self.scheduler and self.scheduler.running:
            self.scheduler.shutdown()
            logger.info("APScheduler å·²åœæ­¢")

        logger.info("ç»Ÿä¸€è°ƒåº¦å™¨å·²åœæ­¢")

    async def _scheduler_loop(self):
        """è°ƒåº¦å™¨ä¸»å¾ªç¯ - å¤„ç†é«˜é¢‘æ£€æŸ¥ä»»åŠ¡"""
        while self.running:
            try:
                # æ£€æŸ¥è®¡åˆ’çŠ¶æ€å˜åŒ–å’Œéœ€è¦ç«‹å³å“åº”çš„ä»»åŠ¡
                await self._check_immediate_tasks()

                # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                await asyncio.sleep(30)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"è°ƒåº¦å™¨å¾ªç¯å‡ºé”™: {e}")
                await asyncio.sleep(30)

    async def _check_immediate_tasks(self):
        """æ£€æŸ¥éœ€è¦ç«‹å³å“åº”çš„ä»»åŠ¡"""
        try:
            with get_db() as db:
                now = now_beijing()

                # è·å–æ‰€æœ‰å¯ç”¨è‡ªåŠ¨åŒ–çš„è¿è¡Œä¸­è®¡åˆ’
                plans = db.query(TradingPlan).filter(
                    TradingPlan.status == 'running'
                ).all()

                for plan in plans:
                    try:
                        # æ£€æŸ¥è‡ªåŠ¨Agentä»»åŠ¡ï¼ˆéœ€è¦å¿«é€Ÿå“åº”ï¼‰
                        if plan.auto_agent_enabled:
                            await self._check_immediate_agent_tasks(plan, now, db)

                    except Exception as e:
                        logger.error(f"å¤„ç†è®¡åˆ’ {plan.id} çš„ç«‹å³ä»»åŠ¡æ—¶å‡ºé”™: {e}")

        except Exception as e:
            logger.error(f"æ£€æŸ¥ç«‹å³ä»»åŠ¡æ—¶å‡ºé”™: {e}")

    async def _check_immediate_agent_tasks(self, plan: TradingPlan, now: datetime, db):
        """æ£€æŸ¥éœ€è¦ç«‹å³æ‰§è¡Œçš„Agentä»»åŠ¡"""
        try:
            # æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æ–°çš„æ¨ç†ç»“æœéœ€è¦Agentå¤„ç†
            # è¿™é‡Œå¯ä»¥å®ç°æ›´æ™ºèƒ½çš„è§¦å‘é€»è¾‘ï¼Œç›®å‰ä¿æŒç®€å•
            if now.minute % 30 == 0:  # æ¯30åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                latest_training = db.query(TrainingRecord).filter(
                    and_(
                        TrainingRecord.plan_id == plan.id,
                        TrainingRecord.status == 'completed',
                        TrainingRecord.is_active == True
                    )
                ).order_by(desc(TrainingRecord.created_at)).first()

                if latest_training:
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰Agentä»»åŠ¡åœ¨æœ€è¿‘æ‰§è¡Œè¿‡
                    recent_time = now - timedelta(minutes=25)  # 25åˆ†é’Ÿå†…ä¸ç®—é‡å¤
                    existing_task = db.query(TaskExecution).filter(
                        and_(
                            TaskExecution.plan_id == plan.id,
                            TaskExecution.task_type == 'auto_agent',
                            TaskExecution.created_at >= recent_time,
                            TaskExecution.status.in_(['pending', 'running', 'completed'])
                        )
                    ).first()

                    if not existing_task:
                        await self._create_agent_task(plan, latest_training, now, db)

        except Exception as e:
            logger.error(f"æ£€æŸ¥ç«‹å³Agentä»»åŠ¡æ—¶å‡ºé”™: {e}")

    async def start_plan_schedule(self, plan_id: int) -> bool:
        """
        å¯åŠ¨è®¡åˆ’çš„æ‰€æœ‰å®šæ—¶ä»»åŠ¡

        Args:
            plan_id: è®¡åˆ’ID

        Returns:
            æ˜¯å¦æˆåŠŸå¯åŠ¨
        """
        try:
            current_time_beijing = datetime.now(self.BEIJING_TZ)
            logger.info(f"å¼€å§‹å¯åŠ¨è®¡åˆ’å®šæ—¶ä»»åŠ¡: plan_id={plan_id}, current_time(UTC+8)={current_time_beijing.strftime('%Y-%m-%d %H:%M:%S')}")

            # è·å–è®¡åˆ’ä¿¡æ¯
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    logger.error(f"è®¡åˆ’ä¸å­˜åœ¨: plan_id={plan_id}")
                    return False

                logger.info(f"è®¡åˆ’ä¿¡æ¯: plan_id={plan_id}, status={plan.status}, auto_finetune_enabled={plan.auto_finetune_enabled}, auto_inference_enabled={plan.auto_inference_enabled}")

                # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä»»ä½•è‡ªåŠ¨åŒ–åŠŸèƒ½
                if not (plan.auto_finetune_enabled or plan.auto_inference_enabled or plan.auto_agent_enabled):
                    logger.warning(f"è®¡åˆ’æœªå¯ç”¨ä»»ä½•è‡ªåŠ¨åŒ–åŠŸèƒ½: plan_id={plan_id}")
                    return False

            task_count = 0

            # å¤„ç†è‡ªåŠ¨å¾®è°ƒä»»åŠ¡ (ä½¿ç”¨ ScheduleService çš„å®ç°ï¼Œæ›´ç²¾ç¡®)
            if plan.auto_finetune_enabled:
                schedule_times = plan.auto_finetune_schedule or []
                if schedule_times:
                    logger.info(f"å¯åŠ¨è‡ªåŠ¨å¾®è°ƒä»»åŠ¡: plan_id={plan_id}, schedule_times={schedule_times}")

                    for time_str in schedule_times:
                        try:
                            # è§£ææ—¶é—´ (HH:MM)
                            hour, minute = map(int, time_str.split(':'))
                            logger.info(f"è§£æå¾®è°ƒæ—¶é—´: time_str={time_str}, hour={hour}, minute={minute}")

                            # åˆ›å»ºcronè§¦å‘å™¨ï¼ˆæ¯å¤©æŒ‡å®šæ—¶é—´æ‰§è¡Œï¼‰
                            trigger = CronTrigger(hour=hour, minute=minute, timezone='Asia/Shanghai')

                            # ä»»åŠ¡IDï¼šplan_id + ä»»åŠ¡ç±»å‹ + æ—¶é—´
                            job_id = f"plan_{plan_id}_finetune_{time_str.replace(':', '')}"

                            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å­˜åœ¨
                            existing_job = self.scheduler.get_job(job_id)
                            if existing_job:
                                logger.info(f"ä»»åŠ¡å·²å­˜åœ¨ï¼Œå…ˆç§»é™¤: {job_id}")
                                self.scheduler.remove_job(job_id)

                            # æ·»åŠ ä»»åŠ¡
                            self.scheduler.add_job(
                                func=self._trigger_finetune_wrapper,
                                trigger=trigger,
                                args=[plan_id],
                                id=job_id,
                                name=f"è‡ªåŠ¨å¾®è°ƒ-è®¡åˆ’{plan_id}-{time_str}",
                                replace_existing=True,
                                misfire_grace_time=300  # å…è®¸5åˆ†é’Ÿçš„å»¶è¿Ÿæ‰§è¡Œ
                            )

                            task_count += 1

                            # ç«‹å³æ£€æŸ¥ä»»åŠ¡çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                            job = self.scheduler.get_job(job_id)
                            next_run_time = job.next_run_time
                            if next_run_time:
                                next_run_beijing = next_run_time.astimezone(self.BEIJING_TZ)
                                logger.info(f"å·²æ·»åŠ è‡ªåŠ¨å¾®è°ƒä»»åŠ¡: plan_id={plan_id}, time={time_str}, job_id={job_id}, ä¸‹æ¬¡æ‰§è¡Œ(UTC+8)={next_run_beijing.strftime('%Y-%m-%d %H:%M:%S')}")
                            else:
                                logger.warning(f"å¾®è°ƒä»»åŠ¡åˆ›å»ºæˆåŠŸä½†æ— ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: plan_id={plan_id}, time={time_str}, job_id={job_id}")

                        except Exception as e:
                            logger.error(f"åˆ›å»ºå¾®è°ƒä»»åŠ¡å¤±è´¥: time={time_str}, error={e}")
                            continue
                else:
                    logger.warning(f"è®¡åˆ’å¯ç”¨äº†è‡ªåŠ¨å¾®è°ƒä½†æœªé…ç½®æ—¶é—´: plan_id={plan_id}")

            # å¤„ç†è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡ï¼ˆä½¿ç”¨é—´éš”æ—¶é—´æ¨¡å¼ï¼‰
            if plan.auto_inference_enabled:
                interval_hours = plan.auto_inference_interval_hours or 4
                if interval_hours > 0:
                    logger.info(f"å¯åŠ¨è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡: plan_id={plan_id}, interval_hours={interval_hours}")

                    try:
                        # åˆ›å»ºé—´éš”è§¦å‘å™¨ï¼ˆæ¯Nå°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰
                        trigger = IntervalTrigger(hours=interval_hours, timezone='Asia/Shanghai')

                        # ä»»åŠ¡IDï¼šplan_id + ä»»åŠ¡ç±»å‹
                        job_id = f"plan_{plan_id}_inference_interval"

                        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å­˜åœ¨
                        existing_job = self.scheduler.get_job(job_id)
                        if existing_job:
                            logger.info(f"ä»»åŠ¡å·²å­˜åœ¨ï¼Œå…ˆç§»é™¤: {job_id}")
                            self.scheduler.remove_job(job_id)

                        # æ·»åŠ ä»»åŠ¡
                        self.scheduler.add_job(
                            func=self._trigger_inference_wrapper,
                            trigger=trigger,
                            args=[plan_id],
                            id=job_id,
                            name=f"è‡ªåŠ¨é¢„æµ‹-è®¡åˆ’{plan_id}-{interval_hours}hé—´éš”",
                            replace_existing=True,
                            misfire_grace_time=300  # å…è®¸5åˆ†é’Ÿçš„å»¶è¿Ÿæ‰§è¡Œ
                        )

                        task_count += 1

                        # ç«‹å³æ£€æŸ¥ä»»åŠ¡çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                        job = self.scheduler.get_job(job_id)
                        next_run_time = job.next_run_time
                        if next_run_time:
                            next_run_beijing = next_run_time.astimezone(self.BEIJING_TZ)
                            logger.info(f"å·²æ·»åŠ è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡: plan_id={plan_id}, interval={interval_hours}h, job_id={job_id}, ä¸‹æ¬¡æ‰§è¡Œ(UTC+8)={next_run_beijing.strftime('%Y-%m-%d %H:%M:%S')}")
                        else:
                            logger.warning(f"é¢„æµ‹ä»»åŠ¡åˆ›å»ºæˆåŠŸä½†æ— ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: plan_id={plan_id}, interval={interval_hours}h, job_id={job_id}")

                    except Exception as e:
                        logger.error(f"åˆ›å»ºé¢„æµ‹ä»»åŠ¡å¤±è´¥: interval_hours={interval_hours}, error={e}")
                else:
                    logger.warning(f"è®¡åˆ’å¯ç”¨äº†è‡ªåŠ¨é¢„æµ‹ä½†é—´éš”æ—¶é—´æ— æ•ˆ: plan_id={plan_id}, interval_hours={interval_hours}")

            # é‡æ–°è¾“å‡ºè°ƒåº¦å™¨çŠ¶æ€
            self._log_scheduler_status()

            logger.info(f"å¯åŠ¨è®¡åˆ’å®šæ—¶è°ƒåº¦æˆåŠŸ: plan_id={plan_id}, ä»»åŠ¡æ•°={task_count}")
            return True

        except Exception as e:
            logger.error(f"å¯åŠ¨è®¡åˆ’å®šæ—¶è°ƒåº¦å¤±è´¥: plan_id={plan_id}, error={e}")
            return False

    async def stop_plan_schedule(self, plan_id: int) -> bool:
        """
        åœæ­¢è®¡åˆ’çš„æ‰€æœ‰å®šæ—¶ä»»åŠ¡

        Args:
            plan_id: è®¡åˆ’ID

        Returns:
            æ˜¯å¦æˆåŠŸåœæ­¢
        """
        try:
            # ç§»é™¤è¯¥è®¡åˆ’çš„æ‰€æœ‰ä»»åŠ¡
            removed_count = 0
            for job in self.scheduler.get_jobs():
                if job.id.startswith(f"plan_{plan_id}_"):
                    self.scheduler.remove_job(job.id)
                    removed_count += 1
                    logger.info(f"ç§»é™¤ä»»åŠ¡: {job.id}")

            logger.info(f"åœæ­¢è®¡åˆ’å®šæ—¶è°ƒåº¦æˆåŠŸ: plan_id={plan_id}, ç§»é™¤ä»»åŠ¡æ•°={removed_count}")
            return True

        except Exception as e:
            logger.error(f"åœæ­¢è®¡åˆ’å®šæ—¶è°ƒåº¦å¤±è´¥: plan_id={plan_id}, error={e}")
            return False

    async def _trigger_finetune(self, plan_id: int):
        """
        è§¦å‘å¾®è°ƒä»»åŠ¡ï¼ˆç”±è°ƒåº¦å™¨è°ƒç”¨ï¼‰
        ä½¿ç”¨ ScheduleService çš„å®ç°ï¼Œå› ä¸ºå®ƒæ›´å®Œå–„
        """
        try:
            current_time_beijing = datetime.now(self.BEIJING_TZ)
            logger.info(f"â° å®šæ—¶ä»»åŠ¡è§¦å‘å¾®è°ƒ: plan_id={plan_id}, time(UTC+8)={current_time_beijing.strftime('%Y-%m-%d %H:%M:%S')}")

            # æ£€æŸ¥è®¡åˆ’çŠ¶æ€
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    logger.error(f"è®¡åˆ’ä¸å­˜åœ¨: plan_id={plan_id}")
                    return {'success': False, 'error': 'è®¡åˆ’ä¸å­˜åœ¨'}

                logger.info(f"è®¡åˆ’çŠ¶æ€æ£€æŸ¥: plan_id={plan_id}, status={plan.status}, auto_finetune_enabled={plan.auto_finetune_enabled}")

                # æ£€æŸ¥è®¡åˆ’æ˜¯å¦è¿è¡Œä¸­
                if plan.status != 'running':
                    logger.warning(f"è®¡åˆ’æœªè¿è¡Œï¼Œè·³è¿‡å¾®è°ƒ: plan_id={plan_id}, status={plan.status}")
                    return {'success': False, 'error': f'è®¡åˆ’æœªè¿è¡Œ: {plan.status}'}

                # å†æ¬¡æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨å¾®è°ƒ
                if not plan.auto_finetune_enabled:
                    logger.warning(f"è®¡åˆ’æœªå¯ç”¨è‡ªåŠ¨å¾®è°ƒï¼Œè·³è¿‡: plan_id={plan_id}")
                    return {'success': False, 'error': 'è‡ªåŠ¨å¾®è°ƒæœªå¯ç”¨'}

                # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´è¡¨é…ç½®
                schedule_times = plan.auto_finetune_schedule or []
                if not schedule_times:
                    logger.warning(f"è®¡åˆ’æœªé…ç½®å¾®è°ƒæ—¶é—´è¡¨ï¼Œè·³è¿‡: plan_id={plan_id}")
                    return {'success': False, 'error': 'æœªé…ç½®å¾®è°ƒæ—¶é—´è¡¨'}

                logger.info(f"è®¡åˆ’é…ç½®æ£€æŸ¥é€šè¿‡: plan_id={plan_id}, schedule_times={schedule_times}")

            # åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®°å½•
            task_execution = None
            try:
                # ä»è®¡åˆ’é…ç½®ä¸­æ‰¾åˆ°åŒ¹é…å½“å‰æ—¶é—´çš„ä»»åŠ¡
                current_datetime = datetime.now(self.BEIJING_TZ)
                current_time_str = current_datetime.strftime('%H:%M')

                # æ‰¾åˆ°åŒ¹é…çš„æ—¶é—´ç‚¹
                scheduled_time_str = None
                for time_str in schedule_times:
                    if time_str == current_time_str:
                        scheduled_time_str = time_str
                        break

                # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                if not scheduled_time_str:
                    scheduled_time_str = current_time_str

                task_execution = TaskExecutionService.create_scheduled_task(
                    plan_id=plan_id,
                    task_type='auto_finetune',
                    time_str=scheduled_time_str
                )

                # æ ‡è®°ä»»åŠ¡å¼€å§‹
                TaskExecutionService.start_task_execution(task_execution.id)

            except Exception as record_error:
                logger.error(f"åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®°å½•å¤±è´¥: plan_id={plan_id}, error={record_error}")

            # è§¦å‘è®­ç»ƒ
            logger.info(f"å¼€å§‹è°ƒç”¨è®­ç»ƒæœåŠ¡: plan_id={plan_id}")

            try:
                training_id = await TrainingService.start_training(plan_id, manual=False)

                if training_id:
                    logger.info(f"âœ… å®šæ—¶å¾®è°ƒå·²å¯åŠ¨: plan_id={plan_id}, training_id={training_id}")

                    # ç­‰å¾…è®­ç»ƒå®Œæˆï¼ˆè¿™æ˜¯å…³é”®æ”¹è¿›ï¼šç­‰å¾…è®­ç»ƒå®Œå…¨å®Œæˆï¼‰
                    logger.info(f"ç­‰å¾…è®­ç»ƒå®Œå…¨å®Œæˆ: plan_id={plan_id}, training_id={training_id}")
                    max_wait_time = 3600  # æœ€å¤§ç­‰å¾…1å°æ—¶
                    wait_interval = 10   # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
                    waited_time = 0

                    while waited_time < max_wait_time:
                        await asyncio.sleep(wait_interval)
                        waited_time += wait_interval

                        # æ£€æŸ¥è®­ç»ƒçŠ¶æ€
                        training_status = TrainingService.get_training_status(training_id)
                        if training_status:
                            logger.info(f"è®­ç»ƒçŠ¶æ€æ£€æŸ¥: plan_id={plan_id}, training_id={training_id}, status={training_status['status']}, elapsed={waited_time}s")

                            if training_status['status'] in ['completed', 'failed', 'cancelled']:
                                logger.info(f"âœ… è®­ç»ƒå·²å®Œæˆ: plan_id={plan_id}, training_id={training_id}, final_status={training_status['status']}")

                                # è®°å½•æˆåŠŸç»“æœ
                                if task_execution:
                                    TaskExecutionService.complete_task_execution(
                                        task_id=task_execution.id,
                                        success=training_status['status'] == 'completed',
                                        output_data={
                                            'training_id': training_id,
                                            'final_status': training_status['status'],
                                            'duration': training_status.get('train_duration', 0)
                                        }
                                    )

                                return {
                                    'success': training_status['status'] == 'completed',
                                    'training_id': training_id,
                                    'final_status': training_status['status'],
                                    'duration': training_status.get('train_duration', 0)
                                }
                        else:
                            logger.warning(f"æ— æ³•è·å–è®­ç»ƒçŠ¶æ€: plan_id={plan_id}, training_id={training_id}")

                    # è¶…æ—¶å¤„ç†
                    logger.error(f"è®­ç»ƒç­‰å¾…è¶…æ—¶: plan_id={plan_id}, training_id={training_id}, waited={waited_time}s")
                    if task_execution:
                        TaskExecutionService.complete_task_execution(
                            task_id=task_execution.id,
                            success=False,
                            error_message='è®­ç»ƒç­‰å¾…è¶…æ—¶'
                        )

                    return {'success': False, 'error': 'è®­ç»ƒç­‰å¾…è¶…æ—¶', 'training_id': training_id}

                else:
                    logger.error(f"âŒ å®šæ—¶å¾®è°ƒå¯åŠ¨å¤±è´¥: plan_id={plan_id}")

                    # è®°å½•å¤±è´¥ç»“æœ
                    if task_execution:
                        TaskExecutionService.complete_task_execution(
                            task_id=task_execution.id,
                            success=False,
                            error_message='è®­ç»ƒæœåŠ¡å¯åŠ¨å¤±è´¥'
                        )

                    return {'success': False, 'error': 'è®­ç»ƒæœåŠ¡å¯åŠ¨å¤±è´¥'}

            except Exception as training_error:
                logger.error(f"è®­ç»ƒæœåŠ¡è°ƒç”¨å¤±è´¥: plan_id={plan_id}, error={training_error}")

                # è®°å½•å¼‚å¸¸ç»“æœ
                if task_execution:
                    TaskExecutionService.complete_task_execution(
                        task_id=task_execution.id,
                        success=False,
                        error_message=f'è®­ç»ƒæœåŠ¡å¼‚å¸¸: {str(training_error)}'
                    )

                return {'success': False, 'error': f'è®­ç»ƒæœåŠ¡å¼‚å¸¸: {str(training_error)}'}

        except Exception as e:
            logger.error(f"è§¦å‘å¾®è°ƒå¤±è´¥: plan_id={plan_id}, error={e}")
            return {'success': False, 'error': f'è§¦å‘å¾®è°ƒå¼‚å¸¸: {str(e)}'}

    def _trigger_finetune_wrapper(self, plan_id: int):
        """
        å¾®è°ƒè§¦å‘å™¨åŒ…è£…å™¨ï¼Œç”¨äºåœ¨APSchedulerä¸­è°ƒç”¨asyncå‡½æ•°
        """
        try:
            logger.info(f"å¾®è°ƒè§¦å‘å™¨åŒ…è£…å™¨å¼€å§‹: plan_id={plan_id}")

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰äº‹ä»¶å¾ªç¯
            try:
                loop = asyncio.get_running_loop()
                logger.info(f"æ£€æµ‹åˆ°è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨æ–°çº¿ç¨‹æ‰§è¡Œ: plan_id={plan_id}")

                # å¦‚æœæœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œåœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œ
                import concurrent.futures
                def run_training_complete():
                    """ç¡®ä¿è®­ç»ƒå®Œå…¨å®Œæˆï¼ˆåŒ…æ‹¬çŠ¶æ€æ›´æ–°ï¼‰çš„åŒ…è£…å‡½æ•°"""
                    try:
                        logger.info(f"æ–°çº¿ç¨‹ä¸­å¼€å§‹æ‰§è¡Œè®­ç»ƒ: plan_id={plan_id}")
                        result = self._run_async_in_new_loop(plan_id, 'finetune')
                        logger.info(f"æ–°çº¿ç¨‹ä¸­è®­ç»ƒå®Œæˆ: plan_id={plan_id}, result={result}")
                        return result
                    except Exception as e:
                        logger.error(f"æ–°çº¿ç¨‹ä¸­è®­ç»ƒæ‰§è¡Œå¤±è´¥: plan_id={plan_id}, error={e}")
                        raise

                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(run_training_complete)
                    # ç­‰å¾…è®­ç»ƒå®Œå…¨å®Œæˆï¼ŒåŒ…æ‹¬çŠ¶æ€æ›´æ–°ï¼Œè®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
                    logger.info(f"ç­‰å¾…è®­ç»ƒå®Œå…¨å®Œæˆ: plan_id={plan_id}")
                    result = future.result(timeout=10800)  # 3å°æ—¶è¶…æ—¶ï¼Œç»™å¾®è°ƒè®­ç»ƒè¶³å¤Ÿæ—¶é—´å®Œæˆ
                    logger.info(f"âœ… è‡ªåŠ¨è®­ç»ƒå®Œå…¨å®Œæˆ: plan_id={plan_id}, result={result}")

            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œç›´æ¥è¿è¡Œ
                logger.info(f"æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥æ‰§è¡Œ: plan_id={plan_id}")
                result = asyncio.run(self._trigger_finetune(plan_id))
                logger.info(f"âœ… è‡ªåŠ¨è®­ç»ƒå®Œå…¨å®Œæˆ: plan_id={plan_id}, result={result}")

        except Exception as e:
            logger.error(f"å¾®è°ƒåŒ…è£…å™¨è°ƒç”¨å¤±è´¥: plan_id={plan_id}, error={e}")

    async def _trigger_inference(self, plan_id: int, manual_trigger: bool = False):
        """
        è§¦å‘é¢„æµ‹ä»»åŠ¡ï¼ˆç”±è°ƒåº¦å™¨è°ƒç”¨ï¼‰
        ä½¿ç”¨ ScheduleService çš„å®ç°ï¼ŒåŒ…å«æ™ºèƒ½æ•°æ®åç§»è®¡ç®—
        """
        try:
            current_time_beijing = datetime.now(self.BEIJING_TZ)
            trigger_type = "æ‰‹åŠ¨" if manual_trigger else "å®šæ—¶"
            logger.info(f"â° {trigger_type}é¢„æµ‹ä»»åŠ¡è§¦å‘: plan_id={plan_id}, time(UTC+8)={current_time_beijing.strftime('%Y-%m-%d %H:%M:%S')}")

            # æ£€æŸ¥è®¡åˆ’çŠ¶æ€
            with get_db() as db:
                plan = db.query(TradingPlan).filter(TradingPlan.id == plan_id).first()
                if not plan:
                    logger.error(f"è®¡åˆ’ä¸å­˜åœ¨: plan_id={plan_id}")
                    return

                logger.info(f"è®¡åˆ’çŠ¶æ€æ£€æŸ¥: plan_id={plan_id}, status={plan.status}, auto_inference_enabled={plan.auto_inference_enabled}")

                # æ£€æŸ¥è®¡åˆ’æ˜¯å¦è¿è¡Œä¸­
                if plan.status != 'running':
                    logger.warning(f"è®¡åˆ’æœªè¿è¡Œï¼Œè·³è¿‡é¢„æµ‹: plan_id={plan_id}, status={plan.status}")
                    return

                # å†æ¬¡æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨é¢„æµ‹
                if not plan.auto_inference_enabled:
                    logger.warning(f"è®¡åˆ’æœªå¯ç”¨è‡ªåŠ¨é¢„æµ‹ï¼Œè·³è¿‡: plan_id={plan_id}")
                    return

                # æ£€æŸ¥æ˜¯å¦æœ‰é—´éš”æ—¶é—´é…ç½®
                interval_hours = plan.auto_inference_interval_hours or 4
                if interval_hours <= 0:
                    logger.warning(f"è®¡åˆ’æœªé…ç½®é¢„æµ‹é—´éš”æ—¶é—´ï¼Œè·³è¿‡: plan_id={plan_id}")
                    return

                logger.info(f"è®¡åˆ’é…ç½®æ£€æŸ¥é€šè¿‡: plan_id={plan_id}, interval_hours={interval_hours}")

            # æ‰‹åŠ¨è§¦å‘æ—¶è·³è¿‡é—´éš”æ—¶é—´æ£€æŸ¥ï¼Œè‡ªåŠ¨è§¦å‘æ—¶è¿›è¡Œæ™ºèƒ½é¢„æµ‹æ£€æŸ¥
            if not manual_trigger:
                # æ™ºèƒ½é¢„æµ‹è§¦å‘ï¼šæ£€æŸ¥æœ€æ–°é¢„æµ‹æ•°æ®æ—¶é—´
                latest_prediction_time = self.check_latest_prediction_time(plan_id)
                current_time = datetime.now(self.BEIJING_TZ)

                if latest_prediction_time:
                    # è®¡ç®—æ—¶é—´å·®
                    time_diff = current_time - latest_prediction_time
                    time_diff_hours = time_diff.total_seconds() / 3600

                    logger.info(f"è®¡åˆ’ {plan_id}: æœ€æ–°é¢„æµ‹æ—¶é—´: {latest_prediction_time}, è·ä»Š {time_diff_hours:.2f} å°æ—¶")

                    # å¦‚æœæ—¶é—´å·®å°äºé…ç½®çš„é—´éš”æ—¶é—´ï¼Œè·³è¿‡æœ¬æ¬¡é¢„æµ‹
                    if time_diff_hours < interval_hours:
                        remaining_hours = interval_hours - time_diff_hours
                        logger.info(f"â¸ï¸ è®¡åˆ’ {plan_id}: é¢„æµ‹é—´éš”æœªæ»¡è¶³ï¼Œè·³è¿‡æœ¬æ¬¡é¢„æµ‹ã€‚è¿˜éœ€ç­‰å¾… {remaining_hours:.2f} å°æ—¶")
                        return
                    else:
                        logger.info(f"âœ… è®¡åˆ’ {plan_id}: é¢„æµ‹é—´éš”å·²æ»¡è¶³ï¼Œæ‰§è¡Œæ–°çš„é¢„æµ‹ï¼ˆé—´éš” {time_diff_hours:.2f} å°æ—¶ï¼‰")
                else:
                    logger.info(f"âœ… è®¡åˆ’ {plan_id}: æ²¡æœ‰å†å²é¢„æµ‹æ•°æ®ï¼Œæ‰§è¡Œé¦–æ¬¡é¢„æµ‹")
            else:
                logger.info(f"âœ… è®¡åˆ’ {plan_id}: æ‰‹åŠ¨è§¦å‘ï¼Œè·³è¿‡é—´éš”æ—¶é—´æ£€æŸ¥ï¼Œç›´æ¥æ‰§è¡Œé¢„æµ‹")

            # åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®°å½•
            task_execution = None
            try:
                # åˆ›å»ºé¢„æµ‹ä»»åŠ¡è®°å½•
                current_datetime = datetime.now(self.BEIJING_TZ)

                if manual_trigger:
                    task_name = f"æ‰‹åŠ¨é¢„æµ‹-è®¡åˆ’{plan_id}"
                    task_description = "ç”¨æˆ·æ‰‹åŠ¨è§¦å‘çš„é¢„æµ‹ä»»åŠ¡"
                    trigger_type = "manual"
                    trigger_source = f"plan_{plan_id}_manual_trigger"
                else:
                    task_name = f"è‡ªåŠ¨é¢„æµ‹-è®¡åˆ’{plan_id}-{interval_hours}hé—´éš”"
                    task_description = f"æ¯{interval_hours}å°æ—¶è‡ªåŠ¨æ‰§è¡Œä¸€æ¬¡é¢„æµ‹"
                    trigger_type = "scheduled"
                    trigger_source = f"plan_{plan_id}_interval_scheduler"

                task_execution = TaskExecutionService.create_task_execution(
                    plan_id=plan_id,
                    task_type="auto_inference",
                    task_name=task_name,
                    task_description=task_description,
                    trigger_type=trigger_type,
                    trigger_source=trigger_source,
                    input_data={"interval_hours": interval_hours, "manual_trigger": manual_trigger}
                )

                # æ ‡è®°ä»»åŠ¡å¼€å§‹
                TaskExecutionService.start_task_execution(task_execution.id)

            except Exception as record_error:
                logger.error(f"åˆ›å»ºé¢„æµ‹ä»»åŠ¡æ‰§è¡Œè®°å½•å¤±è´¥: plan_id={plan_id}, error={record_error}")

            # è®¡ç®—æ™ºèƒ½æ•°æ®åç§»
            from services.inference_data_offset_service import inference_data_offset_service
            logger.info(f"è®¡ç®—æ™ºèƒ½æ•°æ®åç§»: plan_id={plan_id}")

            try:
                offset_result = inference_data_offset_service.calculate_optimal_data_offset(
                    plan_id=plan_id,
                    target_interval_hours=interval_hours,
                    manual_trigger=manual_trigger
                )

                if offset_result['success']:
                    data_offset = offset_result['data_offset']
                    logger.info(f"âœ… æ•°æ®åç§»è®¡ç®—å®Œæˆ: plan_id={plan_id}, offset={data_offset}")
                    logger.info(f"ğŸ“Š åç§»è¯´æ˜: {offset_result['reasoning']}")

                    # è·å–æœ€æ–°è®­ç»ƒè®°å½•å¹¶æ›´æ–°å‚æ•°
                    with get_db() as db:
                        latest_training = db.query(TrainingRecord).filter(
                            TrainingRecord.plan_id == plan_id,
                            TrainingRecord.status == 'completed',
                            TrainingRecord.is_active == True
                        ).order_by(TrainingRecord.created_at.desc()).first()

                        if latest_training:
                            # æ›´æ–°æ¨ç†å‚æ•°
                            update_success = inference_data_offset_service.update_inference_params_with_offset(
                                plan_id=plan_id,
                                training_id=latest_training.id,
                                data_offset=data_offset
                            )

                            if update_success:
                                logger.info(f"âœ… æ¨ç†å‚æ•°å·²æ›´æ–°: training_id={latest_training.id}, data_offset={data_offset}")
                            else:
                                logger.warning(f"âš ï¸ æ¨ç†å‚æ•°æ›´æ–°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                        else:
                            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒè®°å½•ï¼Œæ— æ³•æ›´æ–°æ¨ç†å‚æ•°")

                else:
                    logger.warning(f"âš ï¸ æ•°æ®åç§»è®¡ç®—å¤±è´¥: {offset_result['reasoning']}")
                    data_offset = 0

            except Exception as offset_error:
                logger.error(f"æ•°æ®åç§»è®¡ç®—å¼‚å¸¸: plan_id={plan_id}, error={offset_error}")
                data_offset = 0

            # è§¦å‘é¢„æµ‹
            from services.inference_service import InferenceService
            logger.info(f"å¼€å§‹è°ƒç”¨æ¨ç†æœåŠ¡: plan_id={plan_id}, data_offset={data_offset}")

            try:
                inference_id = await InferenceService.start_inference_by_plan(plan_id, manual=False)

                if inference_id:
                    logger.info(f"âœ… å®šæ—¶é¢„æµ‹å·²å¯åŠ¨: plan_id={plan_id}, inference_id={inference_id}, data_offset={data_offset}")

                    # è®°å½•æˆåŠŸç»“æœ
                    if task_execution:
                        TaskExecutionService.complete_task_execution(
                            task_id=task_execution.id,
                            success=True,
                            output_data={
                                'inference_id': inference_id,
                                'data_offset': data_offset,
                                'offset_reasoning': offset_result.get('reasoning', '') if 'offset_result' in locals() else ''
                            }
                        )
                else:
                    logger.error(f"âŒ å®šæ—¶é¢„æµ‹å¯åŠ¨å¤±è´¥: plan_id={plan_id}")

                    # è®°å½•å¤±è´¥ç»“æœ
                    if task_execution:
                        TaskExecutionService.complete_task_execution(
                            task_id=task_execution.id,
                            success=False,
                            error_message='æ¨ç†æœåŠ¡å¯åŠ¨å¤±è´¥'
                        )

            except Exception as inference_error:
                logger.error(f"æ¨ç†æœåŠ¡è°ƒç”¨å¤±è´¥: plan_id={plan_id}, error={inference_error}")

                # è®°å½•å¼‚å¸¸ç»“æœ
                if task_execution:
                    TaskExecutionService.complete_task_execution(
                        task_id=task_execution.id,
                        success=False,
                        error_message=f'æ¨ç†æœåŠ¡å¼‚å¸¸: {str(inference_error)}'
                    )

        except Exception as e:
            logger.error(f"è§¦å‘é¢„æµ‹å¤±è´¥: plan_id={plan_id}, error={e}")

    def _trigger_inference_wrapper(self, plan_id: int):
        """
        é¢„æµ‹è§¦å‘å™¨åŒ…è£…å™¨ï¼Œç”¨äºåœ¨APSchedulerä¸­è°ƒç”¨asyncå‡½æ•°
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰äº‹ä»¶å¾ªç¯
            try:
                loop = asyncio.get_running_loop()
                # å¦‚æœæœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œåœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œ
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(self._run_async_in_new_loop, plan_id, 'inference')
                    future.result()
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œç›´æ¥è¿è¡Œ
                asyncio.run(self._trigger_inference(plan_id, manual_trigger=True))
        except Exception as e:
            logger.error(f"é¢„æµ‹åŒ…è£…å™¨è°ƒç”¨å¤±è´¥: plan_id={plan_id}, error={e}")

    def _run_async_in_new_loop(self, plan_id: int, task_type: str):
        """åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            logger.info(f"æ–°äº‹ä»¶å¾ªç¯å¼€å§‹: plan_id={plan_id}, task_type={task_type}")
            if task_type == 'finetune':
                result = loop.run_until_complete(self._trigger_finetune(plan_id))
            elif task_type == 'inference':
                result = loop.run_until_complete(self._trigger_inference(plan_id, manual_trigger=True))
            else:
                raise ValueError(f"Unknown task type: {task_type}")
            logger.info(f"æ–°äº‹ä»¶å¾ªç¯å®Œæˆ: plan_id={plan_id}, task_type={task_type}, result={result}")
            return result
        except Exception as e:
            logger.error(f"æ–°äº‹ä»¶å¾ªç¯æ‰§è¡Œå¤±è´¥: plan_id={plan_id}, task_type={task_type}, error={e}")
            raise
        finally:
            loop.close()
            logger.info(f"æ–°äº‹ä»¶å¾ªç¯å·²å…³é—­: plan_id={plan_id}, task_type={task_type}")

    async def _create_agent_task(self, plan: TradingPlan, training_record: TrainingRecord, scheduled_time: datetime, db):
        """åˆ›å»ºè‡ªåŠ¨Agentä»»åŠ¡"""
        try:
            task = TaskExecution(
                plan_id=plan.id,
                task_type='auto_agent',
                task_name=f'è‡ªåŠ¨Agentå†³ç­– - {plan.plan_name}',
                task_description=f'åŸºäºæ¨ç†ç»“æœçš„è‡ªåŠ¨Agentå†³ç­–ä»»åŠ¡',
                status='pending',
                priority=3,
                scheduled_time=scheduled_time,
                trigger_type='scheduled',
                trigger_source='immediate_scheduler',
                input_data={
                    'training_record_id': training_record.id,
                    'training_version': training_record.version
                },
                task_metadata={
                    'auto_generated': True,
                    'auto_tool_execution': plan.auto_tool_execution_enabled  # å·²åºŸå¼ƒå­—æ®µï¼Œä¿ç•™ç”¨äºå†å²è®°å½•
                }
            )

            db.add(task)
            db.commit()
            db.refresh(task)

            logger.info(f"åˆ›å»ºè‡ªåŠ¨Agentä»»åŠ¡: {task.id}")
            return task

        except Exception as e:
            logger.error(f"åˆ›å»ºAgentä»»åŠ¡å¤±è´¥: {e}")
            return None

    def check_latest_prediction_time(self, plan_id: int) -> Optional[datetime]:
        """
        æ£€æŸ¥è®¡åˆ’æœ€æ–°çš„é¢„æµ‹æ•°æ®æ—¶é—´

        Args:
            plan_id: è®¡åˆ’ID

        Returns:
            æœ€æ–°é¢„æµ‹æ•°æ®çš„åˆ›å»ºæ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰é¢„æµ‹æ•°æ®åˆ™è¿”å›None
        """
        try:
            with get_db() as db:
                # è·å–æœ€æ–°çš„è®­ç»ƒè®°å½•ID
                latest_training = db.query(TrainingRecord).filter(
                    TrainingRecord.plan_id == plan_id,
                    TrainingRecord.status == 'completed'
                ).order_by(TrainingRecord.created_at.desc()).first()

                if not latest_training:
                    logger.info(f"è®¡åˆ’ {plan_id}: æ²¡æœ‰æ‰¾åˆ°å®Œæˆçš„è®­ç»ƒè®°å½•")
                    return None

                # è·å–è¯¥è®­ç»ƒè®°å½•çš„æœ€æ–°é¢„æµ‹æ•°æ®
                from database.models import PredictionData
                latest_prediction = db.query(PredictionData).filter(
                    PredictionData.training_record_id == latest_training.id
                ).order_by(PredictionData.created_at.desc()).first()

                if latest_prediction:
                    logger.info(f"è®¡åˆ’ {plan_id}: æœ€æ–°é¢„æµ‹æ•°æ®æ—¶é—´: {latest_prediction.created_at}")
                    return latest_prediction.created_at
                else:
                    logger.info(f"è®¡åˆ’ {plan_id}: è®­ç»ƒè®°å½• {latest_training.id} æ²¡æœ‰é¢„æµ‹æ•°æ®")
                    return None

        except Exception as e:
            logger.error(f"æ£€æŸ¥æœ€æ–°é¢„æµ‹æ•°æ®æ—¶é—´å¤±è´¥: plan_id={plan_id}, error={e}")
            return None

    def _log_scheduler_status(self):
        """è¾“å‡ºè°ƒåº¦å™¨çŠ¶æ€ä¿¡æ¯"""
        try:
            if self.scheduler:
                current_time = datetime.now(self.BEIJING_TZ)
                logger.info(f"ç»Ÿä¸€è°ƒåº¦å™¨çŠ¶æ€ - å½“å‰æ—¶é—´(UTC+8): {current_time.strftime('%Y-%m-%d %H:%M:%S')}")

                # è¾“å‡ºæ‰€æœ‰ä»»åŠ¡
                jobs = self.scheduler.get_jobs()
                logger.info(f"å½“å‰ä»»åŠ¡æ•°: {len(jobs)}")
                for job in jobs:
                    next_run = job.next_run_time
                    if next_run:
                        # è½¬æ¢ä¸ºUTC+8æ—¶é—´æ˜¾ç¤º
                        if next_run.tzinfo is None:
                            next_run_beijing = next_run.replace(tzinfo=self.BEIJING_TZ)
                        else:
                            next_run_beijing = next_run.astimezone(self.BEIJING_TZ)
                        logger.info(f"ä»»åŠ¡ {job.id}: ä¸‹æ¬¡æ‰§è¡Œ {next_run_beijing.strftime('%Y-%m-%d %H:%M:%S')}")
                    else:
                        logger.info(f"ä»»åŠ¡ {job.id}: æ— ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´")
        except Exception as e:
            logger.error(f"è¾“å‡ºè°ƒåº¦å™¨çŠ¶æ€å¤±è´¥: {e}")

    def get_task_history(self, plan_id: int, limit: int = 50) -> List[Dict]:
        """è·å–ä»»åŠ¡æ‰§è¡Œå†å²"""
        try:
            with get_db() as db:
                tasks = db.query(TaskExecution).filter(
                    TaskExecution.plan_id == plan_id
                ).order_by(desc(TaskExecution.created_at)).limit(limit).all()

                task_list = []
                for task in tasks:
                    task_info = {
                        'id': task.id,
                        'task_type': task.task_type,
                        'task_name': task.task_name,
                        'status': task.status,
                        'priority': task.priority,
                        'scheduled_time': format_datetime_full_beijing(task.scheduled_time) if task.scheduled_time else None,
                        'started_at': format_datetime_full_beijing(task.started_at) if task.started_at else None,
                        'completed_at': format_datetime_full_beijing(task.completed_at) if task.completed_at else None,
                        'duration_seconds': task.duration_seconds,
                        'trigger_type': task.trigger_type,
                        'progress_percentage': task.progress_percentage,
                        'error_message': task.error_message,
                        'created_at': format_datetime_full_beijing(task.created_at)
                    }

                    # æ·»åŠ çŠ¶æ€æ˜¾ç¤º
                    status_map = {
                        'pending': 'â³ ç­‰å¾…ä¸­',
                        'running': 'ğŸ”„ æ‰§è¡Œä¸­',
                        'completed': 'âœ… å·²å®Œæˆ',
                        'failed': 'âŒ å¤±è´¥',
                        'cancelled': 'â¹ï¸ å·²å–æ¶ˆ'
                    }
                    task_info['status_display'] = status_map.get(task.status, f"â“ {task.status}")

                    # æ·»åŠ ä»»åŠ¡ç±»å‹æ˜¾ç¤º
                    type_map = {
                        'auto_finetune': 'ğŸ”§ è‡ªåŠ¨å¾®è°ƒ',
                        'auto_inference': 'ğŸ”® è‡ªåŠ¨æ¨ç†',
                        'auto_agent': 'ğŸ¤– è‡ªåŠ¨Agent'
                    }
                    task_info['type_display'] = type_map.get(task.task_type, f"ğŸ“‹ {task.task_type}")

                    task_list.append(task_info)

                return task_list

        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡å†å²å¤±è´¥: {e}")
            return []

    def _daily_model_cleanup_wrapper(self):
        """æ¯æ—¥æ¨¡å‹æ¸…ç†åŒ…è£…å™¨"""
        import concurrent.futures
        try:
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._daily_model_cleanup)
                future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
        except Exception as e:
            logger.error(f"æ¯æ—¥æ¨¡å‹æ¸…ç†åŒ…è£…å™¨æ‰§è¡Œå¤±è´¥: {e}")

    def _daily_model_cleanup(self):
        """æ‰§è¡Œæ¯æ—¥æ¨¡å‹æ¸…ç†"""
        try:
            from services.model_cleanup_service import cleanup_all_plans_models
            logger.info("ğŸ•°ï¸ å¼€å§‹æ¯æ—¥æ¨¡å‹æ¸…ç†")
            cleanup_stats = cleanup_all_plans_models(keep_count=7)
            total_deleted = sum(stats['models_deleted'] for stats in cleanup_stats.values())
            logger.info(f"âœ… æ¯æ—¥æ¨¡å‹æ¸…ç†å®Œæˆ: åˆ é™¤{total_deleted}ä¸ªæ¨¡å‹")
            return cleanup_stats
        except Exception as e:
            logger.error(f"âŒ æ¯æ—¥æ¨¡å‹æ¸…ç†å¤±è´¥: {e}")

    async def reload_all_schedules(self):
        """
        é‡æ–°åŠ è½½æ‰€æœ‰è¿è¡Œä¸­è®¡åˆ’çš„å®šæ—¶ä»»åŠ¡
        ï¼ˆç”¨äºåº”ç”¨å¯åŠ¨æ—¶ï¼‰
        """
        try:
            logger.info("é‡æ–°åŠ è½½æ‰€æœ‰å®šæ—¶ä»»åŠ¡...")

            with get_db() as db:
                # æŸ¥è¯¢æ‰€æœ‰è¿è¡Œä¸­çš„è®¡åˆ’
                running_plans = db.query(TradingPlan).filter(
                    TradingPlan.status == 'running'
                ).all()

                logger.info(f"æ‰¾åˆ° {len(running_plans)} ä¸ªè¿è¡Œä¸­çš„è®¡åˆ’")

                for plan in running_plans:
                    success = await self.start_plan_schedule(plan.id)
                    if success:
                        logger.info(f"âœ… é‡æ–°åŠ è½½è®¡åˆ’ {plan.id} çš„å®šæ—¶ä»»åŠ¡æˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ é‡æ–°åŠ è½½è®¡åˆ’ {plan.id} çš„å®šæ—¶ä»»åŠ¡å¤±è´¥")

            logger.info("å®šæ—¶ä»»åŠ¡é‡æ–°åŠ è½½å®Œæˆ")

        except Exception as e:
            logger.error(f"é‡æ–°åŠ è½½å®šæ—¶ä»»åŠ¡å¤±è´¥: error={e}")

    # å…¼å®¹æ€§æ–¹æ³•ï¼Œä¿æŒä¸åŸæœ‰æ¥å£çš„å…¼å®¹
    async def start_schedule(self, plan_id: int) -> bool:
        """å…¼å®¹æ€§æ–¹æ³•ï¼Œè°ƒç”¨ start_plan_schedule"""
        return await self.start_plan_schedule(plan_id)

    async def stop_schedule(self, plan_id: int) -> bool:
        """å…¼å®¹æ€§æ–¹æ³•ï¼Œè°ƒç”¨ stop_plan_schedule"""
        return await self.stop_plan_schedule(plan_id)

    def test_scheduler(self):
        """æµ‹è¯•è°ƒåº¦å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
        try:
            logger.info("=== ç»Ÿä¸€è°ƒåº¦å™¨æµ‹è¯•å¼€å§‹ ===")

            current_time_beijing = datetime.now(self.BEIJING_TZ)
            logger.info(f"å½“å‰æ—¶é—´(UTC+8): {current_time_beijing.strftime('%Y-%m-%d %H:%M:%S')}")

            # è·å–æ‰€æœ‰ä»»åŠ¡
            jobs = self.scheduler.get_jobs()
            logger.info(f"æ€»ä»»åŠ¡æ•°: {len(jobs)}")

            if not jobs:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä»»åŠ¡")
                return

            for job in jobs:
                next_run = job.next_run_time
                if next_run:
                    next_run_beijing = next_run.astimezone(self.BEIJING_TZ)
                    time_until = next_run_beijing - current_time_beijing
                    logger.info(f"ä»»åŠ¡ {job.id}: ä¸‹æ¬¡æ‰§è¡Œ {next_run_beijing.strftime('%Y-%m-%d %H:%M:%S')}, è·ç¦»ç°åœ¨ {time_until}")
                else:
                    logger.warning(f"ä»»åŠ¡ {job.id}: æ— ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´")

            logger.info("=== ç»Ÿä¸€è°ƒåº¦å™¨æµ‹è¯•ç»“æŸ ===")

        except Exception as e:
            logger.error(f"ç»Ÿä¸€è°ƒåº¦å™¨æµ‹è¯•å¤±è´¥: {e}")


# å…¨å±€ç»Ÿä¸€è°ƒåº¦å™¨å®ä¾‹
unified_scheduler = UnifiedScheduler()